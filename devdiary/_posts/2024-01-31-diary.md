---
layout: post
title: dev diary - 2024.01
description: >
  2024.01의 개발일지 입니다.
sitemap: false
---

## Dev Diary (2024.01)

### 2024.01.15

- 오랜만에 하니까 다 까먹었다.
- 다이어그램 해설 기능은 python_arrow_detect.py파일
- 아직 앱이랑 연결 안함
    - 오늘 이거 연결하고 끝날듯
    - 2주치 계획도 세워야지 (아이패드 들고다니자..)
- 할 일
    - 앱이랑 다이어그램 해설 기능 연결
    - 테스트할 강의 동영상 및 해설 텍스트 제작 (생성된 것과 비교할 수 있는)
    - 테스트 (BLEU, ROUGE 등) 
        - 여기까지 목요일 랩미 발표
    - 설문 조사 틀 만들기
    - 논문 작성 (서론까지 이번주 완성)
    
- 앱이랑 연동 직전에 끝남
    - flask_arrow_detect.py랑 앱 연동
    - 앱의 4번째 버튼으로 만들어서 확인
    - 프론트는 모르겠음 대충해
    - 연동 확인만 하고 영상 제작하면 될 것 같음
    - 아 강의자 음성 speak to text 연동해야함
    - 프론트 구상해야겠는데..
- flask_test.py
- flask_rectangle_detect.py
- flask_arrow_detect.py 키면됨 (가상환경에서)


### 2024.01.20

- 여태 한거
    - flask_arrow_detect.py랑 연동했다.
        - 이제 크롭 이미지 firebase 저장, 그 이미지로 diagram analysis sentence만들기 가능.

- 이제 해야할 것
    - 이제 동영상을 firebase에 저장해서 그 동영상으로 flask_test, flask_rectangle_detect 해야함
        - 일단 flask_test를 연동해서 firebase의 동영상으로 scene detect를 해야함
    - 그 다음에 그 이미지들을 firebase에 올려서 flask_rectangle_detect 진행
    - 그 rectangle이 다이어그램이면 다이어그램 해설인 flask_arrow_detect진행
    - speech to text 진행
    - STT랑 ocr, diagram to text 결합

- 여기까지 일요일까지 완성
    - 돌려보려면 강의 동영상 필요
    - 3개 만들기까지 일요일 자정 완성
- 월요일에 나머지 만들고 테스트
    - 월요일 자정까지 테스트 완료
- 화요일에 서론, 관련연구 쓰기
- 수요일에 본론, 테스트 관련 쓰기
- 목요일에 ppt만들어 발표

1. flask_test에 로컬 동영상 연동
    - flask_test의 비디오 path는 외부 url도 가능
        - firebase에 비디오 저장, url 불러오기
    - scene잘라서 나온 이미지를 그냥 밀어넣었는데, 연동해야함
    - 동영상을 선택한 다음에 
        1. 동영상을 firebase에 저장
            - 완료!  
        2. firebase에서 url download
            - 완료!
        3. url을 flask_test에 전달
            - 완료!
        4. detected scenes timeline 앱으로 전송
            - 완료!
        5. 앱에서 video to image 해서 image를 firebase에 저장
        - 이미지는 앱 화면에 보여줌 (로컬도 저장)
        6. firebase에서 해당 이미지들 다 불러옴
        7. 이미지를 flask_rectangle_detect.py 다 돌림

2. flask_rectangle_detect.py에 로컬 동영상 연동
    - 각 scene에서 2번째로 큰 사각형 뽑음


### 논문 작성
- 논문 6페이지 이내
- 익명으로 
    - 선수 연구도 작성하면 안된다고 함
    - All submissions must be anonymized.  No information that would reveal author identity, including author names or affiliations, should be included.  References to one’s own work should not be identifiable as self-citations; e.g. “As we showed in Jones (2017)” should be avoided in favor of “Jones (2017) showed.”  Acknowledgements, including sources of funding and assistance, should also be omitted in the initial submissions. Any online supplemental information that submissions refer to must also be anonymized. Submissions that do not conform to these requirements will be rejected.
    - 그럼 관련 연구에 선수 연구 쓰면 안되나..? 아니면 이 연구를 참고했다고 작성하면 되는건가..?

허ㅣㅏㄴㅇ머히ㅏ머히ㅏ어하ㅣㅓ임ㅎ
할수 있따!!!!!!!!!!!
씨발

- 논문 포인트
    - 저번 논문이랑 다른 점
        - 아 방콕논문, 영국 논문 아직 안나옴
        - 그 전 논문들을 언급해야하나..?
        - 영국 논문이 10페이지니까 거의 절반정도 줄여야함
        - 서론, 요약을 1페이지 안에 끝내야함
    - 서론에서 코로나 언급 하지 말고 온라인 수업의 비율이 증가하고 있다는 내용으로 시작.
    - 전 논문은 다이어그램 해설 기법에 대한 평가를 진행
    - 이번 논문에서는 전체적인 해설기에 대한 평가 진행, 이 해설기에 대한 소개를 해야한다. 
    - 해설기
        - 동영상을 넣으면 동영상 내의 모든 정보를 텍스트화해서 시각장애인에게 소리로 알려준다.
        - 어차피 초안 발표니까 되는데까지 대충 쓰자.

    1. 서론
        - 현대 교육 환경에서의 최근 동향에 집중하여 온라인 교육과 관련된 변화를 강조
        - 교육 방식의 디지털 전환 및 기술 도입 등의 측면을 강조
        - 사용자 중심의 관점을 강조하여, 온라인 교육이 어떻게 학생들에게 더 나은 경험을 제공할 수 있는지에 대한 관점을 강조합니다. 특히 시각장애 학생들의 고유한 제한사항을 고려하여 어떻게 개선되고 제공되어야 하는지에 중점
        - 기술 발전과 그에 따른 변화를 강조하면서, 어떻게 새로운 어플리케이션은 기존의 어려움을 극복하고 학생들에게 더 나은 지원을 제공할 수 있는지에 대해 강조
        - 미래의 교육 환경에 대한 고려와 그에 따른 대비책에 중점을 두면서, 개발된 어플리케이션이 어떻게 학생들에게 적응 가능하고 지속적으로 유용한지에 대해 강조

    2. 관련 연구
        - 디지털 환경에서 시각장애인의 정보 획득 도구
        - 영상에서 정보를 획득하기 위한 다양한 기술
    
    3. 동영상 강의 내 화면자료 음성 해설 제공
        - 시스템 개요
        - 화면자료 해설 시스템 구현
            - 동영상 화면 내 슬라이드 전환 시점 추출
            - 강의자료 슬라이드별 해설 음성 자동 생성
                - text
                - image
                    - natural picture
                    - diagram
            - 영상 병합 및 최종 영상 생성

    4. 화면자료 음성 해설 시스템 사용성 평가
        - 시스템 성능 평가 및 사용성 평가 설계
        - 사용성 평가 결과 분석

        - BLEU
            - image caption을 하는거는 의미 없을 것같음.
            - 이게 내가 만들어놓은 

    5. 결론
        - 기대되는 기여와 결과 예측:
        - 어플리케이션의 성능 향상과 사용자 경험 개선을 통해 시각장애 학생들이 온라인 강의에 보다 효과적으로 참여할 수 있도록 예상되는 기여를 강조합니다.
        - 연구 결과에 대한 예상되는 결과와 그에 따른 교육환경 개선의 가능성을 언급합니다.



    2장에서는 현재 디지털 환경에서 활용되고 있는 시각장애인의 정보 획득 도구와 영상에서 정보를 획득하기 위한 다양한 기술에 대하여 설명한다. 3장에서는 동영상 강의 내 화면자료 음성 해설을 제공하기 위해 본 논문에서 제안하는 시스템의 개요 및 해설 시스템 구현 방법에 대하여 설명한다. 4장에서는 화면 자료 음성 해설 시스템의 성능 및 사용성 평가 과정과 결과를 제시하고 5장에서 결론을 제시한다. 


    다이어그램 감지, 다이어그램 부분의 감지된 텍스트 
