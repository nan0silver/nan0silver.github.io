var tipuesearch = {"pages": [{
    "title": "[JAVA] Java 알고리즘 문제 풀이 시, 자주 쓰이는 Steam API 함수들",
    "text": "1. 배열 → 스트림 2. 형 변환 (Mapping) 3. 집계 연산 (Aggregation) 4. 정렬 / 수집 5. forEach / joining 자주 쓰이는 Stream API 함수들 1. 배열 → 스트림 Arrays.stream(arr) : int[], double[], long[] 같은 primitive 배열을 스트림으로 변환 Stream.of(array) : String[] 같은 객체 배열을 스트림으로 변환 예: int[] arr = {1, 2, 3}; Arrays.stream(arr).forEach(System.out::println); String[] strArr = {\"1\", \"2\", \"3\"}; Stream.of(strArr).forEach(System.out::println); 2. 형 변환 (Mapping) mapToInt(Integer::parseInt) : 문자열 스트림 → 정수 스트림 map(String::length) : 문자열 스트림 → 문자열 길이 스트림 예: String[] arr = {\"1\", \"2\", \"3\"}; int[] intArr = Arrays.stream(arr).mapToInt(Integer::parseInt).toArray(); 3. 집계 연산 (Aggregation) .min().getAsInt() / .max().getAsInt() : 최솟값 / 최댓값 .sum() : 합계 .average().getAsDouble() : 평균 예: int[] arr = {1, 2, 3, 4}; int min = Arrays.stream(arr).min().getAsInt(); int max = Arrays.stream(arr).max().getAsInt(); 4. 정렬 / 수집 .sorted() : 정렬 .toArray() : 배열로 다시 변환 .collect(Collectors.toList()) : 리스트로 변환 예: String[] arr = {\"3\", \"1\", \"2\"}; List&lt;Integer&gt; list = Arrays.stream(arr) .map(Integer::parseInt) .sorted() .collect(Collectors.toList()); 5. forEach / joining .forEach(System.out::println) : 요소 출력 .collect(Collectors.joining(\" \")) : 문자열 합치기 예: String[] arr = {\"a\", \"b\", \"c\"}; String result = Arrays.stream(arr) .collect(Collectors.joining(\", \")); // \"a, b, c\" 🎯 이 문제를 Stream으로 풀면 이렇게도 가능 public String solution(String s) { IntSummaryStatistics stats = Arrays.stream(s.split(\" \")) .mapToInt(Integer::parseInt) .summaryStatistics(); // count, min, max, sum, average 한번에 return stats.getMin() + \" \" + stats.getMax(); } 👉 IntSummaryStatistics를 쓰면 최소값/최대값/합계/평균을 다 구할 수 있어서 깔끔! 💡 정리 비슷한 문제에서 빠르게 풀고 싶으면 최소한 아래 3개는 꼭 익혀두자: mapToInt(Integer::parseInt) min() / max() / sum() / average() summaryStatistics()",
    "tags": "java",
    "url": "/java/2025-09-12-stream/"
  },{
    "title": "[친구하자] 매칭 대기열 만들면서 정리한 Redis 명령어 치트시트 (SET/ZSET편)",
    "text": "카테고리별 2인 매칭을 구현하며 실제로 쓴(또는 고민했던) 명령어들을 짧게 정리. 예시 키는 {cat:123} 해시태그로 Redis Cluster 슬롯을 고정하는 패턴을 사용. ZSET (Sorted Set) — 순번/대기시간/우선순위가 필요할 때 ZADD key score member [score member ...] 멤버 추가/갱신. score가 작을수록 앞쪽. ZADD wait:z:{cat:123} 1725430000123 101 ZRANGE key start stop [WITHSCORES | REV | BYSCORE ...] 정렬 순서대로 조회. 삭제는 아님! ZRANGE wait:z:{cat:123} 0 1 # 가장 오래 기다린 2명 ZRANGE wait:z:{cat:123} 0 9 WITHSCORES # 상위 10명 + score ZRANK key member 멤버의 순위(0-base). ZRANK wait:z:{cat:123} 101 # 0이면 1번째 ZSCORE key member 멤버의 score(대기 시작 시각 등). ZSCORE wait:z:{cat:123} 101 ZCARD key 멤버 수. ZCARD wait:z:{cat:123} ZREM key member [member ...] 멤버 삭제. ZREM wait:z:{cat:123} 101 205 ZRANDMEMBER key [count] [WITHSCORES] (6.2+) 무작위 조회(삭제 아님). ZRANDMEMBER wait:z:{cat:123} 2 ZPOPMIN key [count] / ZPOPMAX 꺼내며 삭제(원자). 대기순 매칭에 유용. ZPOPMIN wait:z:{cat:123} 2 SET (집합) — 중복 없는 랜덤 풀 SADD key member [member ...] / SREM key member [...] 추가/삭제 (중복 불가). SADD matching:queue:{cat:123} 101 SREM matching:queue:{cat:123} 101 SPOP key [count] 무작위 추출+삭제(원자). 랜덤 매칭에 간단·빠름. SPOP matching:queue:{cat:123} 2 SCARD key 멤버 수. SCARD matching:queue:{cat:123} TTL/키 유틸 (대기 상태 자동 청소용) SET key value EX &lt;sec&gt; NX 선점 + TTL(중복 입장 방지). SET user:index:42 \"cat=123|queue=q_...\" EX 600 NX EXPIRE key &lt;sec&gt; / TTL key 키 만료/조회. 주의: TTL은 키 전체에 붙음(멤버 단위 X). 베스트 프랙티스: 대기열 컬렉션(SET/ZSET)엔 TTL 금지, 개별 사용자 상태 키에만 TTL. 매칭에서 자주 쓰는 레시피 1) 대기순(공정성) 매칭 방법 A(2단계): ZRANGE로 상위 N 조회 → ZREM로 제거 ZRANGE wait:z:{cat:123} 0 1 # 후보 조회 ZREM wait:z:{cat:123} 101 205 # 확정 후 제거 방법 B(원자): ZPOPMIN wait:z:{cat:123} 2 (조회+삭제가 한 번에) 2) 랜덤 매칭 ZSET만 쓸 때(원자화는 Lua 추천): ZRANDMEMBER로 조회 → 같은 로직 안에서 ZREM SET을 함께 쓸 때: SPOP matching:queue:{cat:123} 2 (원자 랜덤 추출) 3) 하이브리드(랜덤 80% + 대기순 20%) 하나의 Lua/Functions에서 분기: 랜덤: ZRANDMEMBER → ZREM 대기순: ZRANGE → ZREM (또는 ZPOPMIN) 4) 원자성 보장(동시성 안전) 조회(선정)와 삭제를 한 덩어리로: Lua/Functions로 감싸기 “이미 다른 워커가 먼저 가져간” 케이스를 **ZREM 반환값(0/1)**로 판단해 필터링. 흔한 실수 &amp; 주의 ZRANGE/ZRANDMEMBER 만 호출하고 ZREM을 빼먹음 → 큐에 그대로 남아 중복 매칭 발생. 컬렉션 키에 TTL을 걸어 전체 대기열이 사라짐. TTL은 개별 사용자 키(예: user:queued:{cat:123}:42)에만. Redis Cluster 사용 시, 스크립트 KEYS는 같은 해시태그({cat:123})로 묶기. 전역 키는 Lua에서 다루지 말고 자바에서만. 시간 복잡도 ZADD/ZREM/ZRANK ≈ O(log N) ZRANGE ≈ O(k) (반환 수) ZPOPMIN/MAX ≈ O(k log N) SADD/SREM/SPOP ≈ 평균 O(1) 미니 예시: 대기열 입장 &amp; 매칭 # 입장 ZADD wait:z:{cat:123} 1725430000456 101 # 대기 시작 시각(밀리초) SET user:queued:{cat:123}:101 q_101_123 EX 600 # 개별 TTL # 대기순 매칭 2명 (원자) ZPOPMIN wait:z:{cat:123} 2 # -&gt; [101,score],[205,score] # 랜덤 매칭 2명 (Lua로 원자화 권장) -- 조회 ZRANDMEMBER wait:z:{cat:123} 2 -- 같은 로직 안에서 제거 ZREM wait:z:{cat:123} 101 205 한 줄 정리 ZSET = 순번/대기시간/공정성, SET = 단순 랜덤 풀 ZRANGE/ZRANDMEMBER(조회) 뒤엔 반드시 ZREM(삭제) 경쟁 환경에선 Lua로 “조회→삭제”를 원자화 TTL은 개별 상태 키에만, 대기열 컬렉션엔 금지",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-09-03-diary/"
  },{
    "title": "[친구하자] 배치 스케줄러에서 @Transactional(REQUIRES_NEW)를 선택하기까지 — 실전 회고",
    "text": "“카테고리별 2인 랜덤 매칭”을 스케줄러로 돌리는데, 한 카테고리에서 예외가 나면 전체 루프가 롤백될 수 있다는 얘기를 듣고 시작된 고민. 그 결과 @Transactional(propagation = REQUIRES_NEW)를 채택했고, 다시 self-invocation 문제를 만나 리팩터링까지 갔던 과정을 정리했습니다. 배경: 매칭 스케줄러의 요구사항 여러 카테고리를 순회하며 매칭을 수행한다. 어떤 카테고리에서 실패해도 나머지는 정상 커밋되어야 한다(부분 성공). DB에 매칭 세션을 만들고, Redis 대기열을 정리하고, 알림을 보낸다. 처음엔 스케줄러 전체를 @Transactional로 감싸는 걸 고민했지만, 그러면 카테고리 하나의 실패가 전체 롤백으로 번질 수 있다. 그래서 트랜잭션 경계를 카테고리 단위로 쪼개야 했다. 옵션 검토: 왜 REQUIRES_NEW인가 REQUIRED: 바깥 트랜잭션이 있으면 같이 묶인다 → 부분 실패가 전체 롤백으로 확장될 위험. NESTED: 세이브포인트 기반. 바깥이 롤백되면 내부도 함께 롤백 → 부분 성공 보장 X. 비트랜잭션(NOT_SUPPORTED 등): DB 원자성 보장 X. REQUIRES_NEW: 항상 새 트랜잭션 시작, 외부 트랜잭션은 일시 중단 → 카테고리별 독립 커밋을 정확히 충족. 결론: 내 요구(카테고리별 완결·부분 성공)를 가장 잘 만족시키는 건 REQUIRES_NEW. 첫 번째 벽: “self-invocation” 경고 스케줄러 코드 초안: @Scheduled(fixedDelay = ...) public void processMatching() { for (Category category : activeCategories) { processMatchingForCategory(category); // 내부 메서드 호출 } } @Transactional(propagation = Propagation.REQUIRES_NEW) protected void processMatchingForCategory(Category category) { ... } 경고 메시지: @Transactional self-invocation ... does not lead to an actual transaction at runtime 왜 이런가? Spring의 @Transactional은 프록시 기반 AOP다. 같은 객체 내부에서 자기 메서드를 직접 호출하면 프록시를 우회하므로 트랜잭션이 적용되지 않는다. 접근 제어자(private→protected) 변경으로는 해결되지 않는다. 본질은 프록시를 타느냐이다. 해결: 트랜잭션 경계를 “다른 빈의 public 메서드”로 분리 리팩터링 전/후 Before: 스케줄러 클래스 내부에서 processMatchingForCategory 호출 → 프록시 미적용 After: 별도의 서비스 빈으로 분리 + public 메서드에 @Transactional(REQUIRES_NEW) 스케줄러는 “그 빈을 주입 받아 호출” → 프록시를 경유하므로 트랜잭션 정상 적용 // A. 카테고리 단위 워커 (새 트랜잭션 경계) @Service @RequiredArgsConstructor public class CategoryMatchWorker { private final RedisMatchingQueueService redisMatchingQueueService; private final UserRepository userRepository; private final CallRepository callRepository; // ... 필요한 의존성 @Transactional(propagation = Propagation.REQUIRES_NEW) public void processCategory(Category category) { // 카테고리 하나에 대한 모든 DB 작업 (예외 → 이 트랜잭션만 롤백) // 1) 대기 인원 확인 → 2) 하이브리드 매칭 → 3) 사용자 조회 검증 // 4) Call 생성/저장 → 5) 큐 상태 업데이트 → 6) 알림 예약(afterCommit) } } // B. 스케줄러 (비트랜잭션; 실패해도 루프 계속) @Service @RequiredArgsConstructor public class MatchingSchedulerService { private final CategoryMatchWorker categoryMatchWorker; private final CategoryRepository categoryRepository; @Scheduled(fixedDelay = ...) public void processMatching() { var categories = categoryRepository.findByIsActiveTrueOrderByName(); for (Category category : categories) { try { categoryMatchWorker.processCategory(category); // 프록시 경유 OK } catch (Exception e) { log.warn(\"카테고리 {} 처리 실패 - 다음으로 진행\", category.getId(), e); } } } } 대안으로 TransactionTemplate(프로그래매틱 트랜잭션)도 있다. 카테고리마다 PROPAGATION_REQUIRES_NEW로 실행 블록을 감싸는 방식. 프록시 우회 이슈가 없다. Redis와의 경계: “한 트랜잭션이 아니다” DB와 Redis는 동일 트랜잭션 경계가 아님(2PC 안 쓰는 한). 안전한 순서: DB 커밋 성공 후(트랜잭션 경계 밖) Redis/PubSub/WebSocket 등 사이드 이펙트 수행 Spring에선 TransactionSynchronizationManager.registerSynchronization(... afterCommit) 훅으로 구현 가능 TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization() { @Override public void afterCommit() { // DB 커밋이 확정된 뒤에만 알림/이벤트 발행 webSocketEventService.notifyMatchingSuccess(...); } }); 내가 얻은 체크리스트 부분 성공이 목표면 트랜잭션을 **처리 단위(여기선 카테고리)**로 쪼갠다. REQUIRES_NEW는 외부와 분리된 커밋/롤백을 보장한다. @Transactional은 프록시 기반 → 자기 자신 호출은 적용되지 않는다. 트랜잭션 메서드는 public + 다른 빈으로 분리해 호출. 또는 TransactionTemplate로 명시 제어. 롤백 규칙을 의도대로: 체크 예외까지 롤백이면 rollbackFor = Exception.class. Redis/메시징은 DB 트랜잭션과 별개 → afterCommit에 배치. 멱등성·재시도·처리상태 플래그를 준비(일부 성공/일부 실패가 정상인 아키텍처). 최종 결론 스케줄러 루프 전체를 하나의 트랜잭션으로 묶는 대신, **카테고리별로 REQUIRES_NEW**를 적용해 부분 성공과 격리를 확보한다. 이때 @Transactional이 실제로 동작하려면 프록시를 타야 하므로, 트랜잭션 메서드는 다른 빈의 public 메서드로 분리한다. DB 커밋 이후에만 외부 부작용(알림/Redis)을 발생시키는 흐름으로 정합성을 지킨다. 이 과정을 거치면서 “왜 REQUIRES_NEW인가?”에 더해 “어디에, 어떻게 붙여야 실제로 동작하는가”를 체득했다. 스프링의 트랜잭션은 어노테이션 한 줄이 아니라, 경계 설계 + 호출 구조까지 포함한 문제였다. Redis.. 어렵다.. 참고 Redis programmability You Don’t Need Transaction Rollbacks in Redis Transactional REQUIRES_NEW 옵션에서 예외 및 Rollback",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-08-29-diary/"
  },{
    "title": "[친구하자] 매칭 대기열 설계 기록 : 왜 DB + Redis 하이브리드로 갔나",
    "text": "문제 배경 TL;DR 1. 내가 왜 이런 고민을 하게 됐나 2. 현재 구현의 문제 정리 (Redis 단독일 때) 3. 하이브리드 설계 원칙 4. 개선된 데이터 흐름 5. Redis 자료구조 선택과 이유 6. 원자적 매칭: Lua 스크립트 예시(개념) 7. 복구 메커니즘(서버 재기동/장애 대비) 8. 스키마/인덱스 설계 9. 시스템 구성(개념 아키텍처) 10. 실무에서의 선택지 비교 11. 테스트/운영 시나리오 12. 내가 배운 점 &amp; 선택의 근거 13. Next Steps (로드맵) 부록 A. 코드 스니펫(개념) “대기열=실시간성, 기록/분석/복구=영속성.” 이 두 욕심을 동시에 만족시키려다 보니 하이브리드(DB+Redis)가 자연스럽게 답이 되었다. 문제 배경 친구하자 구현 중 핵심인 통화 매칭 부분을 구현하는 중이였다. 초반 설계에서는 Redis만 사용해서 구현하기로 하여 하고있었는데, 이렇게 하면 대기열 기록이 되지않아 나중에 시스템 분석 및 복구에 어려움이 있어보였다. 따라서 DB와 함께 구현하는 방식이 많이 사용되는 방식인지, 어떤 부분에 장단점이 있고 고려해야하는 부분은 어떤 것인지 궁금했다. 또한 관련되서 더 심화된 기술은 어떤 것이 있는지 알아보고싶었다. TL;DR 문제의식: Redis만 쓰면 빠르지만 휘발성·운영/분석/복구가 약하다. DB만 쓰면 영속적이지만 지연·경합에 취약하다. 결론: DB(사실의 원천, 이력/분석/복구) + Redis(실시간 대기열/매칭) 를 분리한 하이브리드 구조. 실무 팁: 아웃박스 패턴으로 이중 쓰기 일관성, Redis ZSET+Lua로 원자적 매칭, 멱등키/TTL/청소잡/AOF+복제로 운영 내구성 확보. 대안: 규모·요구사항에 따라 Redis Streams, RabbitMQ, Kafka, SQS, Postgres SKIP LOCKED도 선택지. 1) 내가 왜 이런 고민을 하게 됐나 (맥락) 친구하자는 1분 내 매칭 같은 저지연 실시간성이 핵심이다. 그래서 처음엔 Redis 단독이 끌렸다. 하지만 곧바로 다음 현실에 부딪혔다. 휘발성 vs 영속성: Redis는 빠르지만(메모리) 장애/재시작 시 데이터 유실 리스크. 운영/디버깅: 매칭 실패/타임아웃/취소 이슈를 재현하고 원인 추적하려면 이력 테이블이 꼭 필요. 통계/제품개선: 카테고리별 대기시간·매칭률·시간대 부하 같은 지표는 DB가 편하다. 복구 시나리오: 서버/Redis 재기동 시 “누가 줄에 서 있었나?” 를 복원하려면 DB에 근거가 있어야 한다. 결국 “실시간 처리=Redis”, “이력/분석/복구=DB”로 역할을 나누는 하이브리드가 합리적이라는 결론에 도달했다. 2) 현재 구현의 문제 정리 (Redis 단독일 때) 데이터 영속성: 서버/Redis 재시작 시 대기열 유실 가능 통계/분석 취약: 매칭 히스토리/패턴 분석이 어려움 디버깅 곤란: 실패 재현·CS 대응 근거 부족 복구 어려움: 장애 시 대기열/상태 재구성이 힘듦 3) 하이브리드 설계 원칙 (1) 단일 출처(Single Source of Truth, SOT) 명확화 대기열의 SOT = Redis (실시간 기준) 이력/상태의 SOT = DB (사실 기준) (2) 일관성 경계 정의 두 저장소에 언제/어떤 순서로 쓸지 고정. 권장: DB 트랜잭션으로 matching_queue(WAITING) + 아웃박스 이벤트를 함께 기록 → 워커가 Redis에 enqueue (재시도 가능) (3) 멱등성/중복 방지 사용자 중복 등록 방지: SET user:{id}:queued 1 NX EX 600 매칭 결과 멱등 업데이트: match_id UNIQUE 제약 등 4) 개선된 데이터 흐름 참가(Enqueue): DB 트랜잭션: matching_queue(WAITING) + outbox(enqueue_event) Outbox Consumer가 Redis ZSET에 등록 매칭(Match): Redis에서 원자적으로 두 명을 Pop (Lua 스크립트) DB에 MATCHING → MATCHED 상태 전이(멱등) 통계/리포트: DB 이력 기반 분석/대시보드 실시간 조회: Redis 대기열 길이, 평균 대기시간(샘플링) 즉시 응답 5) Redis 자료구조 선택과 이유 ZSET(정렬집합) 권장 score = 대기 시작 시각 or 우선순위 공정성(FCFS)/우선순위/타임아웃 처리 쉽다. 꺼낼 때 원자성을 위해 Lua 스크립트 사용. 덧붙임 SET NX로 중복 등록 방지 HASH(queue:{queueId})로 사용자·카테고리·TTL 메타 저장 TTL + 정리잡으로 고아 항목 청소 단순 리스트(LLEN/LPOP)는 쉽지만 공정성·타임아웃·중복 제어를 구조적으로 풀기 어렵다. Streams는 컨슈머 그룹/ACK로 내구성이 좋지만 매칭 “쌍짓기”엔 별도 설계가 필요. 6) 원자적 매칭: Lua 스크립트 예시(개념) -- KEYS[1]=zset key, ARGV[1]=score(복원용) local k = KEYS[1] local a = redis.call('ZRANGE', k, 0, 0) if #a == 0 then return {} end redis.call('ZREM', k, a[1]) local b = redis.call('ZRANGE', k, 0, 0) if #b == 0 then -- 짝이 없으면 되돌리기 redis.call('ZADD', k, ARGV[1], a[1]) return {} end redis.call('ZREM', k, b[1]) -- 필요 시 락/마킹/TTL 등 추가 return {a[1], b[1]} 실전에서는 되돌리기/락/타임아웃/카테고리 필터까지 넣어야 한다. 7) 복구 메커니즘(서버 재기동/장애 대비) Redis는 AOF(append-only) + 영속 볼륨 + 복제/센티넬로 내구성 강화 그래도 안전망으로 “최근 WAITING만 DB→Redis 재적재” 수행 // 서버 기동 시 안전 복구(개념) @PostConstruct public void recoverQueuesFromDatabase() { var active = matchingQueueRepository.findByQueueStatusAndCreatedAtAfter( QueueStatus.WAITING, LocalDateTime.now().minusMinutes(10) ); active.forEach(queue -&gt; { // Redis 재적재 로직(ZSET + 메타 HSET 등) }); } 운영에선 ApplicationRunner + 분산락으로 중복 복구 방지를 권장. 8) 스키마/인덱스 설계 matching_queue id, user_id, category, status(WAITING/MATCHING/MATCHED/EXPIRED/CANCELLED), created_at, updated_at 인덱스: (status, created_at), (user_id, status) match_events match_id(UNIQUE), user_a, user_b, started_at, ended_at, result, reason 멱등키: match_id UNIQUE outbox event_id, type, payload, created_at, processed_at NULLABLE 워커가 processed_at IS NULL만 읽고 성공 시 채움(재시도 가능) 9) 시스템 구성(개념 아키텍처) [API] ──(Tx)──&gt; [DB] ──(Outbox)──&gt; [Outbox Consumer] ──&gt; [Redis ZSET] │ │ └──────────────(조회/이력)──────────────────────┘ [Matching Worker] &lt;──&gt; [Redis ZSET + Lua + TTL] │ │ └────(멱등 업데이트)──────&gt; [DB: 상태/이력] 운영 필수 체크: Redis AOF + 복제/센티넬 아웃박스/재시도로 DB↔Redis 일관성 보장 SET NX/TTL/청소잡/분산락 대기열 길이/평균 대기시간/타임아웃률/매칭 성공률 메트릭 enqueue/match/cancel/timeout 이벤트 로깅 10) 실무에서의 선택지 비교 시나리오 권장 스택 핵심 포인트 저지연 실시간 매칭 (MVP~중규모) Redis (ZSET/Streams) + DB 속도·복잡도 밸런스 좋음 내구성 높은 큐/재처리/다중소비자 Redis Streams or RabbitMQ + DB ACK/리트라이/가시성 타임아웃 쉬움 대규모 분산/리플레이 Kafka (+ Redis 캐시) 파티셔닝·재처리 강점, 매칭 로직은 앱에서 아주 단순/저QPS Postgres (FOR UPDATE SKIP LOCKED) 운영 단순, 지연·경합은 감수 관리형 간단 큐 SQS 쉬움+내구성, 초저지연 매칭은 보완 필요 친구하자의 “1분 내 매칭·공정성·운영 용이성” 기준에선 현재 Redis ZSET + DB가 가장 적합. 추후 트래픽 급증 시 Streams/Kafka로 확장 가능. 11) 테스트/운영 시나리오 부하 테스트: 카테고리별 동시 1k~5k 등록, 평균/95p 대기시간, 매칭 성공률 측정 경합 테스트: 동시 매칭 워커 2~10개, 중복 매칭/유실 여부 장애 시나리오: Redis 재시작, 네트워크 분리, DB 쓰기 실패 시 재시도 동작 복구 리허설: DB→Redis 재적재 로직의 멱등성/중복 방지 검증 12) 내가 배운 점 &amp; 선택의 근거 실시간성만 보면 Redis 단독이 매력적이지만, 운영·분석·복구까지 생각하면 DB 하이브리드가 필수. 단일 출처를 나누고(대기열=Redis, 이력=DB), 이중 쓰기 일관성(아웃박스/재시도)을 확보하면 MVP 이후에도 확장 가능한 길이 열린다. Redis에선 ZSET + Lua가 공정성/타임아웃/원자성을 한 번에 잡는 실전 해법이었다. 13) Next Steps (로드맵) 아웃박스 컨슈머 도입 및 재시도/백오프 Lua 스크립트에 락/타임아웃/복원 로직 보강 AOF+복제/센티넬 운영화 메트릭/알람: 대기열 길이·대기시간·타임아웃률·에러율 트래픽 증가 시 Streams 도입 검토(컨슈머 그룹 기반), 더 커지면 Kafka 병행 부록 A. 코드 스니펫(개념) DB → Outbox 트랜잭션 @Transactional public void enqueue(Long userId, String category) { MatchingQueue q = matchingQueueRepository.save( MatchingQueue.waiting(userId, category) ); outboxRepository.save(OutboxEvent.enqueue(q.getId(), category)); } Outbox Consumer → Redis public void handle(OutboxEvent e) { String key = \"mq:\" + e.getCategory(); // 중복 방지 Boolean ok = redis.setIfAbsent(\"user:\" + e.getUserId() + \":queued\", \"1\", Duration.ofMinutes(10)); if (Boolean.TRUE.equals(ok)) { redis.zAdd(key, e.getEnqueuedAt().toEpochSecond(ZoneOffset.UTC), e.getQueueId().toString()); } outboxRepository.markProcessed(e.getId()); } 마무리 이번 설계는 “현재 요구(저지연)”와 “미래 요구(운영/분석/복구/확장)”를 동시에 충족시키기 위한 균형점을 찾는 과정이었다. DB+Redis 하이브리드는 그 균형점 위에서 실무적으로 검증된 길이며, MVP에서 시작해 Streams/Kafka로 확장 가능한 진화 경로를 갖는다. 친구하자의 성격(실시간 매칭 + 장기 운영/분석 필요)에 정합한 선택이라고 생각한다.",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-08-25-diary/"
  },{
    "title": "[JAVA] Queue는 왜 안되고 Queue는 왜 될까?",
    "text": "record란? record의 특징 기존 클래스 vs record 비교 record 내부 동작 record 주요 기능 record 사용 방법 정리 왜 Queue&lt;int&gt;는 안 되고 Queue&lt;Integer&gt;는 될까? Java 제네릭을 쓰다 보면 한 번씩 멈칫하게 되는 질문입니다. “왜 Queue&lt;int&gt;는 안 되는데 Queue&lt;Integer&gt;는 되지?” 이 글은 그 이유를 **타입 소거(type erasure)**와 참조 타입만 허용하는 제네릭 규칙에서 차근차근 풀어 설명합니다. 실전 성능 팁과 BFS 같은 알고리즘 코드 패턴도 함께 담았습니다. 정리 제네릭 타입 인자(T)는 참조 타입만 가능합니다. (T extends Object가 암묵적 전제) 타입 소거로 인해 런타임에는 제네릭 정보가 지워지고, 메서드 시그니처가 사실상 Object 기반으로 동작합니다. int 같은 원시 타입(primitive) 은 Object가 아니므로 제네릭 인자로 쓸 수 없습니다. ⇒ Queue&lt;int&gt; 금지 배열은 참조 타입이므로 Queue&lt;int[]&gt;는 가능합니다. (배열 자체는 객체) 알고리즘 큐에는 int[] 또는 record/class로 상태를 묶어 넣으면 박싱 없이 빠르고 메모리 친화적입니다. 1) 제네릭은 왜 쓰나? 컴파일 타임에 타입을 체크해 타입 안전성을 높이고, 캐스트를 없애 가독성과 유지보수성을 올리기 위해서입니다. 제네릭에 대해 정리한 블로그 글 참고 // 제네릭 없음: 캐스트 필요 List list = new ArrayList(); list.add(\"hi\"); String x = (String) list.get(0); // 제네릭 사용: 컴파일 타임에 체크, 캐스트 제거 List&lt;String&gt; list2 = new ArrayList&lt;&gt;(); list2.add(\"hi\"); String y = list2.get(0); 2) 타입 소거(type erasure)란? 자바의 제네릭은 런타임에 사라집니다. 컴파일러가 제네릭 코드를 검사·보정한 뒤, 실행 시점에는 타입 매개변수를 지운(Object로 대체한) 형태로 동작합니다. 개념적으로 다음과 같습니다. // 원본 class Box&lt;T&gt; { void put(T x) { /* ... */ } T get() { /* ... */ } } // (개념적) 컴파일 후 - T가 지워지고 Object 중심으로 class Box { void put(Object x) { /* ... */ } Object get() { /* ... */ } } 컴파일러가 캐스트 삽입과 오토박싱/언박싱으로 타입 안전을 보정해 줍니다(필요 시 브리지 메서드도 생성). 3) T는 왜 ‘참조 타입’만 될 수 있나? 자바 언어 규칙상 **모든 타입 매개변수는 암묵적으로 T extends Object**로 취급됩니다. Integer, String, MyClass 같은 참조 타입(reference type) 은 Object의 하위 타입이므로 OK. int, double, boolean 같은 원시 타입(primitive) 은 Object가 아니므로 제네릭 타입 인자로 금지됩니다. 즉, Queue&lt;int&gt;는 언어 차원에서 성립하지 않습니다. 포인트: 타입 소거 후의 세계는 Object 중심이라, 그 세계로 들어올 수 있는 타입(=참조 타입)만 제네릭 인자가 될 수 있습니다. 4) 그렇다면 Queue&lt;Integer&gt;는 왜 되나? Integer는 int의 래퍼 클래스(참조 타입)입니다. 제네릭 인자로 쓸 수 있고, q.offer(1)처럼 쓰면 오토박싱이 자동으로 일어나 int -&gt; Integer가 됩니다. Queue&lt;Integer&gt; q = new ArrayDeque&lt;&gt;(); q.offer(1); // int가 Integer로 오토박싱 int v = q.poll(); // Integer가 int로 언박싱 단, 이 과정은 객체 할당/GC 비용이 들 수 있습니다. 대량 연산에서는 체감될 수 있어요. 5) Queue&lt;int[]&gt;는 왜 가능한가? 배열은 항상 참조 타입입니다. 원소가 원시 타입이든 말든, 배열 자체는 힙 객체니까 제네릭 인자로 사용 가능해요. Queue&lt;int[]&gt; q = new ArrayDeque&lt;&gt;(); q.offer(new int[]{1,2,3}); // 배열 참조를 넣음 int[] arr = q.poll(); 6) 성능·메모리 관점: 오토박싱을 피하자 Queue&lt;Integer&gt;는 원소마다 Integer 객체가 생길 수 있어 오토박싱/언박싱 비용 객체 헤더 + 포인터 오버헤드 GC 부담 이 발생합니다. 알고리즘(특히 BFS/DFS, 다익스트라 등)에서는 박싱을 피하는 게 유리합니다. 권장 1) int[]로 상태 묶기 (가볍고 빠름) // {r, c, breakUsed, dist} ArrayDeque&lt;int[]&gt; q = new ArrayDeque&lt;&gt;(); q.offer(new int[]{0, 0, 0, 1}); int[] cur = q.poll(); int r = cur[0]; 권장 2) record로 가독성 ↑ (Java 16+) record State(int r, int c, int b, int d) {} ArrayDeque&lt;State&gt; q = new ArrayDeque&lt;&gt;(); q.offer(new State(0, 0, 0, 1)); State s = q.poll(); 팁: 큐 구현체는 **ArrayDeque**가 일반적으로 LinkedList보다 빠르고 메모리 효율적입니다. 7) 실전 FAQ Q1. “런타임에 진짜 Queue&lt;Object&gt;로 동작하나요?” 개념적으로는 그와 유사합니다(타입 소거). 실제로는 컴파일러가 캐스트/브리지 메서드 등으로 타입 안전을 맞춰 줍니다. 핵심은 런타임에 타입 인자 정보가 없고 Object 중심으로 호출된다는 점입니다. Q2. 그렇다면 왜 컴파일러가 Queue&lt;int&gt;도 자동으로 Queue&lt;Integer&gt;로 바꿔주지 않나요? 언어 규칙상 제네릭 인자는 참조 타입만 허용합니다. 타입 인자 자체를 바꾸는 묵시적 변환은 설계상 모호성과 함정(예: T가 원시로 선언됐는데 실제론 참조로 다뤄짐)을 낳기에 금지됩니다. 명시적으로 Integer를 써 주세요. Q3. 원시 타입 컬렉션이 꼭 필요합니다. 방법이 없나요? 표준 라이브러리는 제공하지 않지만, 전용 라이브러리가 있습니다. fastutil (IntArrayList, IntOpenHashSet, …) HPPC (High Performance Primitive Collections) Eclipse Collections (primitive collections) 대량 데이터·고성능 시나리오에서 유용합니다. 8) BFS 예시: 박싱 없이 깔끔하게 아래는 “벽을 한 번만 부술 수 있는” BFS 패턴입니다. int[]로 상태를 묶어 박싱을 회피합니다. import java.io.*; import java.util.*; public class Main { static final int[] dr = {1, -1, 0, 0}; static final int[] dc = {0, 0, 1, -1}; public static void main(String[] args) throws Exception { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); int N = Integer.parseInt(st.nextToken()); int M = Integer.parseInt(st.nextToken()); int[][] map = new int[N][M]; for (int i = 0; i &lt; N; i++) { String line = br.readLine(); for (int j = 0; j &lt; M; j++) map[i][j] = line.charAt(j) - '0'; } boolean[][][] visited = new boolean[N][M][2]; ArrayDeque&lt;int[]&gt; q = new ArrayDeque&lt;&gt;(); q.offer(new int[]{0, 0, 0, 1}); // r, c, breakUsed, dist visited[0][0][0] = true; int ans = -1; while (!q.isEmpty()) { int[] cur = q.poll(); int r = cur[0], c = cur[1], b = cur[2], d = cur[3]; if (r == N - 1 &amp;&amp; c == M - 1) { ans = d; break; } for (int k = 0; k &lt; 4; k++) { int nr = r + dr[k], nc = c + dc[k]; if (nr &lt; 0 || nr &gt;= N || nc &lt; 0 || nc &gt;= M) continue; if (map[nr][nc] == 0) { if (!visited[nr][nc][b]) { visited[nr][nc][b] = true; q.offer(new int[]{nr, nc, b, d + 1}); } } else if (b == 0 &amp;&amp; !visited[nr][nc][1]) { visited[nr][nc][1] = true; q.offer(new int[]{nr, nc, 1, d + 1}); } } } System.out.println(ans); } } 9) 한눈에 요약 체크리스트 제네릭 인자 = 참조 타입만 (암묵적 T extends Object) 런타임 = 타입 소거 (제네릭 정보 없음, Object 중심) Queue&lt;int&gt; ❌, Queue&lt;Integer&gt; ⭕ Queue&lt;int[]&gt; ⭕ (배열은 참조 타입) 성능 중요: 박싱 피하기 (가능하면 int[]/record 사용) 큐 구현체는 보통 ArrayDeque 추천 마무리 Queue&lt;int&gt;가 금지되는 이유는 단순히 “문법이 그렇다”가 아니라, 타입 소거라는 실행 모델과 참조 타입만 허용하는 제네릭 설계가 맞물린 결과입니다. 오늘부터는 알고리즘에서 박싱 없는 상태 표현으로 깔끔하고 빠른 코드를 써 보세요!",
    "tags": "java",
    "url": "/java/2025-08-25-queue-int/"
  },{
    "title": "[TIL] A/B 테스트",
    "text": "📝 TIL (Today I Learned) 📅 작성일: 2025-08-23 🔄 최종 수정: 2025년 08월 25일 🍀 새롭게 배운 것 A/B 테스트란? 정의: 같은 목표를 두고 두 버전(A=기준, B=변경안) 을 동시에 무작위로 사용자에게 나눠 보여준 뒤, 어느 쪽이 더 성과가 좋은지 통계적으로 비교하는 실험. 목적: 느낌/감이 아니라 데이터로 의사결정. 버튼 문구, 화면 배치, 가격 제안, 푸시 타이밍 등 “실제로” 지표가 개선되는지 검증. 기본 용어 변수(Variant): A(컨트롤) vs B(실험안). 3개 이상이면 A/B/n. 지표(Metric): 실험의 목표(예: 등록 전환율, 1일차 잔존, 통화 완료율). 유의수준 α: 오탐 허용(보통 0.05). 검정력 Power(1−β): 진짜 차이가 있을 때 잡아낼 확률(보통 0.8). MDE(최소 검출 가능 효과): “이 정도 차이는 나야 성공이라 본다” 최소 개선 폭(예: +2%p). 어떻게 하는가 (실전 절차 7단계) 가설 세우기 예) “대기시간 안내 문구를 바꾸면 매칭 시작 클릭률이 ↑한다.” 지표 딱 하나만 주지표로 주지표: 매칭 시작 클릭률 보조지표(가드레일): 이탈률, 고객불만 접수율 등 “부작용 체크” 표본수(기간) 계획 대략의 규칙: 차이를 작게 보고 싶을수록, 베이스 전환율이 낮을수록 → 더 많은 트래픽/기간이 필요. (참고 공식 – 이해만): 비율형 지표의 각 그룹 표본수 n ≈ 2 * (zα/2 + zβ)^2 * p̄(1-p̄) / Δ^2 p̄: 기준 전환율 추정, Δ: 검증하고 싶은 차이(절대값) 무작위 배정 &amp; 고정 사용자 단위로 50/50 랜덤 분배(세션/페이지뷰 단위 X). 실험 중엔 변형하지 말기(중간에 디자인을 또 바꾸지 않기). 정확한 로깅 모든 이벤트에 experiment_id, variant(A/B) 파라미터를 함께 로깅. SRM(sample ratio mismatch) 체크: 50/50이 크게 깨지면(예: 60/40) 실험 무효. 기간 고정 &amp; ‘엿보기’ 금지 종료 조건 전에 유의성만 보고 중단하면 거짓 양성↑. 꼭 필요하면 사전 정의된 순차검정(group-sequential)이나 베이즈 접근을 사용. 해석 &amp; 롤아웃 통계 유의 + 실무 유의(임팩트/비용/부작용) 함께 본 뒤, 점진적 롤아웃(예: 10%→30%→100%). GA4/앱에서 바로 쓰는 구성 팁 이벤트 설계 예: event_name: start_match_click 파라미터: experiment_id: \"wait_copy_v1\" variant: \"A\"|\"B\" 사용자 ID 또는 설치 ID(사용자 기준 배정 유지) 빅쿼리 연동 시 쿼리로 variant별 전환율 비교가 쉬워짐. SRM 빠른 체킹: 실시간 대시보드에서 A/B 트래픽이 49–51% 근처인지 확인. A/B 테스트 3가지 예시 대기시간 안내 문구 A: “곧 연결됩니다” B: “평균 30초 내 연결됩니다 · 취소 가능” 주지표: start_match_click / 방문자 가드레일: 즉시 이탈률, 고객불만 통화 후 피드백 수집 방식 A: 5점 척도만 B: 5점 + “칭찬 한마디” 한줄 텍스트 주지표: 피드백 제출률 가드레일: 피드백 작성 시간, 다음날 재방문율 안심케어(유료) 소개 타이밍 A: 첫 3회 통화 후 페이월 B: 첫 1회 통화 후 페이월 주지표: 7일 내 결제 전환율 가드레일: 7일 유지율, 평균 통화시간 변화 설계 체크리스트 (붙여넣어 쓰기) 가설과 주지표 1개 명확 MDE와 기간/표본수 사전 정의 사용자 단위 랜덤 배정 + 고정 experiment_id / variant 로깅 SRM 모니터링 중도 엿보기 금지(혹은 순차검정 채택) 통계 유의 + 비즈니스 유의 함께 판단 롤아웃/롤백 플랜 준비 자주 하는 실수 여러 요소를 한꺼번에 바꾸기 → 원인 분리 불가 주지표를 여러 개로 두기 → 해석 혼란 세션/페이지뷰 단위 랜덤화 → 사용자 경험이 섞여 오염 주중/주말, 마케팅 캠페인 겹침 시즌성 영향 무시 결과가 좋게 나올 때까지만 계속 엿보기 (참고) 빈도주의 vs 베이즈 빈도주의: p-value/신뢰구간, 고정 표본 설계에 적합. 베이즈: “B가 A보다 좋을 확률”처럼 직관적 해석과 순차적 의사결정에 유리. 둘 다 장단점 있어요—팀의 익숙함/툴링에 따라 선택.",
    "tags": "TIL Git ML til",
    "url": "/til/2025-08-23-til/"
  },{
    "title": "[친구하자] Hidden Technical Debt in Machine Learning Systems",
    "text": "1. 오늘 읽은 내용 요약 2. 나에게 필요했던 이유 — 친구하자 적용 사례 3. 느낀 점 &amp; 인사이트 4. 다음 액션 아이템 💡 핵심 요약 이번에는 서울 AI 허브 특강을 듣다가 알게 된 ML관련 논문을 읽고 지금 하고있는 “친구하자” 프로젝트의 어떤 부분에서 도움을 받을 수 있을지에 대해 알아보았다. 논문: [Hidden Technical Debt in Machine Learning Systems (NIPS 2015)] 작성자: D. Sculley외 10인 (Google, Inc.) 논문에 대한 TIL 작성 1. 오늘 읽은 내용 요약 핵심 주제: 머신러닝 시스템에서는 단순히 모델 성능을 높이는 것보다 데이터 흐름 관리, 파이프라인 구조, 의존성 관리가 더 중요하다는 점을 강조. 기술 부채(Technical Debt) ML 시스템은 빠르게 개발 가능하지만, 장기 유지보수 비용은 전통적인 소프트웨어보다 훨씬 높음. 숨은 부채는 코드 수준이 아니라 시스템 수준에서 쌓이기 때문에 발견하기 어렵고 비용이 급격히 커짐. 주요 이슈와 원인 CACE 원칙 (Changing Anything Changes Everything) 피처, 하이퍼파라미터, 데이터셋 중 하나만 바꿔도 전체 모델 성능이 예측 불가능하게 바뀜. 데이터 의존성 불안정한 입력 신호, 중복 피처, 과도한 데이터 연결은 장애 가능성을 높임. Pipeline Jungle 데이터 전처리 단계가 쌓이면 유지보수가 어려워지고 에러 포인트가 증가. 모델 간 숨은 피드백 루프 하나의 모델 변경이 다른 시스템의 입력 데이터에 간접적으로 영향을 미침. 실시간 모니터링 부족 모델 업데이트 후 이상 징후를 늦게 발견하면 복구 비용이 기하급수적으로 커짐. 2. 나에게 필요했던 이유 — 친구하자 적용 사례 (1) 발화/화행 분석 모델 파이프라인 설계 시 고려할 점 현재 시나리오 통화 음성 → 스펙트로그램 변환 → 감정/화행 분석 모델 → 사용자 인지 지표 산출 향후 AI 기반 발화 분석 모델을 도입해 지남력, 유창성, 어휘력, 주의집중력 등의 점수를 자동 산출할 계획. 적용 포인트 데이터 버저닝 필요성 예: 스펙트로그램 생성 방식을 바꿀 경우, 기존 학습 데이터와 호환성이 깨질 수 있음. → DVC나 MLflow 같은 도구를 도입해 음성 데이터, 스펙트로그램, 학습된 모델을 버전 단위로 관리해야 함. Pipeline Jungle 방지 현재는 음성 → 텍스트 → 감정 점수 산출이라는 단순 구조지만, 향후 발화 분석, 화행 분석, 치매 위험 예측까지 추가되면 중간 파이프라인이 폭발적으로 늘어남. → 파이프라인을 계층적으로 나누고, 데이터 입출력 포맷을 표준화하는 설계가 필요. (2) 실시간 통화 분석 시스템 설계 시 고려할 점 현재 시나리오 WebRTC 기반 통화 → 통화 녹음 → 분석 API 호출 → 사용자/보호자 알림 향후 실시간 음성 분석을 통해 통화 중 인지 저하, 우울감 등 감지 시 알림을 제공하는 기능을 목표. 적용 포인트 실시간 피처 드리프트 모니터링 예: 고령 사용자들의 발화 속도나 어휘 다양성이 계절, 이벤트에 따라 달라질 수 있음. → 실시간으로 데이터 분포 변화를 감시해 학습 데이터와 입력 데이터의 괴리를 탐지하는 모니터링 필요. 모델 업데이트 전략(A/B Testing) 새로운 화행 분석 모델을 도입할 때, 전체 사용자에게 바로 적용하면 위험. → 전체 롤아웃 전 소규모 샘플 그룹에서 먼저 성능을 검증하고, 이상 징후 시 자동 롤백하는 시스템 필요. 경계 침식 문제 해결 통화 감정 분석 결과가 다른 추천 시스템(예: 대화 주제 추천)에도 입력될 경우, 모델 간 강한 의존성이 생김. → API 수준에서 의존성 추적 및 제어 기능을 설계해 시스템 분리를 유지해야 함. 3. 느낀 점 &amp; 인사이트 발화/화행 분석 모델처럼 실시간 데이터 기반 ML 시스템은 전통적인 오프라인 예측 모델보다 훨씬 기술 부채 리스크가 큼. 특히 이 논문에서 제시한 CACE 원칙을 그대로 체감할 수 있음: “스펙트로그램 해상도만 살짝 바꿨는데 전체 감정 분석 성능이 붕괴될 수도 있다.” 결론적으로, 친구하자에서는 모델 성능 향상보다 데이터/파이프라인 안정성을 우선시해야 함. 모델 버저닝, 실시간 모니터링, A/B 테스트, 피처 관리 자동화는 반드시 초기에 설계해야 장기 비용을 줄일 수 있음. 4. 다음 액션 아이템 DVC/MLflow 도입 → 발화/화행 분석 모델, 음성 데이터, 스펙트로그램 버전 관리 데이터 파이프라인 표준화 → 입력/출력 포맷 및 계층 구조 설계 실시간 데이터 분포 모니터링 및 알림 시스템 구축 A/B 테스트 기반 모델 롤아웃 전략 설계 및 자동 롤백 기능 구현 서비스 아키텍처에 모델 간 의존성 추적 기능 추가 💡 핵심 요약 친구하자의 실시간 발화/화행 분석 시스템에서 기술 부채를 최소화하려면: 버전 관리: 데이터·모델·파이프라인을 모두 버전 단위로 관리 모니터링: 실시간 데이터 드리프트 및 예측 이상 징후 자동 탐지 분리 설계: 모델 간 강한 의존성 최소화 안전한 업데이트: A/B 테스트 기반 롤아웃 + 자동 롤백 전략 필수",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-08-17-diary/"
  },{
    "title": "[TIL] Hidden Technical Debt in Machine Learning Systems",
    "text": "📝 TIL (Today I Learned) 📅 작성일: 2025-08-16 🔄 최종 수정: 2025년 08월 16일 🍀 새롭게 배운 것 논문: [Hidden Technical Debt in Machine Learning Systems (NIPS 2015)] 작성자: D. Sculley외 10인 (Google, Inc.) 1. 오늘 읽은 내용 요약 핵심 주제: 머신러닝 시스템에서 발생하는 숨은 기술 부채(hidden technical debt) 문제를 설명하고, 시스템 설계 단계에서 고려해야 할 위험 요소를 다룸. 기술 부채(Technical Debt) 개념 ML 시스템은 개발과 배포는 빠르지만 유지보수가 어렵고 비용이 많이 드는 구조적 특성을 가짐. 코드 수준의 문제보다 시스템 전반에서의 복잡성이 더 큰 원인. 숨은 부채는 누적되며, 발견 시에는 비용이 급격히 커짐. ML 시스템에서 기술 부채가 생기는 주요 원인 경계 침식(Boundary Erosion): 모델이 여러 신호를 섞어 사용하기 때문에 한 부분을 바꾸면 전체가 변함 (CACE 원칙: Changing Anything Changes Everything). 데이터 의존성(Data Dependencies): 불안정하거나 과도한 데이터 의존성으로 인해 작은 변화가 큰 장애를 일으킴. 피드백 루프(Feedback Loops): 모델이 자신의 입력 데이터를 간접적으로 바꾸는 경우 → 예측 정확도에 예기치 못한 영향을 미침. 시스템 안티패턴(System Anti-Patterns): Glue Code: 다양한 패키지를 연결하는 코드가 과도해져 유지보수 비용 증가. Pipeline Jungles: 데이터 처리 파이프라인이 점점 복잡해져 관리가 어려워짐. Dead Experimental Codepaths: 실험을 위해 만든 코드가 방치되어 예기치 못한 오류를 유발. 구성(Configuration) 부채: 피처, 하이퍼파라미터, 로깅 설정 등 방대한 설정이 누적되어 관리가 어려워짐. 외부 세계 변화: 환경, 사용자 행동, 시장 조건의 변화가 모델 성능에 직접적인 영향을 미침. 해결 방안 데이터 및 모델 의존성 관리 도구 구축 (버저닝, 자동화된 피처 관리 등). 모니터링 &amp; 자동화 대응 필수. 실험적 코드 정리 및 중복 제거. 연구팀과 엔지니어링팀 간 하이브리드 협업 구조 필요. 2. 나에게 필요했던 이유 이에 대한 자세한 내용은 (깃블로그)[링크]에서 볼 수 있습니다. 현재 진행 중인 AI 기반 발화/화행 분석 모델과 친구하자 서비스의 ML 시스템에 적용할 수 있음: 데이터 버저닝 필요성 → 감정 분석 모델 학습 시 피처 변경이 있을 경우 예기치 못한 성능 저하 방지. 파이프라인 관리 중요성 → 통화 음성 데이터 → 스펙트로그램 변환 → 감정 분석 → 저장 단계에서 발생할 수 있는 Pipeline Jungle 방지. 모델 업데이트 전략 → 모델 개선이 실제 서비스에서 사용자 경험을 악화시킬 수 있는 위험 방지 필요. 실시간 모니터링 필요 → 모델 성능 저하나 데이터 분포 변화에 빠르게 대응 가능해야 함. 3. 느낀 점 &amp; 인사이트 단순히 모델 성능을 높이는 것보다, 시스템 전반의 유지보수성과 데이터 흐름 관리가 훨씬 중요하다는 걸 깨달음. 특히 CACE 원칙은 실무에서 체감할 가능성이 큼: “하나 바꾸면 다 바뀐다” → 모델 입력 피처 변경 시 전체 시스템의 예측 성능이 흔들릴 수 있음. 앞으로 AI 모델 성능 향상보다 안정적인 시스템 아키텍처 설계에 우선순위를 둬야겠다고 느낌. 친구하자 서비스에서도: 데이터 파이프라인 설계를 단순하게 유지. 모델을 엔드 투 엔드로 한 번에 학습하는 방법과 서브모델 앙상블 방식의 트레이드오프를 고려해야 함. 장기적으로 모델 버저닝 + 모니터링 시스템을 도입해 기술 부채를 최소화할 필요 있음. 4. 다음 액션 아이템 데이터 버저닝 전략 조사 및 설계 (e.g., DVC, MLflow) 음성 데이터 파이프라인 단순화 → Glue Code 최소화 실시간 성능 모니터링 및 알림 시스템 설계 모델 업데이트 시 A/B 테스트 기반 롤아웃 전략 도입",
    "tags": "TIL Git ML til",
    "url": "/til/2025-08-16-til/"
  },{
    "title": "[Etc] FastAPI vs Flask: Python 백엔드 프레임워크 비교",
    "text": "새롭게 배운 것 오늘의 문제 상황 &amp; 해결 과정 Pydantic이란? Spring Boot DTO와 Pydantic의 비교 느낀 점 🍀 새롭게 배운 것 Python 백엔드 프레임워크인 FastAPI와 Flask를 비교해보았다. 두 프레임워크 모두 경량 웹 서버를 빠르게 개발할 수 있도록 도와주지만, 철학과 기능 면에서 차이가 존재한다. 주요 비교 항목: 비동기 처리, 타입 힌트 지원, 성능, 문서 자동화, 커뮤니티 및 생태계 등 항목 FastAPI Flask 출시 연도 2018 2010 비동기 지원 async/await 기반 비동기 처리 완전 지원 기본은 동기, 비동기 처리는 별도 패키지 필요 타입 힌트 필수적으로 사용하며, 자동 문서화 및 검증에 활용 선택적 사용, 검증은 외부 라이브러리 의존 문서 자동화 Swagger UI 및 Redoc 자동 생성 기본 제공 없음 (Flasgger 등으로 보완) 성능 매우 빠름 (Starlette 기반, Uvicorn 활용) 상대적으로 느림 러닝 커브 초기 진입 장벽이 다소 높음 (타입, Pydantic 등) 매우 쉬운 진입, 학습 곡선 완만 커뮤니티 빠르게 성장 중 매우 크고 안정적인 생태계 데이터 검증 Pydantic 기반의 자동 검증 별도 유효성 검사 코드 필요 REST API 개발 RESTful 설계에 최적화 자유도가 높음, 규칙이 느슨함 🍎 오늘의 문제 상황 &amp; 해결 과정 지금까지는 Flask의 간결함과 진입 장벽이 낮은 점이 마음에 들어 주로 Flask를 사용해왔다. 하지만 이번에는 FastAPI를 직접 적용해보고 싶어 새 프로젝트에 도입해보았다. 특히 Pydantic 모델이 처음엔 어렵게 느껴질까 걱정했지만, 막상 사용해보니 Spring Boot의 DTO와 매우 유사한 느낌이 들어 빠르게 익숙해졌다. 타입 기반 구조와 자동 검증, 문서화 덕분에 프로젝트가 자연스럽게 구조화되고 개발 속도도 빨랐다. 📌 Pydantic이란? Pydantic은 FastAPI에서 입력/출력 데이터의 구조를 정의하고, 유효성을 검사하며, JSON 직렬화를 자동으로 처리하는 핵심 컴포넌트다. Python의 타입 힌트(type hint)를 기반으로 동작하며, BaseModel을 상속하여 필드와 제약 조건을 선언할 수 있다. from pydantic import BaseModel, Field class User(BaseModel): name: str = Field(..., min_length=1) age: int email: str 위와 같이 작성하면, FastAPI는 요청 데이터가 이 조건을 만족하는지 자동으로 검증하고, Swagger 문서까지 자동 생성해준다. 🔍 Spring Boot DTO와 Pydantic의 비교 항목 Spring Boot DTO FastAPI Pydantic Model 역할 요청/응답 객체 정의 + 유효성 검사 요청/응답 객체 정의 + 유효성 검사 유효성 검사 도구 JSR 380 (e.g., @NotNull, @Size) Pydantic (Field, validator) 직렬화/역직렬화 Jackson 사용 내장 기능으로 자동 처리 중첩 구조 지원 중첩 DTO 클래스 중첩 BaseModel을 통한 자연스러운 처리 문서화 연동 Swagger/OpenAPI 설정 필요 FastAPI에 자동 내장 확장성 Bean Validation 위주 타입 변환, 커스텀 직렬화 등 더 다양한 기능 내장 결론적으로 Pydantic은 Spring의 DTO와 유사한 사용 경험을 제공하면서도, 그 이상의 기능(데이터 직렬화, 문서화, 타입 변환 등)을 하나의 모델에서 처리할 수 있다는 점에서 DTO + Validator + Mapper + Serializer의 통합체로 볼 수 있다. 🦄 느낀 점 Flask는 여전히 빠른 개발과 간단한 구조를 원할 때 유용한 선택지다. 반면 FastAPI는 프로젝트 구조를 더 명확히 하고, 자동화된 유효성 검사 및 문서화 기능까지 갖추고 있어 중·대형 규모 프로젝트나 협업 시에 훨씬 효율적이라는 점을 느꼈다. 개인적으로는 Pydantic이 예상보다 익숙했고, Spring Boot의 DTO를 써본 경험이 FastAPI 적응에 큰 도움이 되었다. 앞으로는 프로젝트의 성격에 따라 Flask와 FastAPI를 유연하게 선택하며, 각 도구의 장점을 상황에 맞게 활용할 계획이다.",
    "tags": "TIL FastAPI Flask Backend miscellaneous til",
    "url": "/miscellaneous/til/2025-07-20-flask-fastAPI/"
  },{
    "title": "[TIL] Jenkins vs GitHub Actions, IaaS vs PaaS vs SaaS",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #62 📅 작성일: 2025-05-27 🔄 최종 수정: 2025년 05월 28일 🍀 새롭게 배운 것 AI Tech 2025 : AI 융합 비즈니스 개발 컨퍼런스 후기 작성 완료! Tistory 1️⃣ Jenkins vs GitHub Actions 둘 다 **CI/CD(지속적 통합/지속적 배포)**를 자동화하는 도구다. 개발자가 코드를 push하면 자동으로 빌드하고, 테스트하고, 배포까지 해주는 파이프라인 역할. 항목 Jenkins GitHub Actions 배포 방식 직접 서버에 설치 (온프레미스, 클라우드) GitHub 내장 서비스 (클라우드 기반) 파이프라인 구성 Groovy 기반 DSL (Jenkinsfile) YAML 기반 설정 (.github/workflows/) UI/플러그인 수많은 플러그인과 커스터마이징 가능 GitHub 생태계에 최적화된 워크플로우 설정 난이도 다소 복잡 (서버 관리 필요) 상대적으로 간단하고 빠른 적용 가능 장점 유연한 환경 설정, 다양한 툴 연동 가능 GitHub와 완벽하게 통합, 설정이 간단 단점 서버 유지보수 필요, 러닝커브 있음 GitHub 내에서만 동작 (GitLab, Bitbucket X) ✅ GitHub Actions는 빠르게 CI/CD를 도입하고 싶은 팀에 좋고, ✅ Jenkins는 복잡한 환경이나 내부망에서의 CI/CD가 필요할 때 적합하다. —å 🧪 간단 예시 – GitHub Actions # .github/workflows/deploy.yml name: Build and Deploy on: [push] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - run: ./gradlew build 2️⃣ IaaS vs PaaS vs SaaS 클라우드 서비스 모델을 구분할 때 자주 등장하는 세 가지 개념. “내가 어디까지 책임지고, 어디서부터는 제공자가 해주는가?”가 핵심. ✅ 개념 요약 구분 설명 예시 IaaS (Infrastructure as a Service) 인프라만 제공받고, OS부터 직접 설치 AWS EC2, Google Compute Engine PaaS (Platform as a Service) 실행 환경까지 제공, 앱 코드만 올리면 됨 Heroku, Google App Engine, Render SaaS (Software as a Service) 소프트웨어 완제품 사용 Gmail, Notion, Slack ✅ 비교 예시 항목 IaaS PaaS SaaS 서버 관리 내가 함 클라우드가 함 필요 없음 개발 유연성 높음 중간 거의 없음 배포 편의성 낮음 (직접 설정) 높음 (코드만 배포) 매우 높음 (사용만 하면 됨) 대상 사용자 인프라 엔지니어, DevOps 백엔드 개발자 일반 사용자, 마케터 등 🧠 요약 정리 질문 답변 Jenkins랑 GitHub Actions 중 뭐가 더 쉽지? GitHub Actions! 설정이 YAML이고 GitHub랑 연동이 편함 IaaS는 언제 써야 해? 서버에 대해 완전히 커스터마이징이 필요할 때 SaaS는 어떤 거야? 구글 드라이브, 노션, 슬랙처럼 바로 쓰는 서비스 오늘의 핵심: ✅ CI/CD 도구는 “내가 코드를 어떻게 자동화할지”에 따라 고르고, ✅ 클라우드 서비스 모델은 “어디까지 직접 관리할지”에 따라 고른다.",
    "tags": "TIL Git DevOps Cloud til",
    "url": "/til/2025-05-27-til/"
  },{
    "title": "[TIL] Nginx, 리버스 프록시, 로드 밸런서",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #61 📅 작성일: 2025-05-24 🔄 최종 수정: 2025년 05월 27일 🍀 새롭게 배운 것 1️⃣ Nginx란? **Nginx(엔진엑스)**는 고성능 웹 서버 소프트웨어다. 원래는 정적 콘텐츠 제공을 위한 웹 서버였지만, 현재는 리버스 프록시, 로드 밸런서, API Gateway, 캐시 서버 등 다용도로 활용된다. ✅ Nginx의 주요 기능 기능 설명 웹 서버 HTML, CSS, JS 같은 정적 파일 제공 리버스 프록시 클라이언트 요청을 내부 서버에 전달 로드 밸런서 여러 서버에 트래픽을 분산하여 처리 캐시 서버 응답을 캐싱해 성능 향상 SSL 종단 처리 HTTPS 인증서 처리 (Let’s Encrypt 등과 연동) 🔄 리버스 프록시란? 클라이언트는 Nginx에 요청을 보내고, Nginx는 **백엔드 서버(Apache, Spring, Node 등)**에 요청을 전달한 후 응답을 다시 클라이언트에 전송한다. [Client] → [Nginx] → [Spring Server] 보안, 로드 밸런싱, 서버 분리 등 다양한 이유로 활용됨 ⚖️ 로드 밸런서 요청을 여러 서버에 고르게 분산시켜 트래픽 집중을 막고 가용성을 높임 Nginx에서 로드 밸런싱 구성 예시: upstream backend { server backend1.example.com; server backend2.example.com; } server { location / { proxy_pass http://backend; } } upstream 블록을 통해 백엔드 서버를 그룹핑하고, Nginx가 자동으로 라운드로빈 방식으로 분산 처리 📦 정적 파일 서버로의 활용 HTML/CSS/JS 파일을 빠르게 서빙할 수 있음 WAS(Spring, Node 등)에서 정적 리소스를 분리하면 서버 부하를 줄일 수 있음 server { listen 80; location / { root /usr/share/nginx/html; index index.html; } } 🔒 HTTPS 설정 Let’s Encrypt와 Certbot을 이용해 무료 SSL 인증서 발급 가능 HTTPS로 종단 보안(SSL Termination)을 적용하여 보안 강화 🧠 함께 알아두면 좋은 심화 키워드 키워드 설명 리버스 프록시 Nginx가 중간에 서서 내부 서버 대신 요청 응답 처리 포워드 프록시 사용자의 요청을 외부로 보낼 때 중개하는 프록시 CDN (Content Delivery Network) 정적 리소스를 전 세계에 분산 저장하여 빠르게 전송 캐싱 정책 Cache-Control, ETag를 이용한 정적 자원 캐싱 Blue-Green Deployment Nginx로 배포 서버를 스위칭하여 무중단 배포 실현 ✍️ 오늘의 요약 Nginx는 단순 웹 서버 그 이상으로, 프론트와 백엔드 사이의 허브 역할을 한다. 리버스 프록시, 로드 밸런서, 정적 파일 서버, SSL 처리까지 담당할 수 있는 멀티플레이어 실제 운영 환경에서는 Spring Boot와 Nginx 연동, HTTPS 적용, EC2 배포 시 로드밸런싱 구성 등을 할 수 있도록 익숙해져야 한다",
    "tags": "TIL til",
    "url": "/til/2025-05-24-til/"
  },{
    "title": "[TIL] Grafana &amp; Prometheus, Rolling Policy, 시계열 메트릭",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #60 📅 작성일: 2025-05-23 🔄 최종 수정: 2025년 05월 27일 🍀 새롭게 배운 것 1️⃣ Grafana &amp; Prometheus – 시계열 메트릭 시각화 도구 📊 Prometheus CNCF(Cloud Native Computing Foundation)에서 관리하는 시계열 메트릭 수집 도구 주로 인프라/애플리케이션 성능 모니터링에 사용됨 Pull 방식으로 타겟 서버의 메트릭을 주기적으로 수집함 메트릭 쿼리 언어: PromQL 내장된 시계열 DB에 메트릭 저장 예시 메트릭: http_requests_total{method=\"GET\", status=\"200\"} 1523 cpu_usage_seconds_total{core=\"1\"} 82.3 📈 Grafana Prometheus 등의 시계열 데이터 소스를 시각화하는 대시보드 도구 사용자가 커스터마이징 가능한 대시보드/그래프/알람을 만들 수 있음 Prometheus 외에도 Loki(로그), InfluxDB, MySQL, Elasticsearch 등 다양한 소스와 연동 가능 주요 사용 예: CPU/메모리/디스크 사용률 실시간 모니터링 서비스 요청 응답 시간 추적 메트릭 기반 알림 설정 (ex. 5분간 에러율이 5% 넘으면 슬랙 알림) 🧩 Grafana + Prometheus = DevOps 핵심 콤보 도구 역할 Prometheus 메트릭 수집 및 저장 Grafana 메트릭 시각화 및 알람 두 도구는 함께 사용할 때 진가를 발휘한다. Prometheus가 메트릭 데이터를 모으고, Grafana가 이를 시각적으로 표현해준다. 2️⃣ Rolling Policy (로그 롤링 정책) 🧾 개념 로그 파일이 커지거나 오래되었을 때, 자동으로 새로운 파일로 교체하거나 백업하는 정책 로그 관리를 자동화해서 디스크 과부하를 방지하고, 오래된 로그를 보관하거나 삭제할 수 있게 해줌 📁 적용 예 – logback-spring.xml 예시: &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;logs/app-%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;!-- 30일간 보관 --&gt; &lt;/rollingPolicy&gt; 🎛️ 주요 타입 정책 유형 설명 TimeBasedRollingPolicy 날짜별로 로그 파일 분리 (app-2025-05-14.log) SizeBasedTriggeringPolicy 특정 크기 초과 시 새로운 파일 생성 (app.log.1, .2…) FixedWindowRollingPolicy 번호 기반 순환 롤링 (app.1.log, app.2.log) 🚧 왜 중요한가? 로그 파일이 무한히 커지지 않도록 제어 백업 및 운영에 필요한 로그만 유지 가능 ELK/EFK 스택과 연동할 때도 파일 기반 로그를 안정적으로 관리 정리하자면, **“로그를 무한정 쌓지 말고, 잘라서 보관하고, 오래된 건 지우자!”**는 개념이다. 📌 오늘의 요약 개념 핵심 기능 Prometheus 메트릭 수집 및 저장 (시계열 DB) Grafana 메트릭 시각화 및 알림 Rolling Policy 로그 용량/시간 기준 자동 분할 및 관리 3️⃣ 🕐 시계열 메트릭(Time Series Metrics)이란? 시간(Time) + 값(Value) 이 쌍으로 구성된 데이터 특정 지표가 시간에 따라 어떻게 변하는지를 보여줌 📊 예시: 시간 CPU 사용률 (%) 2025-05-14 10:00:00 30 2025-05-14 10:01:00 35 2025-05-14 10:02:00 70 이처럼 “시간에 따른 수치 변화”를 기록한 데이터가 바로 시계열 메트릭 📦 시계열 메트릭 수집 도구란? 이런 시간 기반 데이터를 자동으로 수집, 저장, 관리해주는 도구를 말합니다. 대표적인 도구: Prometheus InfluxDB Graphite OpenTSDB 이들은 서버나 애플리케이션에서 CPU, 메모리, 요청 수, 에러율 같은 수치를 주기적으로 수집해서 시계열 DB에 저장한다. 🛠️ 예를 들어 Prometheus는? 15초마다 모든 서버의 CPU 사용률, HTTP 요청 수 등을 수집 내부에 시계열 전용 데이터베이스를 가지고 있어 시간 순서대로 저장 나중에 Grafana 같은 도구로 꺾은선 그래프를 그릴 수 있음 📌 정리 용어 의미 시계열 데이터 시간에 따라 변화하는 수치 데이터 (예: CPU 70% → 50%) 시계열 메트릭 도구 시간 기반 데이터를 주기적으로 수집/저장하는 시스템 시계열 메트릭 도구는 결국 **“시간의 흐름에 따라 시스템이 어떻게 작동하고 있는지 보여주는 도구”**",
    "tags": "TIL til",
    "url": "/til/2025-05-23-til/"
  },{
    "title": "[TIL] 메테리얼 디자인 vs 쿠퍼티노 디자인, Log vs Metrics, Structure…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #59 📅 작성일: 2025-05-22 🔄 최종 수정: 2025년 05월 27일 🍀 새롭게 배운 것 1️⃣ 메테리얼 디자인(Material Design) vs 쿠퍼티노 디자인(Cupertino Design) 🎨 메테리얼 디자인 (Material Design) Google에서 만든 디자인 시스템 Android 앱에서 기본적으로 사용되는 UI 가이드라인 특징: 실제 종이처럼 동작하는 “표면” 개념 → 레이어, 그림자, 깊이감 굵은 색상, 명확한 애니메이션, 카드 UI 일관된 컴포넌트 구조 (Button, Dialog 등) 다양한 화면 크기 및 접근성 고려가 잘 되어 있음 🍏 쿠퍼티노 디자인 (Cupertino Design) Apple이 만든 iOS용 디자인 철학 Flutter에서는 CupertinoWidget으로 구현 특징: 심플하고 정갈한 UI, 얇은 폰트, 미니멀한 구성 iOS의 네이티브한 느낌을 충실히 재현 스크롤, 네비게이션, 토글 스위치 등에서 iOS 특유의 인터랙션 존재 비교 요약: 항목 Material Design Cupertino Design 주요 플랫폼 Android, Web, Desktop iOS 디자인 철학 종이+레이어+애니메이션 단순함+미려함+일관성 주요 사용 예 Google 앱, Android 앱 Apple 앱, iOS 앱 Flutter 적용 MaterialApp CupertinoApp 요약: Android 앱은 Material 위주, iOS는 Cupertino 스타일을 따르며, Flutter는 둘 다 지원해 플랫폼에 맞는 UI를 쉽게 만들 수 있다! 2️⃣ Log vs Metrics 백엔드/운영 환경에서 시스템 상태를 추적할 때 자주 쓰이는 두 가지 개념을 비교해 보았다. 📄 로그 (Log) 시간 순으로 발생한 이벤트 기록 보통 텍스트 기반이며, 문제가 발생했을 때 무슨 일이 있었는지 파악하는 데 유용 예: 사용자가 로그인에 실패했습니다. 서버에서 500 에러가 발생했습니다. 특징: 구조화가 느슨함 (JSON 또는 단순 텍스트) 디버깅, 감사 추적에 용이 사후 분석에 효과적 저장 공간 많이 차지할 수 있음 예시: { \"timestamp\": \"2025-05-13T12:45:00\", \"level\": \"ERROR\", \"message\": \"Login failed for user ID 123\" } 📊 메트릭 (Metrics) 수치로 측정 가능한 시스템의 상태 시간에 따라 변화하는 수치 → CPU 사용량, 요청 수, 응답 시간 등 예: 서버 응답 시간 평균 120ms 현재 접속 사용자 수 300명 특징: 구조화된 데이터 시각화 및 대시보드 구성에 유리 알림(경고) 설정에 적합 보통 Prometheus, Grafana와 같이 사용됨 예시: http_requests_total{method=\"GET\", status=\"200\"} 3456 비교 요약: 항목 로그(Log) 메트릭(Metrics) 목적 이벤트 디버깅, 추적 상태 모니터링, 성능 추적 형식 텍스트 기반, 구조 유동적 수치 기반, 구조화됨 저장 로그 파일, ELK Stack 시계열 DB (Prometheus 등) 시각화 Kibana, Logtail 등 Grafana 등 실시간성 낮음 (분석 중심) 높음 (모니터링, 알림에 적합) 로그는 “무슨 일이 일어났는가”를 알려주고, 메트릭은 “현재 시스템이 어떤 상태인가”를 알려준다. 둘은 보완 관계로 함께 사용하는 것이 가장 효과적이다! 3️⃣ Structured Logging (구조화된 로그) ✅ 개념 일반 로그는 텍스트 형식으로 사람이 읽기 쉽게 쓰는 반면, Structured Logging은 로그를 JSON 같은 구조화된 형태로 기록하는 방식입니다. 🔍 예시 비교 ❌ 일반 로그 (Unstructured): User 1234 failed to login due to wrong password ✅ 구조화 로그 (Structured): { \"timestamp\": \"2025-05-13T10:42:00Z\", \"level\": \"WARN\", \"event\": \"login_failed\", \"user_id\": 1234, \"reason\": \"wrong_password\" } ✨ 장점 기계가 파싱하기 쉽고, 검색/필터링/집계에 유리 로그 수집 도구(예: Elasticsearch, Datadog)와 연동할 때 편함 실시간 모니터링이나 경고 시스템과 연계 가능 구조화 로그는 결국 “로그도 데이터다”라는 관점에서 관리하는 것! 4️⃣ ELK vs EFK 스택 ✅ 공통 목적 분산 로그 수집, 저장, 분석, 시각화를 위한 스택입니다. 대규모 시스템에서 수많은 서버 로그를 한 곳으로 모아서 검색·분석하기 위해 사용합니다. 🧩 ELK Stack Elasticsearch: 로그를 저장하고 검색 가능한 DB Logstash: 로그 수집기. 다양한 소스에서 로그를 받아 필터링/변환 Kibana: 시각화 도구 (대시보드, 검색 UI 등) 장점 오래된 구성으로 안정적이고 성숙함 다양한 입력 소스를 지원 (DB, 파일, MQ 등) 단점 Logstash가 무거움 → 리소스 많이 사용 설정 복잡함 🧩 EFK Stack Elasticsearch Fluentd: 경량 로그 수집기 (Logstash 대체) Kibana 장점 Kubernetes 환경에 더 적합 Fluentd는 가볍고 플러그인으로 유연하게 확장 가능 최근 클라우드 환경에서 더 많이 사용됨 단점 복잡한 변환/파이프라인 처리 시엔 Logstash보다 기능 제한 있음 비교 요약표: 항목 ELK EFK 로그 수집기 Logstash (무거움) Fluentd (가볍고 유연함) 시각화 Kibana Kibana 주 사용 환경 온프레미스, 레거시 시스템 클라우드, Kubernetes 구성 난이도 다소 복잡 상대적으로 단순 📌 결론 상황 추천 Kubernetes 기반 마이크로서비스 ✅ EFK Stack 다양한 로그 소스와 복잡한 처리 필요 ✅ ELK Stack 단순한 파일 로그 수집 및 시각화 ✅ 둘 다 가능, 구조화 로그 필수 실제로는 EFK + Structured Logging 조합이 요즘 가장 트렌디한 방식입니다. 로그를 JSON 형태로 남기고, Fluentd를 통해 Elasticsearch에 넣은 뒤 Kibana로 시각화하면 아주 강력한 로그 분석 시스템이 됩니다.",
    "tags": "TIL til",
    "url": "/til/2025-05-22-til/"
  },{
    "title": "[TIL] RPM, 앙상블, 비용, WSL, Windows Subsystem for Linux …",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #58 📅 작성일: 2025-05-21 🔄 최종 수정: 2025년 05월 27일 🍀 새롭게 배운 것 1️⃣ RPM, 앙상블, 비용 RPM (Revolutions Per Minute) 원래는 하드디스크나 모터 회전 속도를 나타내는 단위지만, **웹/앱 분석에서는 보통 “Revenue Per Mille(천 회당 수익)”**로 사용된다. 광고 업계에서는 광고가 1,000번 노출될 때 수익이 얼마인지를 뜻함. 예: RPM = 5라면, 1,000번 광고 노출 시 수익이 $5 수익성을 평가하는 지표로 자주 사용됨. 앙상블 (Ensemble) 머신러닝에서 여러 모델을 조합해 예측 정확도를 향상시키는 기법 주요 기법: Bagging (ex. Random Forest) Boosting (ex. XGBoost, LightGBM) Stacking (모델들의 출력값을 다시 모델에 입력) 하나의 모델보다 성능이 좋을 가능성이 높고, 특히 Kaggle 등 실전 대회에서 필수 전략임. 비용 (Cost) 머신러닝에서의 비용은 보통 오차(error)를 수치화한 값 목표는 이 비용(Cost)을 최소화하는 모델 파라미터를 찾는 것 예: 회귀에서는 MSE (Mean Squared Error) 분류에서는 Cross Entropy 같은 손실 함수 사용 2️⃣ WSL, Windows Subsystem for Linux 2 WSL (Windows Subsystem for Linux) Windows에서 Linux 환경을 사용할 수 있게 해주는 Microsoft의 호환 계층 WSL2는 WSL1과 달리 실제 Linux 커널을 가상 머신 위에 구동시킴 더 빠르고 호환성이 뛰어남 (ex. Docker 사용 가능) 개발자가 Mac 없이도 Unix/Linux 개발 환경을 Windows에서 구성할 수 있어 유용함 UNIX vs MacOS vs WSL2 vs Tux UNIX: OS 설계 철학/표준, 안정성과 보안성으로 서버 환경에서 많이 사용됨 MacOS: BSD 계열의 UNIX 기반 OS → 터미널 환경이 UNIX 명령어와 유사 WSL2: 윈도우 안에서 리눅스 환경을 제공해, 리눅스 개발 도구 사용 가능 Tux: 리눅스의 공식 마스코트 펭귄 이름 🐧 요약: Mac이나 Linux 서버가 없더라도 WSL2를 쓰면 로컬에서 UNIX 개발 환경을 손쉽게 세팅할 수 있다. 3️⃣ Phoenix vs Snowflake 이 두 용어는 데이터 웨어하우스 시스템 및 클라우드 아키텍처 문맥에서 자주 사용됨. 🔥 Phoenix Server (불사조 서버) 시스템을 중단하지 않고 점진적으로 설정, 코드, 인프라를 바꾸는 방식 “죽지 않는 서버” 실시간으로 코드를 수정하거나, 배포 중에도 유저에게 영향을 주지 않음 하지만 시간이 지날수록 기술 부채가 쌓일 수 있음 ❄️ Snowflake Server (눈송이 서버) 수작업 설정이 많고, 특정 환경에서만 작동하는 불안정한 서버 배포마다 설정이 조금씩 달라서, 한번 망가지면 복원하기 어려움 반의어로 Immutable Infrastructure (변경 불가능한 인프라)가 선호됨 예: 컨테이너 기반 인프라 (Docker + CI/CD) 요약: Phoenix 서버는 장기적으로 위험이 쌓이고, Snowflake 서버는 설정 의존도가 높아 불안정하며, **이 둘을 피하기 위해 IaC(Infrastructure as Code)**와 컨테이너, 배포 자동화를 쓰는 것이 최신 DevOps 흐름이다.",
    "tags": "TIL til",
    "url": "/til/2025-05-21-til/"
  },{
    "title": "[TIL] Ollama",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #57 📅 작성일: 2025-05-20 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 Ollama 로컬 머신에서 대규모 언어 모델(LLM)을 실행할 수 있게 해주는 오픈소스 도구 주요 특징 로컬 실행: 모든 처리가 로컬에서 이루어져 개인정보 보호가 가능 다양한 모델 지원: Llama, Mistral, Gemma 등 다양한 오픈소스 모델 지원 간단한 API: REST API를 통해 쉽게 통합 가능 CPU/GPU 지원: 다양한 하드웨어에서 실행 가능 크로스 플랫폼: Windows, macOS, Linux 지원 Ollama 시작하기 ollama.com에서 OS에 맞는 버전 다운로드 및 설치 터미널에서 모델 다운로드 (예: ollama pull llama3.2) 모델 실행 (예: ollama run llama3.2) API 사용 방법 Ollama는 http://localhost:11434에서 REST API를 제공합니다: # Python 예제 import requests response = requests.post('http://localhost:11434/api/generate', json={ 'model': 'llama3.2', 'prompt': '백엔드 개발에 필요한 기술은?', 'stream': False }) print(response.json()['response']) // JavaScript 예제 fetch(\"http://localhost:11434/api/generate\", { method: \"POST\", headers: { \"Content-Type\": \"application/json\" }, body: JSON.stringify({ model: \"llama3.2\", prompt: \"백엔드 개발에 필요한 기술은?\", stream: false, }), }) .then((response) =&gt; response.json()) .then((data) =&gt; console.log(data.response));",
    "tags": "TIL til",
    "url": "/til/2025-05-20-til/"
  },{
    "title": "[컨퍼런스] AI Tech 2025 참석 후기",
    "text": "1. 행사 개요 2. 키노트 요약: Embodied AI와 기술 진화 방향 3. A2A 시대의 도래: Agent 협업 구조 4. AI는 이제 운영의 시대 5. 실무 적용 사례 및 전략 6. 기술 인사이트 7. 결론 실무자 중심의 AI 도입 이후 전략, 오케스트레이션 구조, 에이전트 협업 사례 중심 1. 행사 개요 AI Tech 2025는 단순한 모델 개발이나 비전 소개를 넘어서, “AI를 어떻게 현업에 도입하고 운영할 것인가”를 주제로 구성된 실무 중심의 컨퍼런스였다. 다양한 기업과 기술 리더들이 실제 적용 사례, 인프라 설계, 오케스트레이션 전략을 공유했으며, AI 도입 이후 단계에서 실질적인 생산성을 확보하기 위한 전략들이 인상 깊었다. 2. 키노트 요약: Embodied AI와 기술 진화 방향 서울대 장병탁 교수의 기조연설에서는 AI의 진화 방향이 강조되었다. 기존: 디지털 정보 공간 내 추론 중심의 AI 변화: 실세계와 상호작용하며 학습·판단·행동하는 Embodied AI Embodied AI는 물리적 환경을 인식하고 그에 반응할 수 있는 에이전트로, 강화학습 및 체화 학습을 통해 자율성을 확보한다. Figure: Embodied AI – 환경 인지, 판단, 행동이 통합된 AI 시스템 3. A2A 시대의 도래: Agent 협업 구조 🔍 A2A(Agent-to-Agent Protocol) 이번 행사에서 가장 빈번하게 언급된 개념 중 하나는 A2A였다. 의미: 에이전트 간 데이터 공유 및 협업을 위한 통신 프로토콜 기능: 목적 지향형 대화, 작업 분담, 협업형 워크플로우 구성 사례: 문서 요약 에이전트 → 일정 정리 에이전트로 결과 전달 요약 에이전트 → 분석 결과 전달 → 일정 에이전트가 회의 제안 자동화 🧩 관련 개념 Agent Hub: 에이전트 설계/운영 통합 플랫폼 ADK: Agent Design Kit Agent Engine: 배포 및 실행 환경 Agent Garden: 에이전트 레지스트리/관리 이와 같은 구조는 기존 **MSA(마이크로서비스 아키텍처)**와 유사하게, AI 시스템에서도 다수의 특화 에이전트가 상호작용하는 구조적 전환을 의미한다. 4. AI는 이제 운영의 시대 기술보다 중요한 건 운영과 조율이다. 특히 다음과 같은 통찰이 강조되었다. AGI는 단일 모델이 아닌, 여러 특화 에이전트의 조합 이 조합을 조율하는 AI 오케스트레이션 계층이 핵심 개발자는 모델 사용자에서 AI 아키텍처 설계자로 역할 확장 필요 A2A는 단순한 API 호출이 아니라, 에이전트 간 협업 흐름을 구성하는 전략적 도구로 자리잡고 있다. 5. 실무 적용 사례 및 전략 📌 주요 사례 한화생명: 보험 상담 자동화 (LLM + RAG 기반 챗봇 운영) KT: 기관 문서 기반 검색 시스템 구축 MARA: 자산 시장 분석 자동화 Nota AI: 엣지 디바이스용 AI 모델 경량화 및 배포 이 외에도 다양한 기업들이 AI를 ‘기능’으로서가 아닌, 문제 해결 도구로서 어떻게 전략적으로 운영하고 있는지를 소개했다. 6. 기술 인사이트 🛠️ 실용 기술 Structured Pruning: 불필요한 파라미터 제거로 경량화 Filter Decomposition: 병렬 연산을 직렬화하여 성능 최적화 RAG 기반 검색: 문서 기반 답변 정확도 향상 Agent Workflow: 도메인 특화 다중 에이전트 협업 구성 7. 결론 AI 시스템은 이제 단일 모델의 정확도보다, 어떻게 운영되고 협업 구조를 갖추는가가 더 중요해지고 있다. 이번 컨퍼런스를 통해 확인한 핵심은 다음과 같다: AI는 플랫폼이다: 단일 모델보다 다중 에이전트의 구조화된 조율이 핵심 A2A는 미래의 기본 요소: 마이크로서비스처럼 에이전트 협업이 표준화될 것 운영 전략이 곧 성패를 가른다: 기술보다 프로덕션 환경 최적화가 우선시됨 기술을 넘어 전략으로서의 AI를 고민하게 된 의미 있는 자리였다.",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-05-15-diary/"
  },{
    "title": "[TIL] spring-boot-starter-validation, 테스트 코드 모니터링 툴",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #56 📅 작성일: 2025-05-12 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 spring-boot-starter-validation 테스트 코드 모니터링 툴 1️⃣ spring-boot-starter-validation Spring Boot에서 사용자 입력 값(요청 바디 등)을 검증할 수 있게 해주는 의존성 패키지 내부적으로는 javax.validation (JSR-380)이나 jakarta.validation API를 기반으로 동작 주로 아래와 같은 상황에 동작 사용자가 회원가입을 할 때 게시글을 작성할 때 비밀번호 변경할 때 등 프론트엔드에서 필터링한다고 해도, 백엔드에서는 무조건 검증이 필요 신뢰할 수 없는 요청이나 보안 위험을 방지하기 위해서 (프론트는 우회가 가능하므로) 백엔드 검증은 필수! 검증 애너테이션 @NotNull, @NotBlank, @Size, @Email, @Min, @Max 등 검증 실패 시 @ControllerAdvice와 @ExceptionHandler를 이용해 에러 메시지 사용 1. 의존성 추가 (build.gradle) implementation 'org.springframework.boot:spring-boot-starter-validation' 2. DTO 클래스에 검증 어노테이션 달기 import jakarta.validation.constraints.NotBlank; import jakarta.validation.constraints.Size; public class SignupRequestDto { @NotBlank(message = \"이메일은 필수입니다.\") private String email; @Size(min = 8, message = \"비밀번호는 최소 8자 이상이어야 합니다.\") private String password; // getter, setter } 3. Controller에서 검증 처리 @PostMapping(\"/signup\") public ResponseEntity&lt;?&gt; signup(@Valid @RequestBody SignupRequestDto request) { // 통과 시 로직 실행 } @Valid가 붙은 객체에서 문제가 발생하면 자동으로 400 에러 발생. 에러 메시지는 @ControllerAdvice를 통해 커스터마이징도 가능. 2️⃣ 테스트 코드 모니터링 툴 “테스트 코드의 품질과 실행 현황을 시각적으로 분석/모니터링하는 도구” 즉, 테스트가 얼마나 잘 되어 있는지 **“숫자와 그래프”**로 보여주는 도구 테스트 코드가 있다고 해도, **정말 전체 코드를 잘 테스트하고 있는지는 모름 그래서 “코드 커버리지”, “테스트 성공률”, “실행 시간” 같은 걸 측정해서 모니터링할 수 있어야 한다. 커버리지 코드의 품질과 신뢰성을 수치로 확인할 수 있는 지표 단순히 테스트를 작성하는 것보다, 커버리지를 보면서 blind spot 없이 테스트하는 게 중요! 🔧 대표적인 도구들 | 도구 | 설명 | | ———————- | ———————————– | | JaCoCo | Java 프로젝트에서 가장 널리 쓰이는 코드 커버리지 측정 도구 | | SonarQube | 코드 품질, 보안 취약점, 커버리지까지 통합 분석 | | IntelliJ 자체 기능 | 실행 후 커버리지를 하이라이팅으로 보여줌 | | Codecov, Coveralls | GitHub Actions와 연동해 커버리지 리포트 자동화 |",
    "tags": "TIL Spring til",
    "url": "/til/2025-05-12-til/"
  },{
    "title": "[TIL] UUID와 Auto Increment PK는 언제 사용할까?",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #55 📅 작성일: 2025-05-11 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 UUID와 Auto Increment PK는 언제 사용할까? 오늘은 엔티티의 기본 키(primary key)를 정의할 때 UUID와 Auto Increment(Long 타입) 중 어떤 것을 선택할지에 대해 정리해보았다. ✅ Auto Increment (일반적인 정수형 PK) 특징 @GeneratedValue(strategy = GenerationType.IDENTITY) 형태로 많이 사용 DB가 자동으로 증가시키며 관리 숫자 기반이라 인덱싱 속도가 빠르고, 저장 공간도 적게 차지함 사용에 적합한 경우 내부 시스템용 데이터 데이터 유출 시에도 ID 자체로는 식별 불가 → 보안 문제가 크지 않은 경우 검색/조회 성능이 중요한 경우 단점 순차적으로 증가하는 ID는 보안상 예측 가능성이 있음 (특히 API 경로에 노출될 경우 위험) 시스템 간 병합 시 충돌 가능성 있음 (ex. 여러 서버에서 동시에 데이터를 생성하는 분산 환경) ✅ UUID (범용 고유 식별자) 특징 @GeneratedValue(strategy = GenerationType.AUTO) 또는 UUID.randomUUID() 사용 128비트의 랜덤 고유값 (예: d290f1ee-6c54-4b01-90e6-d701748f0851) 전역적으로 충돌 가능성이 거의 없음 → 분산 시스템에 적합 사용에 적합한 경우 외부에 노출되는 식별자(API, 클라이언트 전송 등) 데이터 생성 주체가 분산되어 있어 충돌을 방지해야 할 때 보안상 ID 노출을 피하고 싶을 때 단점 길이가 길고 가독성이 떨어짐 저장 시 공간 낭비 (VARCHAR or BINARY 타입) 인덱싱 성능이 낮음 → 대량 데이터일수록 성능 저하 가능 💡 결론: 어떤 상황에 어떤 걸 쓸까? 상황 추천 방식 단일 서버, 내부 관리 중심 서비스 Auto Increment 외부 노출 ID가 필요하거나, 분산 환경에서 생성되는 데이터 UUID 민감한 정보 식별자 (예: 사용자 ID, 주문 번호 등) UUID 빠른 정렬/검색이 중요한 대량 데이터 Auto Increment (with caution) 오늘의 교훈: “보안성과 확장성”이 중요한 시스템이라면 UUID, “성능과 단순함”이 중요하다면 Auto Increment를 고려하자. 다만 외부에 노출될 수 있는 ID는 무조건 UUID나 별도의 난수 토큰을 사용하는 것이 안전하다!",
    "tags": "TIL til",
    "url": "/til/2025-05-11-til/"
  },{
    "title": "[TIL] 순환 참조 문제 (Infinite Recursion in JSON Serializat…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #54 📅 작성일: 2025-05-10 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 순환 참조 문제 (Infinite Recursion in JSON Serialization) 오늘은 API 응답을 구성하는 과정에서 발생한 무한 재귀 직렬화 오류를 해결하며 순환 참조(Circular Reference)에 대해 학습했다. 문제의 핵심은 Entity 간 양방향 참조가 존재할 때, JSON 직렬화 과정에서 객체 간 호출이 끝없이 반복되어 StackOverflowError가 발생하는 현상이었다. ⚠️ 문제 상황 PeerReview → Post Post → Member, postMembers PostMember → 다시 Post 이렇게 서로 참조하는 구조로 인해 JSON 직렬화 중 무한 루프가 발생했다. 🔍 해결 방법 ✅ 1. DTO 패턴 사용 (권장) 가장 바람직한 해결책은 Entity를 그대로 반환하지 않고, 필요한 정보만 담은 Response DTO를 만들어 응답하는 방식이다. 예를 들어 PeerReviewResponse에서는 Post 전체 객체를 넘기지 않고, postId, postTitle만 넘기도록 변경했다. 같은 방식으로 UserReviewCommentResponse도 수정했다. 이렇게 DTO를 사용하면 다음과 같은 장점이 있다: 불필요한 Entity 참조 제거 → 순환 참조 문제 해결 필요한 데이터만 전달 → 응답 성능 향상 Entity와 API 응답 로직 분리 → 유지보수성 향상 보안상 안전 (내부 필드 노출 방지) 🛠️ 2. Jackson 어노테이션 사용 (보완적/참고용) 만약 어쩔 수 없이 Entity를 직접 반환해야 한다면 @JsonManagedReference, @JsonBackReference 또는 @JsonIgnore를 사용하는 방식도 있다. // Post.java @OneToMany(mappedBy = \"post\") @JsonManagedReference private List&lt;PostMember&gt; postMembers; // PostMember.java @ManyToOne @JoinColumn(name = \"post_id\") @JsonBackReference private Post post; 하지만 이 방법은 API와 Entity 계층이 강하게 결합되므로, 장기적으로는 유지보수나 테스트 측면에서 불리하다. 오늘의 핵심 교훈: Entity는 절대 API 응답용으로 직접 사용하지 말자! Response DTO를 따로 만들어 사용하는 습관이 순환 참조를 방지하고, 더 안전하고 명확한 API를 만들 수 있는 길이다.",
    "tags": "TIL JavaScript til",
    "url": "/til/2025-05-10-til/"
  },{
    "title": "[TIL] Sequence diagram, 아키텍처 다이어그래밍",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #53 📅 작성일: 2025-05-08 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 1️⃣ Sequence diagram 시스템 안에서 객체(또는 컴포넌트)들이 시간 흐름에 따라 어떤 메시지를 주고받는지를 표현한 다이어그램 누가 누구에게 언제 어떤 동작을 요청하는지 한눈에 보여줌 백엔드 실무에서 중요한 이유 내가 만든 API가 어떤 흐름으로 동작하는지 설명할 수 있게 해줌 팀원과 비즈니스 로직을 공유할 때 빠르게 파악 가능 복잡한 시스템에서도 디버깅/확장/테스트의 기반 자료가 됨 예시 : 2️⃣ 아키텍처 다이어그래밍 시스템 전체 구성과 컴포넌트 간 관계를 그림으로 표현한 것 백엔드에서는 서버, DB, API 게이트웨이, 클라이언틑 등 시스템 전체 구조를 말함 그리는 도구 draw.io Lucidchart https://aws.amazon.com/ko/what-is/architecture-diagramming/ -",
    "tags": "TIL Project til",
    "url": "/til/2025-05-08-til/"
  },{
    "title": "[TIL] Spring Boot Test 코드 작성",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #52 📅 작성일: 2025-05-07 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 Spring Boot Test 코드 작성 참고 블로그 링크 Given-When-Then 패턴을 기반으로 테스트 코드의 가독성과 목적을 명확히 하는 연습을 시작했다. import org.junit.jupiter.api.Test; public class MyServiceTest { @Test void 테스트이름_의미있게작성() { // 1. Given: 테스트 준비 (입력값, Mock 설정 등) // 2. When: 실제 테스트 대상 메서드 호출 // 3. Then: 결과 검증 (assert문 사용) } } 느낀 점 테스트 코드를 통해 서비스 로직을 더 명확하게 파악할 수 있었고, 테스트 코드가 일종의 문서처럼 동작한다는 점이 인상 깊었다. 실제 비즈니스 로직을 리팩토링할 때 테스트 코드가 잘 작성되어 있다면 훨씬 더 안전하게 수정이 가능하다는 것도 체감함. 추가 학습 포인트 @SpringBootTest, @WebMvcTest, @DataJpaTest 등 테스트 종류별 차이 Mocking 도구: @MockBean, Mockito, MockMvc 사용법 테스트 클래스 구조 정리: Service, Controller, Repository 각각에 맞는 테스트 전략 앞으로 기능을 개발할 때 무조건 테스트 코드부터 작성하는 습관을 들이자! 특히 WebClient 통신이나 예외 처리 로직은 꼭 단위 테스트로 검증할 수 있도록 설계하자.",
    "tags": "TIL Spring til",
    "url": "/til/2025-05-07-til/"
  },{
    "title": "[TIL] Git 협업 시 PR 대기 중 다음 기능 작업은 어떻게 해야할까?, @RequestB…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #51 📅 작성일: 2025-05-06 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 1️⃣ Git 협업 시 PR 대기 중 다음 기능 작업은 어떻게 해야할까? 티스토리에 첫 글을 올려봤다! (연휴의 소소한 재미..) 티스토리 첫 게시물 2️⃣ @RequestBody가 String을 받을 때 역직렬화를 하지 않는다..? @RequestBody는 일반적으로 JSON을 자바 객체로 역직렬화(deserialize) 하기 위해 사용된다. 하지만 파라미터 타입이 String이면, 역직렬화 과정을 거치지 않고 그냥 원본 요청 바디 내용을 그대로 문자열로 전달한다. @PostMapping(\"/echo\") public String echo(@RequestBody String body) { return body; // 요청 JSON 전체를 String으로 받는다 } 그래서 요청 바디가 JSON이라도 String으로 받으면 파싱되지 않고 JSON 문자열 그대로 처리됨. 실제 객체로 매핑하려면 DTO로 받아야 한다. public String echo(@RequestBody SomeDto dto) { ... } 3️⃣ Custom Exception 참조: SpringBoot Custom Exception 처리 velog 글 반복되는 예외 처리 코드를 줄이기 위해 커스텀 예외를 정의해 사용하는 방식. 예외 클래스를 RuntimeException을 상속해 만들고, 상황에 따라 적절한 에러 메시지와 상태 코드를 담아준다. public class CustomException extends RuntimeException { private final ErrorCode errorCode; public CustomException(ErrorCode errorCode) { super(errorCode.getMessage()); this.errorCode = errorCode; } public ErrorCode getErrorCode() { return errorCode; } } 그리고 @RestControllerAdvice와 @ExceptionHandler를 활용해 예외 발생 시 일관된 응답 형태로 처리할 수 있다. @RestControllerAdvice public class GlobalExceptionHandler { @ExceptionHandler(CustomException.class) public ResponseEntity&lt;ErrorResponse&gt; handleCustomException(CustomException e) { return ResponseEntity .status(e.getErrorCode().getStatus()) .body(new ErrorResponse(e.getErrorCode())); } } 예외 상황을 명확하게 정의하고, 중복 처리 로직을 줄일 수 있어서 실무에서 매우 유용하다는 느낌! 다음에는 ErrorCode enum을 활용한 설계 패턴도 같이 정리해보자.",
    "tags": "TIL Git til",
    "url": "/til/2025-05-06-til/"
  },{
    "title": "[TIL] WebFlux, WebClient",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #50 📅 작성일: 2025-05-05 🔄 최종 수정: 2025년 05월 22일 🍀 새롭게 배운 것 WebFlux RestTemplate로 작성했던 Gemini 통신 부분을 Webclient로 작성하려고 하니 공부해야 할 부분이 많았다. 일단 WebFlux를 공부하기 전에 관련 블로그 링크는 아래와 같아. HttpURLConnection, RestTemplate, WebClient » 논블로킹 vs 비동기 Spring WebFlux 비동기적으로 동작하는 논블로킹 방식으로, Client와 Server에서 reactive 스타일의 어플리케이션 개발을 도와주는 스프링 모듈 WebClient는 Spring WebFlux에서 HTTP Client로 사용되는 비동기 방식의 통신 도구 기존의 RestTemplate과 달리, I/O 작업을 블로킹하지 않고 Mono, Flux를 통해 비동기 스트림 처리가 가능 주요 특징 Netty 기반의 논블로킹 서버 구동 가능 (@EnableWebFlux로 설정) 작은 요청에도 적은 리소스로 대응 가능해, 고성능 시스템에 적합 데이터 처리 흐름이 Reactive Stream 기반으로 동작 기본 구성 요소 Mono&lt;T&gt;: 0 또는 1개의 데이터를 비동기적으로 처리 Flux&lt;T&gt;: 0개 이상의 데이터를 스트림 형태로 처리 예제 코드 WebClient client = WebClient.builder() .baseUrl(\"https://api.example.com\") .defaultHeader(HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE) .build(); Mono&lt;ResponseDto&gt; response = client.post() .uri(\"/gemini\") .bodyValue(requestDto) .retrieve() .bodyToMono(ResponseDto.class); 아직은 WebClient 내부 동작과 Mono/Flux 체계가 낯설지만, 기존 동기식 방식과 비교하면서 천천히 익히는 중. 테스트할 땐 .block()으로 동기화 가능하지만, 실제 운영 환경에선 꼭 지양해야 한다는 것도 기억! 나중에 제대로 정리해서 블로그 업데이트 예정",
    "tags": "TIL til",
    "url": "/til/2025-05-05-til/"
  },{
    "title": "[TIL] DTO 나누는 기준, Entity에서 DTO 생성하는 방식, @Valid",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #49 📅 작성일: 2025-04-30 🔄 최종 수정: 2025년 05월 21일 🍀 새롭게 배운 것 1️⃣ DTO 나누는 기준 DTO를 여러 개 만들다 보니, 어떤 경우에 새로 생성을 해야하고, 어떤 경우에 쓰던 DTO를 사용해도 되는건지 정확하게 알고싶었다. 깃블로그 정리 Response DTO에서도 도메인 모델은 같아도 API의 응답 목적에 따라 DTO를 다르게 한다는 것을 알게되었다. 예를 들어, |클래스|목적|어떤 API에 사용되는가| |——|—|—————| |PeerReviewDetailResponse|단일 리뷰의 상세 정보 제공|리뷰 생성 응답, 리뷰 상세 조회 등| |UserReviewSummaryResponse|특정 사용자가 받은 리뷰들의 종합 통계 정보 제공|사용자 리뷰 평균 조회 API| |ProjectReviewStatusResponse|프로젝트 내에서 리뷰가 완료되었는지 확인|프로젝트 리뷰 진행 상태 확인 API| 즉, 하나의 PeerReviewResponse로 모든 경우를 처리하면 과한 데이터가 응답되거나, 불필요한 필드를 채워야하는 문제가 생김 각 API의 의미, 응답 범위, 데이터의 성격이 다르기 때문에 분리를 해줘야 함 또한 너무 단순한 DTO를 별도로 여러 개 만드는 것이 오히려 복잡해지진않을까 고민했다. 단순해도 별도 DTO를 유지할 수 있는 이유 응답 목적이 분명히 다름 예를 들어, PeerReviewDetailResponse는 리뷰 하나하나의 전체 정보를 보여줌 UserReviewSummaryResponse는 집계 결과만 보여줌 ➡️ DTO는 목적에 따라 나눠야지, 포함된 데이터 수가 적다고 합치면 안됨 확장성 고려 오늘은 평균 점수와 코멘트만 보여주지만, 내일은 “피어리뷰 받은 날짜 리스트”, “리뷰 작성자 정보” 등이 추가될 수 있음 API 유지보수 용이 응답 스펙이 명확하게 고정된 하나의 DTO로 분리되어 있으면, 클라이언트와의 연동 시에도 변경 위험을 줄일 수 있음 어떤 API는 summary만 주고, 어떤 API는 리뷰 detail 리스트를 따로 주는 등 조합이 자유로움 응답 크기 / 성능 최적화 하나의 응답에 모든 리뷰 데이터를 다 담으면 리스트가 커짐 -&gt; 느려질 수 있음 필수정보만 담아 빠르고 가볍게 구현 가능 따라서 API 엔드포인트 별로, 응답 목적 별로 DTO를 나눠서 생성하는 것이 좋을 것 같다고 생각하게 되었다. 각 DTO가 명확한 책임을 가지게 하여, 가독성과 유지보수성을 향상시키는 방향이 좋은 방향! API 목적 = DTO 목적 plus, DTO는 View에 맞춰 설계해야 한다. DTO는 전달 목적에 맞게 필요한 정보만 포함해야 한다. 실제 사용자에게 보이지 않는 데이터를 포함하면 응답 크기 증가, 클라이언트/프론트 코드가 혼란스러움, 유지보수 시 헷갈림 2️⃣ Entity에서 DTO 생성하는 방식 Entity에서 DTO를 생성하는 방식 예시 코드 public record TestDto( String data1, String data2 ) { public static TestDto from(Entity entity) { return new TestDto(entity.getData1(), entity.getData2();) } } 장점 엔티티와 DTO간이 명확한 매핑 엔티티에서 DTO로 변환하는 로직이 한 곳에 집중되어 있어 매핑 로직이 명확함 일관성 항상 엔티티에서 DTO로 변환하는 방식이 일관되어 코트의 패턴이 일정 유지보수성 엔티티의 필드가 변경되면 DTO 변환 로직만 수정하면 되므로 유지보수가 상대적으로 쉬움 도메인 중심 설계 엔티티를 중심으로 데이터 흐름이 설계되어, DDD 방식에 더 적합 단점 DTO와 엔티티 사이의 강한 결합 DTO가 엔티티 구조에 의존하므로 결합도가 높다. 테스트 복잡성 엔티티없이 DTO를 테스트하기 어려움 파라미터로 DTO를 직접 생성하는 방식 예시 코드 public record TestDto( String data1, String data2 ){ public static TestDto from( String data1, String data2 ) { return new TestDto(data1, data2); } } 장점 낮은 결합도 DTO가 엔티티에 직접적으로 의존하지 않아 결합도 낮음 유연성 엔티티 외에도 다양항 소스에서 DTO를 생성할 수 있어 유연 테스트 용이성 엔티티 없이도 DTO 테스트 가능 서비스 계층의 자율성 서비스 계층에서 DTO생성 시 엔티티 변환 외에도 다양한 로직을 적용할 수 있음 엔티티 구조 변경에 영향 최소화 엔티티 내부 구조가 변경되어도 DTO 생성 로직은 서비스 계층에서만 수정 가능 단점 중복 코드 가능성 여러 곳에서 동일한 DTO를 생성하는 경우 중복 코드가 발생할 수 있음 일관성 유지 어려움 서로 다른 서비스에서 동일한 DTO를 다르게 생성할 수 있음 매핑 로직 분산 엔티티에서 DTO로 변환하는 로직이 여러 곳에 분산될 수 있음 3️⃣ @Valid 역할 해당 객체의 필드에 붙은 @Notnull, @Size, @Min등 유효성 검증(Validation) 어노테이션을 실행하게 함 사용 위치 @RequestBody, @ModelAttribute등에서 받은 객체의 값이 유효ㅏㄴ지 검사 예시 public record CreatePeerReviewRequest( @NotNull Long projectId, @Min(1) @Max(5) Integer technicalScore, ... ) {} 이렇게 DTO에 유효성 조건을 걸고 @Valid를 붙이면, 조건을 만족하지 못할 경우 400 Bad Request 응답이 자동 발생",
    "tags": "TIL til",
    "url": "/til/2025-04-30-til/"
  },{
    "title": "[Spring] DTO를 나누는 기준은 어떻게 고려해야할까?",
    "text": "API 응답을 위한 DTO는 왜 나눠야 하는가? 1. 하나의 도메인, 여러 개의 응답 목적 2. “필드 수”가 아니라 “의도”로 판단해야 한다 3. DTO 설계는 “View 기반”이어야 한다 4. DTO 분리의 장점 – 실무 중심으로 요약 결론 ✅ API 응답을 위한 DTO는 왜 나눠야 하는가? 서비스 개발을 하다 보면 DTO(Data Transfer Object)를 여러 개 만들게 된다. 처음에는 같은 도메인 모델에서 파생되는 응답 DTO라면 하나로 통일할 수 있지 않을까? 하는 생각이 들기도 한다. 하지만 실제로 API를 설계하고 클라이언트와 연동하는 과정을 겪어보면, DTO를 목적에 따라 나눠야 하는 이유가 분명히 보이기 시작한다. 1️⃣ 하나의 도메인, 여러 개의 응답 목적 실제로 PeerReview라는 동일한 도메인을 기반으로 하더라도, API마다 응답 목적이 전혀 다르다. 클래스 목적 사용되는 API PeerReviewDetailResponse 단일 리뷰의 상세 정보 제공 리뷰 생성 응답, 리뷰 상세 조회 UserReviewSummaryResponse 특정 사용자의 리뷰 통계 요약 사용자 리뷰 평균 조회 ProjectReviewStatusResponse 프로젝트 리뷰 진행 상태 확인 프로젝트별 리뷰 완료 여부 확인 이처럼 동일한 도메인 모델이더라도 응답의 대상, 범위, 표현 방식이 다르면 DTO는 분리되어야 한다. 하나의 PeerReviewResponse에 모든 필드를 때려넣고 공통으로 쓰다 보면, 어떤 API는 불필요한 데이터가 너무 많이 오가고, 어떤 API는 필요한 정보가 빠져 있어 클라이언트가 혼란을 겪는다. ❗️ “DTO 하나로 합쳐도 되지 않나요?” → 되긴 하지만, API의 명확한 역할과 응답 일관성을 해친다. 2️⃣ “필드 수”가 아니라 “의도”로 판단해야 한다 DTO를 나눌 때 흔히 하는 실수 중 하나가 “필드가 너무 적은데 굳이 따로 DTO로 만들어야 해?” 라는 의문이다. 내가 프로젝트를 하며 이런 고민을 계속 하고, 실제로 다른 사람들은 어떤 기준을 가지는지 찾아보다 이 글을 작성하게 되었다. 하지만 DTO는 포함된 데이터의 양이 아니라, 응답의 의도에 따라 나뉘어야 한다. 예시 비교 클래스 주요 필드 설명 UserReviewSummaryResponse 평균 점수, 리뷰 개수 사용자 요약 통계 PeerReviewDetailResponse 리뷰 항목별 점수, 작성자 정보, 날짜 상세 정보 조회용 이 두 DTO는 필드 수만 보면 합칠 수 있을 것 같지만, 하나는 요약 정보 (Summary), 하나는 상세 정보 (Detail) 제공이라는 근본적인 목적이 다르다. 또한, Summary는 추후 차트, 히스토그램, 트렌드 같은 집계 데이터를 추가하기에 더 적합한 형태이고, Detail은 사용자 경험 개선을 위한 리치한 UI 렌더링에 최적화된 형태로 확장될 수 있다. 3️⃣ DTO 설계는 “View 기반”이어야 한다 DTO는 도메인을 있는 그대로 노출하는 것이 아니라, API View Layer의 역할과 책임에 맞게 정보를 재가공해 전달하는 것이 목적이다. 즉, “어떤 정보를 어떻게 보여줄지”에 따라 설계되어야 한다. 잘못된 설계 예 불필요하게 내부 ID, 시스템 시간, 관리자용 정보 등을 포함한 DTO 클라이언트에 노출되면 혼란을 주거나, 보안상 문제될 수 있는 필드 포함 좋은 설계 예 사용자에게 필요한 정보만 간결하게 포함 실제 프론트 UI와 일치하는 정보 구조 데이터의 “의미”와 “구성 방식”이 API 목적과 맞아떨어짐 🧠 DTO는 단순히 데이터를 전달하는 구조체가 아니라, **“API 응답 설계 그 자체”**라는 것을 항상 기억해야 한다. 4️⃣ DTO 분리의 장점 – 실무 중심으로 요약 이유 설명 명확한 책임 분리 각 API의 목적에 따라 DTO도 명확히 구분되어 유지보수가 쉬움 클라이언트 연동 안정성 응답 구조가 고정되기 때문에 프론트엔드와의 계약(Contract)이 안정됨 확장성 새로운 요구사항이 생겼을 때 불필요한 필드 추가 없이 필요한 DTO만 수정하면 됨 성능 최적화 불필요한 필드 제거로 응답 크기 감소 → 네트워크 비용 감소 테스트 단순화 DTO 단위 테스트, API 응답 테스트가 더 명확하고 간결해짐 ✅ 결론: API 목적 = DTO 목적 하나의 API가 명확한 역할을 가지듯, 그 API가 사용하는 DTO도 명확한 책임을 가져야 한다. DTO는 설계의 산물이면서, 동시에 클라이언트와의 약속이다. 따라서 필드 개수가 적다고 DTO를 합치는 건 설계적 실수일 수 있으며, 응답 데이터는 목적, 의미, 유지보수, 확장성 관점에서 설계되어야 한다. ✍️ 마무리 한 줄 요약 DTO는 “얼마나 많은 데이터를 담는가”보다 “어떤 목적의 데이터를 담는가”가 더 중요하다.",
    "tags": "spring",
    "url": "/spring/2025-04-30-dto-division/"
  },{
    "title": "[TIL] 정적 팩토리 메서드, 모놀로닉 아키텍쳐",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #48 📅 작성일: 2025-04-29 🔄 최종 수정: 2025년 05월 20일 🍀 새롭게 배운 것 정적 팩토리 메서드 (static factory method) 클래스의 public 생성자로 객체를 생상하는 것이 아닌, 메서드를 통해 객체를 생성하는 것 에러를 조기에 발생시키고 객체 생성 과정에서 잘못된 인자나 누락된 필드 등으로 인한 문제를 “컴파일 타임”에 더 쉽게 잡을 수 있게 도와준다. 생성자를 사용할 경우 User user = new User(\"nano\"); // 컴파일은 되지만, 런타임에 NullPointerException 가능 생성자의 시그니쳐가 여러 개 있거나, 필드가 많고 순서가 헷갈리는 경우, 컴파일러는 단순히 시그니처가 맞으면 OK 판단 잘못된 값, 누락된 필드 등은 컴파일러가 알 수 없고, 런타임 에러로 이어짐 정적 팩토리 메서드를 사용할 경우 null, 잘못된 형식, 비즈니스 룰 위반 등을 검증하는 방어적 메서드 내부에서 체크 가능함 public static User of(String username, String email) { if (username == null || email == null) { throw new IllegalArgumentException(\"username과 email은 필수입니다.\"); } return new User(username, email); } 에러를 조기에 발생시키고 명확한 메시지를 제공할 수 있음 장점 (“이펙티브 자바” 책 참고) 이름을 가질 수 있다. 생성자에 넘기는 매개변수와 생성자 자체만으로는 반환될 객체의 특성을 제대로 설명하기 힘들다. new라는 키워드를 통해 객체를 생성하는 생성자는 내부 구조를 잘 알고 있어야 목적에 맞게 객체를 생성할 수 있다. BigInteger(int, int, Random) 정적 팩토리 메서드는 객체의 특성을 설명할 이름을 붙일 수 있다. BigInteger.probablePrime 호출될 때마다 인스턴스를 새로 생성하지 않아도 된다. 인스턴스가 언제 살아있게 할지 통제할 수 있다. 반환 타입의 하위 타입 객체를 반환할 수 있다. API를 작게 유지할 수 있게 해주며 엄청난 유연성을 가질 수 있게 해준다. 입력 매개변수에 따라 매번 다른 클래스의 객체를 반환할 수 있다. 반환 타입의 하위 타입이기만 하면 어떤 클래스의 객체를 반환하든 상관없다. 정적 팩터리 메서드를 작성하는 시점에는 반환할 객체의 클래스가 존재하지 않아도 된다. 대표적인 정적 팩토리 메소드 이름 | 메서드 이름 | 의미 | 예시 | | :———— | :———————————————– | :————————– | | of | 여러 파라미터를 받아 객체를 생성할 때 사용 | User.of(name, email) | | from | 하나의 다른 객체를 받아 변환/생성할 때 사용 | User.from(UserDto dto) | | valueOf | 변환이나 타입 캐스팅 성격이 강할 때 사용 | Integer.valueOf(\"123\") | | getInstance | 이미 생성된 인스턴스를 반환하거나, 새로운 인스턴스를 반환할 때 사용 | Connection.getInstance() | | newInstance | 매번 새로운 인스턴스를 반환할 때 사용 | Class.newInstance() | | create | 새롭게 무엇인가를 생성할 때 사용 | User.create(name, email) | | build | 복잡한 객체를 조립(Build)해서 반환할 때 사용 (주로 Builder 패턴과 연결) | Order.build(itemList) | | copyOf | 기존 객체의 복사본을 생성할 때 사용 | List.copyOf(originalList) | // DTO → Entity 변환 public static User from(UserRequestDto dto) { return new User(dto.getUsername(), dto.getEmail()); } // 직접 필드 입력해서 생성 public static User of(String username, String email) { return new User(username, email); } Monolithic Arichitecture (모놀로닉 아키텍쳐) 모든 구성 요소(기능)가 하나의 애플리케이션/프로세스 내에서 동작하는 아키텍쳐 일반적으로 하나의 코드베이스, 하나의 빌드 단위, 하나의 배포 단위로 구성됨 예: 사용자 인증, 게시글, 댓글, 결제 등의 기능이 한 프로젝트 안에 모두 들어감 구조 예시 [사용자 요청] ↓ [단일 서버 애플리케이션] ├─ 사용자 인증 모듈 ├─ 게시글 처리 모듈 ├─ 결제 모듈 └─ DB 처리 모듈 ↓ [단일 DB] 장점 단순한 개발 : 하나의 코드베이스로 전체 시스템을 빠르게 개발 가능 쉬운 테스트 : 통합된 환경이라 단일 테스트 환경 세팅이 쉬움 쉬운 배포 : 전체 기능이 한 번에 빌드되고 배포됨 직관적인 구조 : 초기에 설계 및 학습이 용이함 단점 규모 확장이 어려움 : 서비스가 커질수록 모듈 간 의존도가 커지고 유지보수가 어려워짐 기능 하나 수정 시 전체 재배포 : 배포 위험도 증가, 릴리즈 속도 저하 장애 전파 가능성 : 하나의 모듈 에러가 전체 애플리케이션에 영향을 줌 기술 스택 제한 : 모듈 별로 다른 언어나 프레임워크 적용이 어려움 언제 사용하면 좋은가? 스타트업이나 초기 프로직트 : 빠르게 MVP(Minimun Viable Product)를 만들고 검증이 필요한 상황 개발 인력이 적거나 복잡도가 낮은 시스템 배포타 운영 환경이 단순한 경우 실제 사용 예시 전통적인 기업 내부 시스템 초기 단계의 웹 서비스 (블로그, 쇼핑몰 등) MSA와 비교 | 구분 | Monolithic | MSA| |——|———–|——–| | 아키텍쳐 | 단일 애플리케이션 | 각 기능이 독립적인 서비스| |개발| 단일 프로젝트 | 서비스 별로 독립 개발| |배포| 전체 배포 | 부분 배포 가능| |확장성| 전체 확장 | 기능 단위 확장| |유지 보수| 복잡해짐 | 모듈화로 유연 | |초기 개발|빠름|상대적으로 복잡| 🦄 느낀 점 정적 팩토리 매서드에 대해 이해가 부족해 이펙티브 자바 책을 서점에서 사서 읽어봤다. 책이 아직 어려워서 공부를 계속 하면서 프로젝트를 진행해야겠다. 좀 더 이해가 되었을 때 블로그에도 정리해보겠다! 🐬 깃블로그 정리 []",
    "tags": "TIL til",
    "url": "/til/2025-04-29-til/"
  },{
    "title": "[TIL] Spring Cloud Gateway",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #47 📅 작성일: 2025-04-28 🔄 최종 수정: 2025년 05월 02일 🍀 새롭게 배운 것 Spring Cloud Gateway 아래의 문제 상황 해결을 위한 해결방법 앞으로 좀 더 공부하며 차근차근 구현 할 예정이다. 🍎 오늘의 문제 상황 현재 버티 서비스는 백엔드 서버의 도메인이 2개로 되어있다. 프론트와 연동을 하기 직전 과정에서 CORS 문제 해결과 이 과정에서 Render배포의 리소스 제약 문제를 어떤 식으로 해결하는 것이 좋은지 아래 내용과 같이 조사해보았다. 현재 버티 구조 서버 구조: 서버 도메인 URL이 2개 (회원 정보는 한쪽에만 존재) 프론트엔드: 도메인 URL이 1개 인증 방식: JWT 기반 인증 구현 중 문제점: 사용자 프로필 업데이트 기능이 있어 JWT에 프로필 정보 포함 어려움 프론트엔드와 백엔드 간 CORS 이슈 발생 가능 Render 프리티어 환경으로 리소스 제약 존재 🦄 해결 방안 모색 API Gateway 패턴 도입 목적: 프론트엔드에 단일 진입점 제공, CORS 문제 해결 구현 방식: Spring Cloud Gateway 활용 장점: 단일 도메인으로 프론트엔드 요청 처리 중앙화된 인증/인가 처리 요청 라우팅 관리 용이 회원 정보 공유 방식 현재 버티 서비스는 JWT에 프로필 정보를 포함하기 어려운 상황이므로: (로그인 후 사용자 프로필을 업데이트 하기 때문) 서비스 간 직접 통신 방식 기본 개념: 회원 정보가 필요할 때 회원 서비스의 API를 직접 호출하여 최신 정보를 가져오는 방식 구현 내용: 회원 서비스에 내부용 API 엔드포인트 추가 (예: /api/internal/users/{userId}) 이 API는 외부 접근이 아닌 서비스 간 통신용으로만 사용 기능 서비스에서 특정 사용자 정보가 필요할 때 이 API를 호출하여 최신 정보 획득 내부 API 키를 사용해 인증 (서비스 간 통신이 안전하게 이루어지도록) 🐬 깃블로그 정리 좀 더 자세한 정리",
    "tags": "TIL Spring Project Cloud til",
    "url": "/til/2025-04-28-til/"
  },{
    "title": "[버티] 버티 서비스를 위한 Spring Boot MSA 구현 방식 조사",
    "text": "1. 현재 버티 서비스 상황 분석 2. MSA 구현 방안 2.1 API Gateway 패턴 도입 2.2 회원 정보 공유 방식 3. Render 프리티어 환경 최적화 방안 4. 단계적 구현 전략 5. 결론 현재 버티 서비스는 백엔드 서버의 도메인이 2개로 되어있다. 프론트와 연동을 하기 직전 과정에서 CORS 문제 해결과 이 과정에서 Render배포의 리소스 제약 문제를 어떤 식으로 해결하는 것이 좋은지 아래 내용과 같이 조사해보았다. 1. 현재 버티 서비스 상황 분석 서버 구조: 서버 도메인 URL이 2개 (회원 정보는 한쪽에만 존재) 프론트엔드: 도메인 URL이 1개 인증 방식: JWT 기반 인증 구현 중 문제점: 사용자 프로필 업데이트 기능이 있어 JWT에 프로필 정보 포함 어려움 프론트엔드와 백엔드 간 CORS 이슈 발생 가능 Render 프리티어 환경으로 리소스 제약 존재 2. MSA 구현 방안 2.1 API Gateway 패턴 도입 목적: 프론트엔드에 단일 진입점 제공, CORS 문제 해결 구현 방식: Spring Cloud Gateway 활용 장점: 단일 도메인으로 프론트엔드 요청 처리 중앙화된 인증/인가 처리 요청 라우팅 관리 용이 2.2 회원 정보 공유 방식 현재 버티 서비스는 JWT에 프로필 정보를 포함하기 어려운 상황이므로: (로그인 후 사용자 프로필을 업데이트 하기 때문) 서비스 간 직접 통신 방식 기본 개념: 회원 정보가 필요할 때 회원 서비스의 API를 직접 호출하여 최신 정보를 가져오는 방식 구현 내용: 회원 서비스에 내부용 API 엔드포인트 추가 (예: /api/internal/users/{userId}) 이 API는 외부 접근이 아닌 서비스 간 통신용으로만 사용 기능 서비스에서 특정 사용자 정보가 필요할 때 이 API를 호출하여 최신 정보 획득 내부 API 키를 사용해 인증 (서비스 간 통신이 안전하게 이루어지도록) 캐싱 전략 적용 문제점: 매번 API를 호출하면 Render 프리티어 환경에서 성능 저하 발생 해결책: 자주 조회되는 회원 정보를 메모리에 임시 저장(캐싱) 첫 번째 조회 시에만 API 호출, 이후에는 캐시에서 빠르게 조회 정해진 시간(예: 15분) 후 캐시 만료하여 일정 주기로 최신 정보 반영 사용자가 프로필을 업데이트하면 해당 사용자의 캐시만 즉시 무효화하는 API 호출 장애 대응 방안 문제점: 회원 서비스가 일시적으로 장애가 발생하면 기능 서비스도 영향 받음 해결책: Circuit Breaker 패턴: 회원 서비스 장애 감지 시 API 호출을 일시 중단하고 기본 정보 반환 예를 들어, 회원 이름을 조회할 수 없으면 “Guest”와 같은 기본값 사용 재시도 제한 및 타임아웃 설정으로 불필요한 대기 시간 방지 이 방식을 통해 JWT에 모든 회원 정보를 담지 않아도 최신 정보를 안전하게 공유하고, 성능과 안정성을 확보할 수 있습니다. 3. Render 프리티어 환경 최적화 방안 리소스 제약이 있는 Render 프리티어 환경에 맞춘 최적화 전략: 경량화된 MSA 구조: 필수적인 도메인만 분리 (회원 서비스 + 기능 서비스) 최소한의 서비스 디스커버리 구조 사용 성능 최적화: 데이터베이스 커넥션 풀 크기 제한 (5-10개) API 요청 타임아웃 짧게 설정 (3초 내외) 캐시 크기 제한 (500 항목 이내) Lazy Loading 적용하여 필요한 데이터만 로딩 에러 처리 강화: 서비스 간 통신 실패 시 폴백(fallback) 메커니즘 구현 재시도 횟수 제한 (최대 3회) 4. 단계적 구현 전략 Burty 서비스에 MSA를 점진적으로 도입하기 위한 단계: 4.1 1단계: API Gateway 구현 Spring Cloud Gateway 기반 게이트웨이 서비스 구축 라우팅 규칙 설정 (회원/기능 서비스 분리) JWT 토큰 검증 필터 구현 CORS 설정 적용 4.2 2단계: 서비스 간 통신 구현 회원 서비스에 내부 API 엔드포인트 추가 기능 서비스에 RestTemplate 설정 서비스 간 인증 메커니즘 적용 4.3 3단계: 캐싱 적용 인메모리 캐시 설정 회원 정보 캐싱 서비스 구현 캐시 무효화 API 구현 4.4 4단계: 장애 대응 패턴 적용 Circuit Breaker 패턴 구현 재시도 메커니즘 추가 로깅 및 모니터링 강화 5. 결론 Burty 서비스의 현재 상황과 Render 프리티어 환경을 고려할 때: JWT만으로는 회원 정보 공유에 한계가 있으므로, 서비스 간 API 통신과 캐싱을 조합하는 것이 적합 API Gateway 패턴을 통해 프론트엔드의 CORS 문제 해결 및 단일 진입점 제공 리소스 제약을 고려한 경량화된 MSA 구조와 성능 최적화 필요 단계적 구현을 통해 점진적으로 MSA 아키텍처로 전환",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-04-28-diary/"
  },{
    "title": "[TIL] Spring Boot Pageable, PageableDefault 어노테이션",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #46 📅 작성일: 2025-04-22 🔄 최종 수정: 2025년 05월 02일 🍀 새롭게 배운 것 Spring Boot Paging 프로젝트에서 커뮤니티 부분을 구현하며 게시글 목록을 조회할 때, 어떤 식으로 반환해야하는지 찾아보다 Pagination을 알게 되었다. Spring JPA 라이브러리의 Pageable을 이용하는 방법을 사용했다. Pageable Spring JPA에서 DB 쿼리에 쉽고 유연하게 limit쿼리를 사용할 수 있게 해준다. 특히 JPA를 사용할 때, 자동으로 Pageable 타입의 변수를 넘겨주면 JPA가 DB에 접근해 데이터를 가져올 때 자동으로 limit조건을 붙여 데이터를 가져온다. 참고 블로그 PageableDefault 어노테이션의 역할 @PageableDefault(size = 10) 어노테이션은 다음과 같은 역할을 합니다: 기본 페이지 크기 설정: 클라이언트가 별도의 페이지 크기(size 파라미터)를 지정하지 않았을 때 기본적으로 페이지당 10개의 항목을 반환하도록 설정합니다. 기본값 제공: 클라이언트가 페이징 관련 파라미터를 명시적으로 지정하지 않았을 때 사용할 기본값을 제공합니다. 컨트롤러 메서드 간소화: 매번 페이징 관련 파라미터를 검증하고 기본값을 설정하는 코드를 작성하지 않아도 됩니다. PageableDefault의 주요 속성 @PageableDefault는 다음과 같은 속성을 지원합니다: @PageableDefault( size = 10, // 페이지당 항목 수 (기본값: 10) page = 0, // 시작 페이지 번호 (기본값: 0, 첫 페이지는 0부터 시작) sort = {}, // 정렬 기준 필드명 direction = Sort.Direction.ASC // 정렬 방향 (기본값: 오름차순) ) Pageable 관련 알아야 할 개념들 1. Pageable 인터페이스 Pageable은 페이징 정보를 캡슐화하는 Spring Data의 인터페이스입니다. 주요 메서드는 다음과 같습니다: getPageNumber(): 현재 페이지 번호 (0부터 시작) getPageSize(): 페이지 크기 getSort(): 정렬 정보 getOffset(): 전체 결과에서의 오프셋 (첫 항목의 위치) next(), previous(), first(): 다음/이전/첫 페이지의 Pageable 객체 생성 2. Page 인터페이스 Page&lt;T&gt;는 페이징된 결과를 담는 인터페이스로, 다음과 같은 메서드를 제공합니다: getContent(): 현재 페이지의 내용(리스트) getTotalElements(): 전체 항목 수 getTotalPages(): 전체 페이지 수 getNumber(): 현재 페이지 번호 (0부터 시작) getSize(): 페이지 크기 hasNext(), hasPrevious(): 다음/이전 페이지 존재 여부 3. 요청 파라미터 클라이언트는 다음과 같은 요청 파라미터를 통해 페이징 정보를 전달할 수 있습니다: page: 페이지 번호 (0부터 시작) size: 페이지 크기 sort: 정렬 기준과 방향 (예: sort=createdAt,desc) 4. Sort 클래스 Sort는 정렬 정보를 나타내는 클래스로, 다음과 같은 방식으로 사용됩니다: Sort.by(Direction.DESC, \"createdAt\") 여러 필드로 정렬할 때: Sort.by( Sort.Order.desc(\"createdAt\"), Sort.Order.asc(\"title\") ) 5. PageRequest 클래스 PageRequest는 Pageable의 구현체로, 다음과 같이 생성할 수 있습니다: PageRequest.of(0, 10, Sort.by(Direction.DESC, \"createdAt\")) 6. JpaRepository에서의 사용 JpaRepository는 페이징을 지원하는 메서드를 제공합니다: Page&lt;Entity&gt; findAll(Pageable pageable); Page&lt;Entity&gt; findByField(String value, Pageable pageable); 코드에서 보이는 findAllByOrderByCreatedAtDesc(Pageable pageable)와 같은 메서드는 이러한 패턴을 따르고 있습니다. 7. 커스텀 쿼리와 페이징 @Query 어노테이션으로 작성한 JPQL 쿼리에서도 Pageable 파라미터를 사용할 수 있습니다: @Query(\"SELECT p FROM Post p WHERE p.title LIKE %:keyword%\") Page&lt;Post&gt; searchByTitle(@Param(\"keyword\") String keyword, Pageable pageable); 실제 동작 방식 제공된 코드에서 getPosts 메서드는 다음과 같이 동작합니다: 클라이언트가 /posts?page=1&amp;size=20&amp;sort=viewCount,desc와 같은 요청을 보내면, Spring은 이 파라미터를 Pageable 객체로 변환합니다. 만약 클라이언트가 size 파라미터를 지정하지 않았다면, @PageableDefault(size = 10)에 따라 기본값 10이 사용됩니다. PostService의 getPosts 메서드에 이 Pageable 객체가 전달되고, 이것은 다시 PostRepository의 적절한 메서드로 전달됩니다. 데이터베이스 쿼리는 LIMIT와 OFFSET 절을 포함하여 페이징을 구현합니다. 예를 들어, page=1&amp;size=10이라면 SQL에서는 LIMIT 10 OFFSET 10과 같이 변환됩니다. 결과는 Page&lt;PostDto.ListResponse&gt; 객체로 반환되며, 이 객체는 현재 페이지의 내용뿐만 아니라 전체 페이지 수, 전체 항목 수 등의 메타데이터도 포함합니다. 예제 응답 형태 API 응답은 다음과 같은 JSON 형태로 반환됩니다: { \"content\": [ { \"id\": 1, \"title\": \"게시글 1\", ... }, { \"id\": 2, \"title\": \"게시글 2\", ... }, ... ], \"pageable\": { \"sort\": { \"empty\": false, \"sorted\": true, \"unsorted\": false }, \"offset\": 10, \"pageNumber\": 1, \"pageSize\": 10, \"paged\": true, \"unpaged\": false }, \"last\": false, \"totalElements\": 42, \"totalPages\": 5, \"size\": 10, \"number\": 1, \"sort\": { \"empty\": false, \"sorted\": true, \"unsorted\": false }, \"first\": false, \"numberOfElements\": 10, \"empty\": false } 최적화 고려사항 카운트 쿼리 최적화: 항목이 많은 경우 totalElements를 계산하기 위한 COUNT 쿼리가 성능에 영향을 줄 수 있습니다. 필요에 따라 countQuery 최적화를 고려해야 합니다. 인덱스 활용: 정렬 및 필터링에 사용되는 필드에 적절한 인덱스를 생성해야 합니다. 페이지 사이즈 제한: 클라이언트가 지나치게 큰 페이지 크기를 요청하지 못하도록 제한할 수 있습니다. Pageable 관련 추가 정보 Pageable 파라미터를 사용하는 메서드는 자동으로 spring-data-commons의 PageableHandlerMethodArgumentResolver에 의해 처리됩니다. 애플리케이션 전체에서 페이징 기본값을 변경하려면 application.properties 또는 application.yml에서 설정할 수 있습니다: spring: data: web: pageable: default-page-size: 20 max-page-size: 100 one-indexed-parameters: true # 페이지 번호를 1부터 시작하도록 설정 RESTful API에서 페이징 정보를 전달하는 다른 방법으로는 헤더 방식, 경로 변수 방식 등이 있지만, Spring Data는 기본적으로 쿼리 파라미터 방식을 사용합니다.",
    "tags": "TIL Spring til",
    "url": "/til/2025-04-22-til/"
  },{
    "title": "[TIL] PATCH vs PUT, 0-1 BFS (동작방식 gif 포함!)",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #45 📅 작성일: 2025-04-21 🔄 최종 수정: 2025년 05월 02일 🍀 새롭게 배운 것 PUT과 PATCH의 차이 둘 다 리소스를 수정할 때 사용하는 HTTP 메서드이지만 차이점이 있다. 자세한 설명은 깃블로그 정리에 있습니다. (코드 예시, 비유 포함) ✅ 1. 기본 개념 항목 PUT PATCH 전체 or 일부 전체 대체 일부만 수정 누락된 필드 삭제될 수 있음 무시하고 유지됨 멱등성(Idempotent) 있음 (여러 번 해도 같은 결과) 보장 X (실행 방식에 따라 달라질 수 있음) 용도 새로운 리소스 생성 or 전체 업데이트 부분 업데이트에 특화됨 ✅ 2. 실무 팁 클라이언트가 전체 데이터를 항상 알고 있고, 전체 리소스를 대체해야 할 경우 → PUT 일부 필드만 수정할 때 → PATCH 0-1 BFS 코딩 테스트 준비를 하다가 0-1 BFS가 기본의 BFS와 어떤 점이 다른지 어떻게 해결해야하는지 잘 모르겠어서 정리를 해보았다. ✅ 1. 기본 개념 0-1 BFS는 간선의 가중치가 0 또는 1인 경우에만 사용할 수 있다. deque를 이용한다. 일반 BFS는 queue를 사용하지만, 0-1 BFS는 deque를 사용 간선의 가중치가 0인 경우 -&gt; 덱의 앞에 넣음 간선의 가중치가 1인 경우 -&gt; 덱의 뒤에 넣음 이렇게 하면 다익스트라처럼 우선순위를 정하지 않아도 자연스럽게 최단 경로가 먼저 탐색된다. 항상 현재까지의 최단 거리가 가장 짧은 노드부터 처리된다. 시간 복잡도는 O(V+E)로, 다익스트라 알고리즘(O(ElogV))보다 효율적이다. ✅ 2. 동작 원리 0-1 BFS 알고리즘은 다음과 같은 절차로 동작: 초기화: 시작 노드의 거리를 0으로, 나머지 노드의 거리를 무한대로 설정합니다. 시작 노드를 덱에 넣습니다. 반복 단계: 덱이 비어있지 않은 동안 다음을 반복합니다: 덱의 앞에서 노드를 꺼냅니다. 해당 노드의 모든 인접 노드에 대해: 가중치가 0인 간선이면: 인접 노드의 거리를 업데이트하고 덱의 앞에 추가합니다. 가중치가 1인 간선이면: 인접 노드의 거리를 업데이트하고 덱의 뒤에 추가합니다. 종료: 모든 노드에 대한 최단 거리가 계산됩니다. ✅ 3. 0-1 BFS의 응용 문제 0-1 BFS는 다음과 같은 상황에서 유용하게 사용된다: 가중치가 0 또는 1인 그래프에서의 최단 경로 찾기 격자(Grid) 기반 경로 찾기 문제 (특히 일부 이동에 비용이 없는 경우) 상태 전이 문제 (상태 간 이동 비용이 0 또는 1인 경우) 이 알고리즘을 사용하면 다익스트라 알고리즘보다 더 효율적으로 최단 경로를 찾을 수 있으며, 특히 가중치가 0과 1만 있는 그래프에서 O(V+E) 시간 복잡도로 동작하기 때문에 매우 빠르다. ✅ 4. 대표적인 문제 백준 1261 - 알고스팟 벽을 부수는 비용이 1, 안 부수는 건 0 → 0-1 BFS 사용 백준 13549 - 숨바꼭질 3 순간이동은 시간 0, 걷는 건 시간 1 → 0-1 BFS로 해결 LeetCode 847 - Shortest Path Visiting All Nodes (비트마스킹 + 0-1 BFS 가능) ✅ 5. 기본 예시 코드 import java.util.*; public class ZeroOneBFS { static class Edge { int to, weight; public Edge(int to, int weight) { this.to = to; this.weight = weight; } } public static int[] zeroOneBFS(List&lt;List&lt;Edge&gt;&gt; graph, int start) { int n = graph.size(); int[] dist = new int[n]; Arrays.fill(dist, Integer.MAX_VALUE); dist[start] = 0; Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;(); deque.add(start); while (!deque.isEmpty()) { int node = deque.pollFirst(); for (Edge edge : graph.get(node)) { int neighbor = edge.to; int weight = edge.weight; if (dist[neighbor] &gt; dist[node] + weight) { dist[neighbor] = dist[node] + weight; if (weight == 0) { deque.addFirst(neighbor); } else { deque.addLast(neighbor); } } } } return dist; } public static void main(String[] args) { int n = 4; // 노드 개수 List&lt;List&lt;Edge&gt;&gt; graph = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) graph.add(new ArrayList&lt;&gt;()); // 예시 그래프 (0-based index) graph.get(0).add(new Edge(1, 0)); graph.get(0).add(new Edge(3, 1)); graph.get(1).add(new Edge(2, 1)); graph.get(3).add(new Edge(2, 0)); int[] dist = zeroOneBFS(graph, 0); System.out.println(\"최단 거리 배열: \" + Arrays.toString(dist)); } }",
    "tags": "TIL Algorithm til",
    "url": "/til/2025-04-21-til/"
  },{
    "title": "[Spring] PATCH vs PUT",
    "text": "1. 기본 개념 2. 예시로 비교해보기 3. 핵심 차이 정리 4. 비유로 이해하기 5. 실무 팁 둘 다 리소스를 수정할 때 사용하는 HTTP 메서드이지만 차이점이 있다. ✅ 1. 기본 개념 메서드 의미 리소스를 어떻게 수정? PUT 리소스를 “통째로 교체” 전체를 새 값으로 대체 PATCH 리소스를 “부분만 수정” 바뀐 부분만 업데이트 ✅ 2. 예시로 비교해보기 📦 가상의 리소스 – 사용자 프로필 { \"name\": \"Sungwoo\", \"age\": 27, \"email\": \"sungwoo@example.com\" } 🟩 PUT 요청 예시 PUT /users/1 Content-Type: application/json { \"name\": \"Sungwoo\", \"age\": 28, \"email\": \"sungwoo@example.com\" } 이 요청은 기존 리소스를 통째로 대체함. 기존 값 중 하나라도 빠지면, 그 필드는 삭제된 것으로 간주될 수 있다. 🟦 PATCH 요청 예시 PATCH /users/1 Content-Type: application/json { \"age\": 28 } 이 요청은 age 필드만 수정하고 나머지(name, email)는 그대로 유지된다. ✅ 3. 핵심 차이 정리 항목 PUT PATCH 전체 or 일부 전체 대체 일부만 수정 누락된 필드 삭제될 수 있음 무시하고 유지됨 멱등성(Idempotent) 있음 (여러 번 해도 같은 결과) 보장 X (실행 방식에 따라 달라질 수 있음) 용도 새로운 리소스 생성 or 전체 업데이트 부분 업데이트에 특화됨 🎨 4. 비유로 이해하기 📘 비유: “이력서 제출하기” PUT은 새로운 이력서 전체를 회사에 제출해서 기존 이력서를 완전히 교체하는 것. 회사에 제출한 파일을 통째로 새로 바꾸는 느낌! PATCH는 기존 이력서에서 전화번호 한 줄만 수정해서 보낸다고 생각하면 됨. “전화번호 바뀌었어요” 라고 알리는 식. ✅ 5. 실무 팁 클라이언트가 전체 데이터를 항상 알고 있고, 전체 리소스를 대체해야 할 경우 → PUT 일부 필드만 수정할 때 → PATCH",
    "tags": "spring",
    "url": "/spring/2025-04-21-patch-put/"
  },{
    "title": "[TIL] Omit, Clean URL, Query String, Tuple, POJO, VO,…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #44 📅 작성일: 2025-04-19 🔄 최종 수정: 2025년 05월 02일 🍀 새롭게 배운 것 1. Omit 뜻: 무언가를 제외하다, 빼다는 의미 개발에서는? TypeScript나 Java 등에서 객체를 다룰 때, 특정 필드만 제외한 새 타입이나 새 객체를 만들 때 사용 예시 (JavaScript/TypeScript): type User = { id: number; name: string; password: string }; type PublicUser = Omit&lt;User, \"password\"&gt;; → PublicUser는 User에서 password만 빠진 타입이다. Java에서는 TypeScript처럼 Omit기능이 직접 있지는 않음. 하지만 “DTO를 따로 만들어서 필요한 필드만 남기는 방식”으로 비슷하게 사용 즉, Java에서 Omit이란 “필요없는 필드를 빼고 새 클래스를 만드는 것”으로 해석함 ✅ 정리: 특정 속성을 빼고 다루는 것을 “Omit”이라고 한다. 2. Clean URL (Path Variable) 뜻: 주소(URL)을 깔끔하게, 의미 있게 만든 것. 개발에서는? 리소스(데이터) 식별을 URL 경로로 표현하는 걸 말한다. (파라미터를 경로에 깔끔하게 넣는다.) 예시: GET /users/123 → 123번 사용자를 조회하는 요청 (Path Variable = 123) ✅ 정리: /detail?id=123처럼 지저분하게 하지 않고, /detail/123처럼 리소스를 주소 안에 자연스럽게 표현하는 게 Clean URL 3. Query String (Search Parameter) 뜻: ? 뒤에 붙는 키-값 쌍. 개발에서는? 데이터 검색, 필터링, 옵션 설정 등에 주로 사용. 예시: GET /products?category=shoes&amp;sort=price → 카테고리=신발, 가격순 정렬이라는 의미. ✅ 정리: 검색조건이나 옵션을 전달할 때 ?key=value&amp;key2=value2처럼 붙이는 게 Query String 4. HTTP Header + JWT HTTP Header: 요청(Request)이나 응답(Response)의 추가 정보를 담는 곳. 예: 인증 정보, 요청 포맷, 토큰 등. JWT (JSON Web Token): 로그인한 사용자인지 증명하는 토큰. Header + Payload + Signature로 구성된다. 보통 HTTP Header 안에 넣어서 서버에 보냄. 예시: Authorization: Bearer eyJhbGciOiJIUzI1... → 요청 헤더에 JWT를 담아 보낸다. ✅ 정리: JWT는 로그인 토큰이고, HTTP Header에 넣어서 서버에 인증정보를 전달한다. 5. Tuple, POJO, VO, Instance Tuple: 여러 데이터(타입 다를 수 있음)를 고정된 순서로 묶은 것. 주로 TypeScript, Python 등에서 사용. 예: (1, \"apple\") POJO (Plain Old Java Object): 특별한 규칙 없이, 그냥 순수한 Java 객체. @Entity, @Component 이런 거 없는 심플한 객체를 말함. VO (Value Object): “값” 자체를 의미하는 객체. 이름이 같으면 같은 것으로 취급하고, 변하지 않는(immutable) 게 일반적이다. 예: Money, Address Instance: 클래스로부터 실제로 만들어진 메모리 상의 객체. 예: new User(\"sungwoo\") → User 인스턴스 ✅ 정리: | 용어 | 설명 | |:—-|:—-| | Tuple | 서로 다른 타입을 순서대로 묶은 데이터 | | POJO | 아무것도 특별하지 않은 순수 Java 객체 | | VO | 값(변하지 않는 의미 단위) 중심의 객체 | | Instance | 클래스로 실제 생성한 객체 | 6. Soft Delete 뜻: 데이터를 진짜로 삭제하지 않고, 삭제된 것처럼 표시만 하는 것. 개발에서는? DB에 is_deleted 같은 컬럼을 만들어서, 삭제 대신 플래그만 켠다. 예시 (MySQL 테이블): UPDATE users SET is_deleted = true WHERE id = 123; → 실제로는 데이터가 남아있지만, 조회할 때는 is_deleted = false인 것만 보여준다. ✅ 정리: Soft Delete = 삭제 표시만 하고 실제 데이터는 남겨두는 것 (복구하거나 기록을 남길 때 유용) 🔥 한 줄 요약 “Omit은 빼는 것, Clean URL은 경로 깔끔하게, Query String은 검색 옵션, JWT는 Header에 인증 토큰, POJO/VO/Instance는 객체 용어 구분, Soft Delete는 삭제 안 하고 표시만!”",
    "tags": "TIL til",
    "url": "/til/2025-04-19-til/"
  },{
    "title": "[TIL] @Controller vs @RestController, JPA reflection에…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #43 📅 작성일: 2025-04-18 🔄 최종 수정: 2025년 04월 22일 🍀 새롭게 배운 것 1️⃣ @Controller vs @RestController @Controller View를 반환하기 위해 사용 하지만 Data를 반환해야 하는 경우도 있음 이때는 @ResponseBody 어노테이션을 사용해야함 @RestController @Controller + @ResponseBody JSON 형태로 객체 데이터를 반환하는 것 참고 URL 2️⃣ JPA reflection에서의 @NoArgConstructor @NoArgsConstructor, @AllArgsConstructor의 동시 필요성의 차이를 알아보다가 @NoArgsConstructor는 JPA의 reflection과 관련이 있다는 것을 알게 되어 좀 더 공부해보았다. JPA는 객체를 생성할 때 reflection을 사용하기 때문에 “기본 생성자(파라미터 없는 생성자)”가 반드시 필요하다. 따라서 JPA는 @NoArgsConstructor가 꼭 필요함! reflection이란? 자바에서 코드 자체를 런타임(실행 중)에 들여다 보고 조작하는 기능 예를 들면 어떤 클래스인지 모르는데도 필드, 메서드, 생성자를 꺼내서 확인하거나, private 필드에도 강제로 접근하거나, 생성자를 호출해서 객체를 만들 수 있음 JPA에서 리플렉션이 필요한 이유 JPA는 직접 new로 객체를 만들지 않음 내부적으로 Hibernate가 리플렉션을 사용해 객체를 생성하고 필드 값을 채워 넣음 그래서 기본 생성자(@NoArgsConstructor)가 반드시 필요한 것 예시 User user = entityManager.find(User.class, 1L); 이 내부에서는 Hibernate가 리플렉션으로 User.class.newInstance()로 기본 생성자 호출 리플렉션으로 각 필드 값 설정 Spring의 DI와 리플렉션의 관계 Spring은 @Component, @Service같은 에너테이션이 붙은 클래스들을 자동으로 Bean으로 등록하는데, 이때 객체를 직접 new하는게 아니라 리플렉션으로 객체를 생성한다. 예제 @Service public class HelloService { public void hello() { System.out.println(\"Hello from Spring Bean!\"); } } Spring이 Bean을 만들 때 내부적으로 하는 일 (비공식 흐름) Class&lt;?&gt; clazz = HelloService.class; Object bean = clazz.getDeclaredConstructor().newInstance(); 리플렉션으로 객체를 만들고, 그걸 Spring Container에 등록해서 DI해주는 것!",
    "tags": "TIL Java til",
    "url": "/til/2025-04-18-til/"
  },{
    "title": "[TIL] JPA Query Method, Spring Security에서 Swagger doc…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #42 📅 작성일: 2025-04-17 🔄 최종 수정: 2025년 04월 22일 🍀 새롭게 배운 것 JPA Query Method JPA로 기존 테이블에 칼럼을 추가하고 해당 칼럼으로 데이터를 찾으려고 하다보니 JPA Query Method를 알게 되었다. JpaRepository 상속의 의미에 대해 좀더 명확히 알기위해 노력했다. 블로그 정리 Spring Security에서 Swagger docs 관련한 트러블 슈팅은 블로그에 정리해두었다. 블로그 정리 Spring Security기반의 JWT 토큰 구현하기 참고 블로그 글 위 블로그 글에서 spring security 아키텍쳐의 처리 과정을 다이어그램을 통해 상세하게 알려주고 있어 이해하는데 도움이 되었다.",
    "tags": "TIL Java Spring til",
    "url": "/til/2025-04-17-til/"
  },{
    "title": "[Spring] JPA Query Method",
    "text": "JpaRepository 상속 그렇다면 커스텀 쿼리는 어떻게 할까? 개발자 관점 팁 JpaRepository 상속 JpaRepository를 상속한 Repository 인터페이스는 여러 기능이 내장된 상태가 된다. 예시 : public interface UserRepository extends JpaRepository&lt;User, Long&gt; {} 이 경우, findById() 같은 기능은 이미 내장되어 편리하게 사용할 수 있다. 내장 함수 JpaReposiroty가 상속하고 있는 인터페이스 중, CrudRepository가 아래와 같이 기본 CRUD 메서드를 가지고 있어 직접 구현하지 않아도 사용할 수 있음. public interface CrudRepository&lt;T, ID&gt; extends Repository&lt;T, ID&gt; { &lt;S extends T&gt; S save(S entity); &lt;S extends T&gt; Iterable&lt;S&gt; saveAll(Iterable&lt;S&gt; entities); Optional&lt;T&gt; findById(ID id); boolean existsById(ID id); Iterable&lt;T&gt; findAll(); Iterable&lt;T&gt; findAllById(Iterable&lt;ID&gt; ids); long count(); void deleteById(ID id); void delete(T entity); void deleteAllById(Iterable&lt;? extends ID&gt; ids); void deleteAll(Iterable&lt;? extends T&gt; entities); void deleteAll(); } 🤔 그렇다면 커스텀 쿼리는 어떻게 할까? Spring Data JPA는 메서드 이름만으로 쿼리를 만들어줌 List&lt;User&gt; findByAgeGreaterThan(int n); -&gt; age &gt; n인 유저들 예시: public interface UserRepository extends JpaRepository&lt;User, Long&gt; { List&lt;User&gt; findByName(String name); } 이 메서드를 호출하면 JPA는 이런 SQL을 자동으로 만든다: SELECT * FROM user WHERE name = ?; 1. 다양한 조건 연산자 사용 가능한 키워드들: 키워드 의미 예시 SQL And AND 조건 findByNameAndAge WHERE name=? AND age=? Or OR 조건 findByNameOrEmail WHERE name=? OR email=? Between 사이 값 findByAgeBetween(int a, int b) WHERE age BETWEEN ? AND ? LessThan / GreaterThan 부등호 findByAgeGreaterThan(20) WHERE age &gt; 20 IsNull / IsNotNull 널 여부 findByEmailIsNull() WHERE email IS NULL In 여러 값 findByNameIn(List&lt;String&gt; names) WHERE name IN (?, ?, ...) Like 부분일치 findByNameLike(\"%woo%\") WHERE name LIKE ? StartingWith / EndingWith / Containing 문자열 검색 findByNameStartingWith(\"s\") WHERE name LIKE 's%' 2. 정렬과 페이징도 가능! List&lt;User&gt; findByAgeGreaterThanOrderByNameAsc(int age); SQL: SELECT * FROM user WHERE age &gt; ? ORDER BY name ASC Page&lt;User&gt; findByNameContaining(String name, Pageable pageable); 페이징 처리까지 자동으로 해줌! 3. 존재 여부만 알고 싶다면? boolean existsByEmail(String email); SQL: SELECT COUNT(*) FROM user WHERE email = ? 결과: 해당 이메일이 존재하면 true, 없으면 false 4. 리턴 타입도 다양하게 지원한다. 리턴 타입 설명 User 단일 객체 (없으면 null) Optional&lt;User&gt; 단일 객체 (안전하게 Optional로 감쌈) List&lt;User&gt; 여러 개 Page&lt;User&gt; 페이징 결과 boolean 존재 여부 확인 5. 규칙을 안 지키면 어떻게 될까? findByWhatIsThis() // ← 엔티티에 없는 필드명이면 컴파일은 되지만 실행 시 에러 No property whatIsThis found for type User! 같은 예외 발생 🧠 개발자 관점 팁 메서드 이름이 너무 길어지면 @Query를 써서 직접 JPQL 작성하는 게 낫다. 자동 생성 쿼리 → 빠르게 CRUD 만들 때 유용 복잡한 조건 → @Query 또는 QueryDSL, Specification 권장",
    "tags": "spring",
    "url": "/spring/2025-04-17-query-method/"
  },{
    "title": "[버티] 프로젝트 개발 중 마주한 사소한 이슈들",
    "text": "JJWT 라이브러리 버전에 따른 변경 사항 카카오 소셜 로그인 이메일 누락 문제 OAuth2 인증 요청 정보 손실 문제 이 문서는 “버티” 프로젝트를 개발하면서 마주쳤던 비교적 사소하지만, 실제 구현 과정에서는 꽤나 시간을 잡아먹거나 시행착오를 유발했던 문제들을 기록해두는 공간입니다. 단순한 에러라기보다는 “한 번쯤은 헷갈릴 수 있는 포인트들”을 중심으로 정리하여, 나중에 유지보수하거나 다른 프로젝트에서 재사용할 때 참고할 수 있도록 작성합니다. 1. JJWT 라이브러리 버전에 따른 변경 사항 JJWT 라이브러리의 업데이트로 인해 토큰 생성 및 파싱 방식이 크게 변경되었습니다. 기존 방식으로 작성된 코드는 더 이상 컴파일되지 않거나 실행 시 에러가 발생할 수 있습니다. 🔧 기존 코드 (구버전 JJWT) String secretKey = Base64.getEncoder().encodeToString(secretKey.getBytes()); Claims claims = Jwts.claims().setSubject(user.getNickname()); String accessToken = Jwts.builder() .setHeaderParam(Header.TYPE, Header.JWT_TYPE) .setClaims(claims) .setIssuedAt(now) .setExpiration(new Date(now.getTime() + ACCESS_TOKEN_VALID_MILLISECOND)) .signWith(SignatureAlgorithm.HS256, secretKey) .compact(); Claims parsedClaims = Jwts.parser().setSigningKey(secretKey).parseClaimsJws(accessToken).getBody(); ✅ 변경 코드 (최신 JJWT) SecretKey secretKey = Keys.hmacShaKeyFor(secretKeyStr.getBytes()); Claims claims = Jwts.claims().subject(user.getNickname()).build(); String accessToken = Jwts.builder() .claims(claims) .header() .type(\"JWT\") .and() .issuedAt(now) .expiration(new Date(now.getTime() + ACCESS_TOKEN_VALID_MILLISECOND)) .signWith(secretKey, Jwts.SIG.HS256) .compact(); Claims parsedClaims = Jwts.parser() .verifyWith(secretKey) .build() .parseSignedClaims(accessToken) .getPayload(); 참고 : Jwt.parserBuilder() Deprecated stack overflow 2. 카카오 소셜 로그인 이메일 누락 문제 🧩 문제 상황 카카오 로그인 시 사용자 이메일이 제공되지 않아 InternalAuthenticationServiceException 이 발생하는 문제가 있었습니다. ✅ 해결 방법 카카오 계정에 이메일 정보가 없을 경우 자동으로 생성된 이메일을 부여하도록 로직을 보완했습니다. // KakaoOAuth2UserInfo 클래스 @Override public String getEmail() { if (attributes.containsKey(\"kakao_account\")) { Map&lt;String, Object&gt; kakaoAccount = (Map&lt;String, Object&gt;) attributes.get(\"kakao_account\"); if (kakaoAccount != null &amp;&amp; kakaoAccount.containsKey(\"email\")) { return (String) kakaoAccount.get(\"email\"); } } return null; // 상위 메소드에서 처리 } // OAuth2UserService 클래스 private OAuth2User processOAuth2User(...) { String email = oAuth2UserInfo.getEmail(); if (email == null || email.isEmpty()) { email = registrationId + \"_\" + oAuth2UserInfo.getId() + \"@example.com\"; log.debug(\"이메일 정보가 없어 생성된 이메일: {}\", email); } // 나머지 사용자 생성/업데이트 로직 ... } 3. OAuth2 인증 요청 정보 손실 문제 🧩 문제 상황 로그인 시 다음과 같은 오류가 발생했습니다: oauth2LoginException: authorization_request_not_found 이유는 Security 설정에서 다음과 같이 세션 생성을 완전히 차단했기 때문입니다: http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS); OAuth2 로그인 과정은 내부적으로 세션에 인증 요청 정보를 저장하여 인증을 이어가는데, 해당 설정으로 인해 정보가 손실되었습니다. ✅ 해결 방법 개발 초기에는 단순화를 위해 다음과 같이 설정을 변경했습니다: http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED); 이를 통해 OAuth2 인증 플로우 중 세션을 사용할 수 있도록 하여 문제를 해결했습니다. 💡 추가 구현: 리프레시 토큰 보안성과 사용자 경험을 위해 리프레시 토큰도 함께 구현했습니다. RefreshToken 엔티티 및 리포지토리 생성 토큰 갱신 서비스 및 API 엔드포인트 구현 액세스 토큰과 리프레시 토큰을 분리 관리하여 보안성 강화",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-04-17-diary/"
  },{
    "title": "[TIL] JWT로 로그인을 구현했을 때 로그아웃 방법을 어떻게 해야할까?",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #41 📅 작성일: 2025-04-16 🔄 최종 수정: 2025년 04월 17일 🍎 오늘의 문제 상황 JWT로 로그인을 구현했을 때 로그아웃 방법을 어떻게 해야할까? 저번 프로젝트에서는 로그아웃을 구현하지 않고, 토큰 만료를 사용했는데 로그아웃을 구현해달라는 요청이 있었어서 이번 프로젝트에서는 제대로 알아보고 구현해보기로 하였다. 로그아웃을 구현하는 방법에는 크게 3가지가 있다. 프론트엔트에서 토큰 삭제 가장 구현이 간단하다. 클라이언트 측에서 토큰을 삭제하여 로그아웃을 구현하는 방법 이 방법이 토큰의 Stateless한 특징을 최대한 살린 방식 ‘Stateful : 데이터베이스에 정보를 저장하고 조회하는 경우 'Stateless : 데이터베이스를 사용하지 않는 방식 JWT는 데이터베이스에 저장 및 조회가 필요없기 때문에 Stateless한 특징을 가지고 있다. 단점 : 서버에선 토큰이 유효하기 때문에, 토큰이 노출되면 보안 문제가 생길 수 있음. 토큰 블랙리스트 관리 JWT가 만료되지 않은 상태에서 로그아웃 요청이 오는 경우, 서버에서 해당 토큰을 블랙리스트 DB에 넣어 처리 인증 필터에서 매 요청마다 토큰이 블랙리스트에 해당하는 토큰인지 확인해야한다. 서버에서 토큰을 효과적으로 관리할 수 있지만, 매 요청마다 블랙리스트를 확인해야하기 때문에 stateless한 JWT의 장점이 없어진다. Refresh Token 기간 만료 처리 사용자가 로그아웃을 요청할 때 리프레시 토큰을 무효화해 해당 사용자가 더 이상 새로운 엑세스 토큰을 발급받지 못하도록 하는 방식 사용자의 로그아웃 요청에 대해 서버 측에서 적극적으로 대응할 수 있다는 장점이 있다. 엑세스 토큰 재발급의 연속성을 차단해 보안을 강화할 수도 있다. 하지만 리프레시 토큰 확인 과정에서 JWT의 Stateless한 장점이 사라진다. 2번 VS 3번 비교 2번의 경우, 블랙리스트 DB 혹은 Redis를 사용해 서버 상태를 관리해야 한다. 또한 Stateless성이 완전히 깨지고 (모은 요청 시 DB확인이 필요하기 때문에!) 성능 이슈가 생길 수 있다. 하지만 3번의 경우, 리프레시 토큰만 관리하면 되기 때문에 상대적으로 가볍다. 리프레시 토큰만 서버 저장 및 관리하면 된다! 또한 3번은 Stateless를 부분적으로 유지 가능하다. (액세스 토큰은 여전히 Stateless) 일단은 3번 방법을 선택해서 로그아웃을 구현해보기로 결정하였다. 어플리케이션이 그렇게 무거운 프로젝트가 아니기 때문에, 블랙 리스트 방식처럼 서버 자원을 지속적으로 소모하는 설계보다는 토큰 생명주기를 명확히 관리할 수 있는 방식이 더 적합할 것 같다고 판단했다. 또한 리프레시 토큰 구현으로 토큰의 생명 주기에 대해 이해해볼 수 있을 것 같아 선택하게 되었다. 이번 프로젝트는 데이터베이스 사용이 많은 구조이기 때문에, 불필요한 토큰 상태 관리를 피하고 전체 시스템의 부하를 줄이기 위한 의도도 있었다. 리프레시 토큰의 발급 및 만료 흐름을 직접 설계함으로써, JWT 기반 인증 시스템의 구조와 보안 설계에 대한 이해도를 높이는 기회로 삼고자 한다.",
    "tags": "TIL til",
    "url": "/til/2025-04-16-til/"
  },{
    "title": "[버티] JWT로 로그인을 구현했을 때 로그아웃 방법을 어떻게 해야할까?",
    "text": "저번 프로젝트에서는 로그아웃을 구현하지 않고, 토큰 만료를 사용했는데 로그아웃을 구현해달라는 요청이 있었어서 이번 프로젝트에서는 제대로 알아보고 구현해보기로 하였다. JWT는 기본적으로 상태를 저장하지 않아(stateless) 로그아웃 처리에 어려움이 있다. 로그아웃을 구현하는 방법에는 크게 3가지가 있다. 1. 프론트엔트에서 토큰 삭제 - 가장 구현이 간단하다. - 클라이언트 측에서 토큰을 삭제하여 로그아웃을 구현하는 방법 - 이 방법이 토큰의 `Stateless`한 특징을 최대한 살린 방식 &gt; 'Stateful` : 데이터베이스에 정보를 저장하고 조회하는 경우 ‘Stateless`: 데이터베이스를 사용하지 않는 방식 JWT는 데이터베이스에 저장 및 조회가 필요없기 때문에Stateless한 특징을 가지고 있다. 단점 : 서버에선 토큰이 유효하기 때문에, 토큰이 노출되면 보안 문제가 생길 수 있음. 토큰 블랙리스트 관리 JWT가 만료되지 않은 상태에서 로그아웃 요청이 오는 경우, 서버에서 해당 토큰을 블랙리스트 DB에 넣어 처리 인증 필터에서 매 요청마다 토큰이 블랙리스트에 해당하는 토큰인지 확인해야한다. 서버에서 토큰을 효과적으로 관리할 수 있지만, 매 요청마다 블랙리스트를 확인해야하기 때문에 stateless한 JWT의 장점이 없어진다. Refresh Token 기간 만료 처리 사용자가 로그아웃을 요청할 때 리프레시 토큰을 무효화해 해당 사용자가 더 이상 새로운 엑세스 토큰을 발급받지 못하도록 하는 방식 사용자의 로그아웃 요청에 대해 서버 측에서 적극적으로 대응할 수 있다는 장점이 있다. 엑세스 토큰 재발급의 연속성을 차단해 보안을 강화할 수도 있다. 하지만 리프레시 토큰 확인 과정에서 JWT의 Stateless한 장점이 사라진다. 2번 VS 3번 비교 2번의 경우, 블랙리스트 DB 혹은 Redis를 사용해 서버 상태를 관리해야 한다. 또한 Stateless성이 완전히 깨지고 (모은 요청 시 DB확인이 필요하기 때문에!) 성능 이슈가 생길 수 있다. 하지만 3번의 경우, 리프레시 토큰만 관리하면 되기 때문에 상대적으로 가볍다. 리프레시 토큰만 서버 저장 및 관리하면 된다! 또한 3번은 Stateless를 부분적으로 유지 가능하다. (액세스 토큰은 여전히 Stateless) 일단은 3번 방법을 선택해서 로그아웃을 구현해보기로 결정하였다. 어플리케이션이 그렇게 무거운 프로젝트가 아니기 때문에, 블랙 리스트 방식처럼 서버 자원을 지속적으로 소모하는 설계보다는 토큰 생명주기를 명확히 관리할 수 있는 방식이 더 적합할 것 같다고 판단했다. 또한 리프레시 토큰 구현으로 토큰의 생명 주기에 대해 이해해볼 수 있을 것 같아 선택하게 되었다. 이번 프로젝트는 데이터베이스 사용이 많은 구조이기 때문에, 불필요한 토큰 상태 관리를 피하고 전체 시스템의 부하를 줄이기 위한 의도도 있었다. 리프레시 토큰의 발급 및 만료 흐름을 직접 설계함으로써, JWT 기반 인증 시스템의 구조와 보안 설계에 대한 이해도를 높이는 기회로 삼고자 한다. 참고 : JWT 토큰 기반의 상태 관리시 로그아웃 처리 문제 [우테코] JWT 방식에서 로그아웃, Refresh Token 만들기(1)",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-04-16-diary/"
  },{
    "title": "[버티] Spring Security와 Swagger 통합 시 발생한 이슈 해결기",
    "text": "1. Swagger 문서 접근 제한 및 인증 설정 이슈 2. OAuth2 엔드포인트가 Swagger에 표시되지 않는 문제 3. Swagger UI 그룹명 ‘default’ 표시 이슈 4. Swagger UI에 Authorization 설정 추가 5. 실무 관점에서의 Swagger 접근 관리 전략 6. 정리하며 Spring Boot와 Spring Security, 그리고 Swagger(OpenAPI)를 함께 사용하기 위해 공부하고 구현하며 여러 이슈가 발생했습니다. 따라서 제가 프로젝트를 수행하며 “소셜 로그인 기능을 구현하면서 Swagger와 관련된 문제들을 어떻게 인지하고 해결했는지”를 기록해 보았습니다. 1. Swagger 문서 접근 제한 및 인증 설정 이슈 1.1. 문제 상황 Spring Security 환경에서 Swagger 문서(/swagger-ui/index.html, /v3/api-docs)에 접근하려면 인증이 필요한 상황이 발생하였습니다. 이는 프론트엔드 개발자와 API 명세를 공유하고 협업하는 데 불편을 초래할 것이라 판단했습니다. 로그인 과정을 거치지 않으면 Swagger UI 자체가 열리지 않았기 때문에, 프론트엔드가 API 테스트를 원활히 진행할 수 없었습니다. 그래서 개발 환경(dev profile) 에 한해 Swagger 관련 인증을 해제했습니다. 이렇게 하니 Swagger 문서를 보다 자유롭게 접근할 수 있었고, API 확인과 테스트 속도도 한결 빨라졌습니다. 다만 이러한 설정을 그대로 운영 환경에 적용할 경우, 민감한 정보 노출의 위험이 있기 때문에, 배포 시에는 Swagger 접근을 차단하거나 관리자만 접근 가능하도록 제한할 계획입니다. 이처럼 환경에 따라 적절하게 보안 수준을 조절하는 방식은 실제 현업에서도 자주 사용하는 전략이기도 합니다. 추가적으로, 설정 과정 중 다음과 같은 오류가 발생했습니다: IllegalStateException: Can't configure mvcMatchers after anyRequest. 1.2. 👀 원인 분석 Spring Security는 기본적으로 모든 요청에 대해 보안 필터를 적용하여, 인증되지 않은 사용자의 접근을 차단합니다. Swagger 문서 관련 URL 또한 별도의 예외 처리를 하지 않으면 일반적인 보호 대상 경로로 인식되어 접근이 제한됩니다. Spring Security에서 .anyRequest() 호출 이후 .requestMatchers()를 선언한 것이 문제 URL 매칭 규칙상 구체적인 경로를 먼저 선언하고, 마지막에 anyRequest()를 사용해야 합니다 1.3. 해결 방법 SecurityConfig 클래스에서 Swagger 관련 경로에 대한 접근을 허용하도록 다음과 같이 설정했습니다: Swagger 관련 경로를 먼저 선언한 후, 마지막에 anyRequest()를 설정하는 방식으로 해결했습니다: @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests(authorize -&gt; authorize .requestMatchers( \"/swagger-ui/**\", \"/swagger-resources/**\", \"/v2/api-docs\", \"/v3/api-docs\", \"/webjars/**\" ).permitAll() .anyRequest().authenticated() ); return http.build(); } 이 설정으로 인해 Swagger 문서에 로그인 없이 접근 가능하게 되었으며, 프론트엔드와의 협업도 원활해졌습니다. “개발 생산성과 보안의 균형”이라는 관점에 대해 생각하게 되었습니다. 2. OAuth2 엔드포인트가 Swagger에 표시되지 않는 문제 2.1. 문제 상황 Spring Security가 자동으로 생성해주는 OAuth2 엔드포인트(/oauth2/authorize/{provider}, /login/oauth2/code/{provider})는 컨트롤러 기반이 아니기 때문에 Swagger 문서에 자동으로 포함되지 않았습니다. 2.2. 👀 원인 Swagger는 기본적으로 @RestController 및 @RequestMapping 애노테이션이 붙은 메서드를 기준으로 API 문서를 생성합니다. 하지만 Spring Security의 OAuth2 로그인 경로는 Security 설정 내부에서 동적으로 구성되기 때문에 Swagger가 자동으로 인식할 수 없습니다. 2.3. 해결 방법 SwaggerConfig에서 수동으로 OpenAPI 객체에 경로를 등록하여 문서화했습니다: @Configuration public class SwaggerConfig { @Bean public OpenAPI customOpenAPI() { OpenAPI openAPI = new OpenAPI() .info(new Info() .title(\"Burty Server API\") .version(\"1.0.0\") .description(\"버티 서버 API 문서\")) .paths(new Paths()); openAPI.getPaths().addPathItem(\"/oauth2/authorize/{provider}\", new PathItem().get(new Operation().summary(\"OAuth2 인증 요청\"))); openAPI.getPaths().addPathItem(\"/login/oauth2/code/{provider}\", new PathItem().get(new Operation().summary(\"OAuth2 로그인 콜백\"))); return openAPI; } } 3. Swagger UI 그룹명 ‘default’ 표시 이슈 3.1. 문제 상황 Swagger UI에서 각 API가 default라는 그룹으로 묶여 가독성이 떨어졌습니다. 3.2. 👀 원인 Swagger는 명시적으로 @Tag 애노테이션이 부여되지 않은 컨트롤러의 경우, 자동으로 default라는 태그로 묶어 표시합니다. 이는 다양한 기능의 API가 하나의 그룹으로 합쳐져 구분이 어렵게 됩니다. 3.3. 해결 방법 컨트롤러에 @Tag 애노테이션을 추가하고, 각 API에 tags를 명시함으로써 그룹을 명확하게 분리했습니다: @Tag(name = \"인증\", description = \"사용자 인증 관련 API\") @RestController @RequestMapping(\"/auth\") public class AuthController { @Operation(summary = \"카카오 로그인 URL 반환\", tags = {\"인증\"}) @GetMapping(\"/kakao\") public ResponseEntity&lt;String&gt; kakaoLogin() { ... } } 4. Swagger UI에 Authorization 설정 추가 4.1. 문제 상황 프론트엔드에서 JWT 인증이 필요한 API를 Swagger UI로 테스트하고자 했으나, Authorization 정보를 입력할 수 있는 UI가 없었습니다. 4.2. 👀 원인 분석 Swagger 기본 설정에는 Authorization 헤더 입력 기능이 포함되어 있지 않습니다. JWT 기반 인증이 필요한 API에도 별도의 인증 설정을 명시하지 않으면 Swagger UI에서 테스트가 불가능합니다. 따라서 개발 및 테스트 과정에서 프론트엔드가 토큰을 포함한 요청을 손쉽게 재현할 수 있도록 하기 위해 보안 스키마 설정이 필요했습니다. 프론트엔드에서 JWT 인증이 필요한 API를 Swagger UI로 테스트하고자 했으나, Authorization 정보를 입력할 수 있는 UI가 없었습니다. 4.3. 해결 방법 1) 전역 보안 스키마 정의 @Configuration @SecurityScheme( name = \"bearerAuth\", type = SecuritySchemeType.HTTP, scheme = \"bearer\", bearerFormat = \"JWT\" ) public class OpenApiConfig { // 어노테이션으로 설정 } 2) 개별 API에 적용 @Operation(security = { @SecurityRequirement(name = \"bearerAuth\") }) @PutMapping(\"/profile\") public ResponseEntity&lt;?&gt; updateUserProfile(...) { // 메서드 구현 } 이 설정을 통해 Swagger UI에서도 인증이 필요한 API를 명확히 구분하고, 테스트 시 토큰을 직접 입력할 수 있도록 구성할 수 있었습니다. 5. 실무 관점에서의 Swagger 접근 관리 전략 개발 환경에서는 Swagger 접근을 자유롭게 열어두고 프론트엔드 테스트를 용이하게 함 운영 환경에서는 보안을 위해 관리자 인증 또는 방화벽 제한을 적용하는 것이 일반적 JWT 기반 인증 API는 Swagger UI에서도 Authorization 헤더를 통해 테스트할 수 있도록 설정 6. 정리하며 Swagger와 Spring Security를 함께 사용할 때 마주친 실제적인 문제들을 해결하면서, 보안과 개발 편의성 사이에서 균형을 맞추는 경험을 할 수 있었습니다. 특히 프론트엔드 협업 관점에서 Swagger 인증 해제와 JWT 연동 설정은 협업 효율을 높이는 핵심 포인트였습니다. 이러한 설정 경험은 포트폴리오에 실질적인 문제 해결 능력으로 정리할 수 있었고, 실무에서도 유용하게 활용될 수 있는 기반이 되었습니다.",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-04-15-diary/"
  },{
    "title": "[버티] 프로젝트 구조 설계 고민과 선택",
    "text": "프로젝트를 처음 시작할 때 가장 고민했던 부분 중 하나는 전체 구조를 어떻게 잡을 것인가였습니다. 단순한 CRUD를 넘어서 소셜 로그인, 커뮤니티, AI 기반 정착 리포트 등 다양한 기능을 포함할 예정이었기 때문에, 기능이 늘어나더라도 유지보수가 쉽고, 각 도메인이 명확하게 분리되도록 설계하고 싶었습니다. 처음엔 기능 중심으로 폴더를 나눌까도 생각했지만, 여러 기능이 얽혀 있을 때 책임이 명확하지 않고 코드가 뒤섞일 우려가 있었습니다. 그래서 고민 끝에 도메인 주도 설계(Domain-Driven Design, DDD) 와 MVC 구조, 그리고 레이어드 아키텍처(Layered Architecture) 를 조합한 형태로 프로젝트 구조를 설계하기로 했습니다. 💡 도메인 주도 설계란? DDD는 비즈니스의 복잡한 요구사항을 도메인 중심으로 풀어가는 소프트웨어 설계 방법입니다. 코드 구조가 실제 도메인 모델과 맞닿아 있어 유지보수가 용이하고, 비즈니스 개념을 중심으로 기능을 구현할 수 있도록 도와줍니다. 핵심은 ‘도메인을 기준으로 책임을 분리’하는 것입니다. 또한 레이어드 아키텍처는 기능을 계층별로 나누어 역할을 분리함으로써 각 계층 간의 결합도를 낮추고 테스트와 유지보수를 용이하게 합니다. 대표적으로는 Controller → Service → Repository 계층 구조를 따릅니다. 최종적으로 다음과 같은 구조를 구성했습니다: org.example.burtyserver/ ├── domain/ # 도메인 중심 패키지 │ ├── auth/ # 인증 관련 기능 │ │ ├── controller/ # API 컨트롤러 (Presentation Layer) │ │ └── dto/ # 데이터 전송 객체 │ │ │ └── user/ # 사용자 관련 기능 │ ├── entity/ # 엔티티 클래스 (Domain Layer) │ ├── repository/ # 데이터 접근 계층 (Persistence Layer) │ └── service/ # 비즈니스 로직 (Application Layer) │ ├── global/ # 공통/전역 기능 │ ├── config/ # 설정 클래스 │ ├── exception/ # 예외 처리 │ └── security/ # 보안 관련 클래스 │ ├── jwt/ # JWT 관련 클래스 │ ├── oauth2/ # OAuth2 관련 클래스 │ └── dto/ # 보안 관련 DTO │ └── BurtyServerApplication.java # 애플리케이션 진입점 -&gt; 아직 개발중! 이 구조는 기능별 분리보다 도메인별 분리를 우선시했으며, 각 도메인이 자신의 책임과 역할에 따라 나뉘도록 구성했습니다. 공통 설정이나 보안 로직처럼 여러 도메인에서 공유되는 요소들은 global이라는 전역 패키지에 따로 관리하여 관심사 분리를 명확히 했습니다. 실제로 프로젝트를 진행하면서 새로운 기능이 추가될 때마다 이 구조 덕분에 확장이 훨씬 수월했습니다. 예를 들어 AI 정착 리포트 기능을 추가할 때도 settlement라는 도메인을 추가해 기존 구조에 영향을 주지 않고도 자연스럽게 통합할 수 있었습니다. 도메인 주도 설계를 기반으로 구조를 잡는 과정은 단순히 코드를 예쁘게 나누는 것을 넘어서, 기능과 비즈니스 로직의 맥락(Context)을 코드 레벨에서 표현하는 데 큰 도움이 되었습니다. 또한 레이어드 아키텍처를 통해 각 계층의 역할이 명확해져 협업 시 작업 분담이나 코드 리뷰도 훨씬 효율적으로 이루어졌습니다. 이 경험은 제가 프로젝트를 단순히 “만드는 것”을 넘어서, “운영 가능한 구조로 설계한다”는 감각을 키우는 데 결정적인 계기가 되었습니다.",
    "tags": "projectdiary",
    "url": "/projectdiary/2025-04-14-diary/"
  },{
    "title": "[TIL] JPA 더티체킹",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #40 📅 작성일: 2025-04-10 🔄 최종 수정: 2025년 04월 17일 🍀 새롭게 배운 것 JPA 더티체킹 (dirty checking) 강의와 팀 스터디 시간에 얘기가 나왔는데 잘 모르겠어서 찾아봤습니다. JPA가 객체의 변경 사항을 자동으로 감지해서 DB에 반영해주는 기능 JPA는 트랜잭션 안에서 영속 상태(@Entity가 EntityManager에 의해 관리되고 있는 상태)의 엔티티가 변경되었는지 감시함 변경사항이 감지되면, 트랜잭션을 커밋할 때 JPA가 자동으로 update SQL을 생성해서 DB에 반영 -&gt; 이것이 더티 체킹 JPA에서는 엔티티를 조회하면 해당 엔티티의 조회 상태 그대로 스냅샷을 만들어 놓음 트랜잭션이 끝나는 시점에 이 스냅샷과 비교해 다른 점이 있다면 Update Query를 데이터베이스로 전달 상태 변경 검사의 대상은 영속성 컨텍스트가 관리하는 엔티티 detach된 엔티티 (준영속) DB에 반영되기 전 처음 생성된 엔티티 (비영속) 등 준영속/비영속 상태의 엔티티는 Dirty Checking 대상에 포함되지 않음 예시 @Transactional public void updateUsername(Long id, String newUsername) { User user = em.find(User.class, id); // 1. 영속 상태로 가져옴 user.setUsername(newUsername); // 2. 필드 값을 변경함 // 3. em.persist 안 해도 됨! // 4. 트랜잭션이 커밋되면 JPA가 변경을 감지하고 update SQL을 실행함 } 위 코드에서 setUsername을 호출했지만 persist나 merge같은 명시적인 저장 메서드는 쓰지 않음 하지만 트랜잭션이 끝나면 UPDATE user SET username = ? WHERE id = ?같은 쿼리가 자동으로 실행됨 이것이 더티 체킹! http://www.gstatic.com/generate_204 사이드 프로젝트 개발 중, 프로젝트 빌드 하다가 이 사이트가 계속 나와서 어떤 의미인지 찾아보았다. Google이 인터넷 연결 상태를 확인할 때 사용하는 테스트용 URL 이 주소에 접속하면 서버는 HTTP 204 No Content 응답을 보내고, 브라우저는 아무것도 표시하지 않아야 정상. 즉, 인터넷 연결은 되지만, 리디렉션이 발생하거나, 204 응답이 안오는 경우 문제가 생겼다고 판단. 이 사이트가 보이는 이유 공공 와이파이 접속 중 스타벅스, 지하철, 학교 와이파이 등에서 자주 발생 아직 로그인 인증 페이지(캡티브 포털)에 접속하지 않은 상태인데, 브라우저가 인터넷에 접속되는지 확인하려고 generate_204에 요청을 보냄. 그런데 와이파이 서버가 요청을 리디렉션해서 로그인 페이지로 보내버리면, 그 주소가 눈에 보임. 인터넷 연결 오류 혹은 차단 방화벽이나 네트워크 정책이 Google 서버 요청을 막을 때 발생 가능 인터넷 연결이 느리거나 중단됨 브라우저가 연결 확인을 위해 해당 URL을 호출하는데 응답을 못받으면 이 주소만 보일 수 있음",
    "tags": "TIL Java til",
    "url": "/til/2025-04-10-til/"
  },{
    "title": "[TIL] Thymeleaf, UUID 버전별 특징",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #39 📅 작성일: 2025-04-09 🔄 최종 수정: 2025년 04월 09일 🍀 새롭게 배운 것 Thymeleaf HTML에서 동적 바인딩을 지원하는 Thymeleaf에 대해 알아봤다. 블로그 정리 Thymeleaf UUID 버전별 특징 🔍 UUID란? UUID(Universally Unique Identifier)는 전 세계에서 중복되지 않도록 고안된 고유 식별자 보통 이런 형식으로 생겼다: 550e8400-e29b-41d4-a716-446655440000 총 128비트(16바이트) → 보통 문자열로는 36자 (하이픈 포함) 여기서 41d4에서 4가 UUID의 버전(version)을 의미 🧬 UUID 버전별 특징 버전 이름 생성 방식 특징/사용처 v1 Time-based 시간 + MAC 주소 시간 순 정렬 가능, MAC 노출 위험 있음 v2 DCE Security 시간 + POSIX UID/GID 거의 사용되지 않음 v3 Name-based 이름 + 네임스페이스 → MD5 해시 정해진 입력 → 같은 UUID 생성 (고정됨) v4 Random 완전 무작위(Random) 가장 널리 사용됨, 중복 가능성 매우 낮음 v5 Name-based 이름 + 네임스페이스 → SHA-1 해시 v3과 유사하지만 더 강력한 해시 알고리즘 사용 v6 Reordered Time 시간 기반 (v1 개량) 시간 정렬에 최적화됨, 일부 DB에서 유리 v7 Unix Epoch-based Unix 타임스탬프 + 랜덤 시간 정렬 최적화, 대체로 최신 시스템 지향 v8 Custom 사용자 정의 (custom layout) 실험적, 규격 자체만 정의됨 ✅ 현재까지 정의된 UUID 버전: v1 ~ v8 v4는 Spring, Java의 UUID 클래스, Python 등에서도 기본으로 많이 쓰임. v7은 최근 표준화가 완료되어서 MySQL, PostgreSQL 같은 DB나 NoSQL 쪽에서 주목받고 있다 (정렬 최적화 + 충돌 방지 효과). v6~v8은 아직 도입 초기 단계지만, 이미 일부 라이브러리에서 지원 중 ✨ 버전 선택 팁 목적 추천 버전 완전 랜덤 고유 ID v4 (UUID.randomUUID()) 시간 순 정렬이 필요한 DB 키 v7 또는 v6 특정 값에 따라 고정된 UUID v3/v5 네트워크 환경에서 시간 기반 생성 v1 (단, MAC 노출 주의)",
    "tags": "TIL til",
    "url": "/til/2025-04-09-til/"
  },{
    "title": "[Spring] Thymeleaf",
    "text": "Thymeleaf는 왜 쓰는 걸까? 기본 문법 정리 전체 흐름 예시 어디에 파일을 넣어야 할까? 요약 🌱 1. Thymeleaf는 왜 쓰는 걸까? Spring Boot에서 매우 자주 사용되는 서버 사이드 템플릿 엔진 HTML을 그저 정적인 파일로만 쓰는 게 아니라, Spring Controller에서 전달한 데이터를 HTML에서 동적으로 표현하고 싶을 때 Thymeleaf를 사용 - HTML에서 Java 객체나 데이터들을 동적으로 바인딩해서 화면에 보여줌. 예를 들어, 사용자 이름을 동적으로 보여주려면 이런 식으로: &lt;p th:text=\"${user.name}\"&gt;홍길동&lt;/p&gt; Spring Controller에서 user라는 객체를 넘기면, user.name이 자동으로 대체돼서 HTML에 출력된다. 🧩 2. 기본 문법 정리 ① th:text — 텍스트 출력 &lt;p th:text=\"${message}\"&gt;&lt;/p&gt; → ${message}의 값을 이 &lt;p&gt; 태그 안에 출력해줌. ② th:each — 반복문 &lt;li th:each=\"item : ${items}\" th:text=\"${item}\"&gt;&lt;/li&gt; → items 리스트를 하나씩 꺼내서 item으로 반복해 &lt;li&gt;들을 만든다. ③ th:if, th:unless — 조건문 &lt;p th:if=\"${user != null}\"&gt;로그인 성공&lt;/p&gt; &lt;p th:unless=\"${user != null}\"&gt;로그인 해주세요&lt;/p&gt; ④ th:href, th:src — 링크나 이미지 경로 바인딩 &lt;a th:href=\"@{/home}\"&gt;홈으로&lt;/a&gt; &lt;img th:src=\"@{/images/logo.png}\" /&gt; @{/home}은 /home 경로를 의미해. 상대경로, 쿼리스트링도 가능하다. ⑤ th:action — form 전송 주소 &lt;form th:action=\"@{/submit}\" method=\"post\"&gt;&lt;/form&gt; → /submit로 POST 요청을 보냄. ⑥ th:object + th:field — 폼 객체 바인딩 &lt;form th:object=\"${userForm}\" method=\"post\"&gt; &lt;input type=\"text\" th:field=\"*{name}\" /&gt; &lt;/form&gt; → userForm.getName()과 연결돼서, 입력하면 자동으로 매핑됨. 🧠 3. 전체 흐름 예시 ✅ Controller @GetMapping(\"/hello\") public String hello(Model model) { model.addAttribute(\"message\", \"안녕하세요!\"); return \"hello\"; } ✅ HTML (hello.html) &lt;!DOCTYPE html&gt; &lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt; &lt;head&gt; &lt;title&gt;Hello&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p th:text=\"${message}\"&gt;기본 메시지&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; 결과적으로는 &lt;p&gt;안녕하세요!&lt;/p&gt;가 출력된다. 🧪 4. 어디에 파일을 넣어야 할까? Thymeleaf 템플릿 파일들은 이곳에 넣는다: src/main/resources/templates/ 여기 안에 hello.html, index.html 같은 HTML 파일들을 넣으면 됨. 이 파일들은 Spring MVC의 Controller에서 return으로 연결할 수 있음 ✨ 요약 기능 문법 예시 텍스트 출력 th:text=\"${data}\" 반복 th:each=\"item : ${items}\" 조건문 th:if, th:unless 링크 경로 th:href=\"@{/path}\" 이미지 경로 th:src=\"@{/img/logo.png}\" 폼 전송 경로 th:action=\"@{/submit}\" 폼 객체 바인딩 th:object, th:field",
    "tags": "spring",
    "url": "/spring/2025-04-09-thymeleaf/"
  },{
    "title": "[Spring] 논블로킹(Non-blocking) vs 비동기 (Asynchronous)",
    "text": "논블로킹이란? 실생활 비유로 논블로킹 이해하기 블로킹 vs 논블로킹 기술적 요점 정리 논블로킹이 중요한 이유 어디서 논블로킹이 쓰이냐? 논블로킹(Non-blocking) 비동기(Asynchronous) 비교 CompletableFuture, WebClient 코드 예시 ✅ 논블로킹(Non-blocking)이란? 먼저, 블로킹(Blocking)이 뭔지부터 알아보자 블로킹 방식은 어떤 작업이 끝날 때까지 프로그램이 멈춰서 기다리는 것 웹 서버라면, DB 응답이나 외부 API 요청이 끝날 때까지 쓰레드가 잡혀서 못 움직임. // 블로킹 방식 (예: RestTemplate) String result = restTemplate.getForObject(\"http://api.example.com\", String.class); // → 이 줄에서 응답이 올 때까지 멈춤 System.out.println(\"응답 받음!\"); 🚀 논블로킹 방식은? 기다리지 않는다. 요청을 보내고, 바로 다음 작업을 처리한다. 응답이 나중에 오면, 그때 콜백(또는 리액티브 스트림)을 통해 처리 // 논블로킹 방식 (예: WebClient) webClient.get() .uri(\"http://api.example.com\") .retrieve() .bodyToMono(String.class) .subscribe(result -&gt; { System.out.println(\"응답 받음! → \" + result); }); System.out.println(\"바로 다음 코드 실행됨!\"); 👆 여기서 중요한 건: subscribe() 안에 있는 코드만 나중에 실행되고 서버 쓰레드는 그동안 다른 요청을 처리할 수 있다는 것 🍜 실생활 비유로 논블로킹 이해하기 ✅ 블로킹 방식: 짜장면집 주방장 1명 손님이 주문 → 짜장면 끓이는 동안 주방장이 다음 주문을 못 받음 5명 동시에 오면? 4명은 그냥 기다림 (쓰레드 낭비, 느림) ✅ 논블로킹 방식: 주방장 + 자동면로봇 손님이 주문 → 기계에 넣고 대기표 발급 → 주방장은 다른 주문 처리 → 주문 100개가 와도 효율적으로 동시에 처리 가능! (고성능, 확장성) 🧠 블로킹 vs 논블로킹 기술적 요점 정리 항목 블로킹 방식 논블로킹 방식 처리 방식 요청 → 대기 → 응답 요청 → 바로 다음 처리 → 응답 오면 콜백 쓰레드 사용 요청 1건당 쓰레드 1개 요청 수백건도 쓰레드 몇 개로 처리 가능 성능 낮은 동시성 처리 높은 동시성, 고성능 코드 간단하고 직관적 콜백이나 리액티브 스트림 필요 예시 RestTemplate, JDBC WebClient, R2DBC, Netty 등 💡 논블로킹이 중요한 이유 ✔️ 1. 고성능 서버 만들기 수천~수만 명이 동시에 요청을 보내도 효율적으로 처리 가능 ✔️ 2. 외부 API 많이 쓰는 서비스에서 유리 다른 서비스의 응답을 기다리는 동안, 서버 리소스를 낭비하지 않음 ✔️ 3. MSA (마이크로서비스 아키텍처)에서 필수 서로 요청 주고받는 일이 많기 때문에 논블로킹 API가 매우 효율적 🛠️ 어디서 논블로킹이 쓰이냐? 기술 논블로킹 여부 비고 WebClient ✅ REST API 호출 Reactor Netty ✅ 웹서버 / 클라이언트 엔진 R2DBC ✅ 논블로킹 DB 클라이언트 (JDBC는 블로킹) Spring WebFlux ✅ 전체 논블로킹 웹 프레임워크 “논블로킹(Non-blocking)”이랑 “비동기(Asynchronous)” 비교 ❌ 같은 말 아님. ✅ 서로 관련 있지만, 개념적으로 다르다. 🔍 핵심 차이 요약 항목 비동기 (Asynchronous) 논블로킹 (Non-blocking) 개념 작업을 요청하고 바로 다음 코드 실행 (응답 기다리지 않음) 리소스(쓰레드 등)를 점유하지 않음 초점 시간(언제 실행될지 모름) 리소스 사용 여부 예시 콜백, Future, Promise, Mono read() 호출 시 즉시 리턴 관련성 비동기 처리는 대부분 논블로킹 방식으로 구현됨 논블로킹이 항상 비동기인 건 아님 🎯 비유로 설명 🍜 비동기란? “너 짜장면 하나, 그리고 바로 다음 손님 주세요~” 주문 받고 즉시 다음 손님 주문을 받는 방식 짜장면이 나올 때까지 기다리지 않음 나중에 “주문하신 짜장면 나왔습니다~” 하고 알림이 옴 (콜백) ✅ 즉, “작업이 완료될 때까지 기다리지 않고 나중에 처리“가 핵심 🥡 논블로킹이란? “면 삶는 동안 주방 공간을 계속 점유하지 않음” 요리를 맡긴 뒤 주방 공간을 즉시 다른 요리사에게 넘겨줌 결과가 나올 때까지 그 리소스를 점유하지 않음 ✅ 즉, 요청을 처리 중인 동안에도 시스템 리소스를 점유하지 않음이 핵심 🧠 코드 예시 비교 🧱 블로킹 + 동기 (가장 기본) String result = restTemplate.getForObject(url, String.class); // 이 줄에서 서버 응답이 올 때까지 기다림 (쓰레드 점유 O, 시간도 대기 O) 🧱 논블로킹 + 동기 String result = socket.readNonBlocking(); // 지금 읽을 수 있는 데이터만 읽고 즉시 리턴 당장 읽을 게 없으면 빈 값만 주고 쓰레드는 곧바로 다음 작업 가능 하지만 이 결과로 바로 처리함 → 동기적 🧱 논블로킹 + 비동기 (진짜 고성능 시스템 핵심!) webClient.get() .uri(\"/data\") .retrieve() .bodyToMono(String.class) .subscribe(data -&gt; { System.out.println(\"데이터 도착: \" + data); }); 요청 후 바로 다음 코드 실행됨 (비동기) 쓰레드를 점유하지 않음 (논블로킹) 응답이 왔을 때만 콜백으로 실행됨 💡 정리하자면 구분 설명 예 비동기 요청 → 응답 기다리지 않고 다른 작업함 콜백, subscribe, Future, CompletableFuture 논블로킹 시스템 리소스를 점유하지 않음 WebClient, R2DBC, Netty 블로킹 결과 나올 때까지 멈춤 RestTemplate, JDBC 비동기 + 논블로킹 성능 최상 조합 WebFlux + Netty + R2DBC CompletableFuture, WebClient 코드 예시 ✅ 1. CompletableFuture로 비동기 (스레드는 점유함 = 논블로킹 아님) import java.util.concurrent.CompletableFuture; import java.util.concurrent.ExecutionException; public class AsyncWithCompletableFuture { public static void main(String[] args) throws ExecutionException, InterruptedException { System.out.println(\"비동기 시작\"); CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; { // 시간이 오래 걸리는 작업 (예: API 호출 시뮬레이션) try { Thread.sleep(2000); // 2초 대기 (스레드 점유) } catch (InterruptedException e) { e.printStackTrace(); } return \"API 결과값\"; }); // 다른 작업 수행 System.out.println(\"다른 작업 수행 중...\"); // 결과 기다리기 String result = future.get(); // 여기서 block됨 System.out.println(\"결과: \" + result); } } 📌 포인트: CompletableFuture는 비동기처럼 보이지만 실제로는 별도 스레드를 점유함. .get()을 호출하면 결과를 기다리는 동안 block됨. 🛸 2. WebClient로 진짜 논블로킹 + 비동기 의존성 필요: mvn repository &lt;!-- build.gradle 혹은 pom.xml --&gt; implementation 'org.springframework.boot:spring-boot-starter-webflux' import org.springframework.web.reactive.function.client.WebClient; import reactor.core.publisher.Mono; public class AsyncWithWebClient { public static void main(String[] args) { WebClient client = WebClient.create(); System.out.println(\"WebClient 비동기 호출 시작\"); Mono&lt;String&gt; response = client.get() .uri(\"https://jsonplaceholder.typicode.com/todos/1\") .retrieve() .bodyToMono(String.class); response.subscribe(body -&gt; System.out.println(\"응답 도착: \" + body)); System.out.println(\"다른 작업 수행 중...\"); // 실제로 메인 스레드가 먼저 종료될 수 있어서 약간 대기 try { Thread.sleep(3000); } catch (InterruptedException e) {} } } 📌 포인트: WebClient는 진짜 논블로킹 (스레드 점유 X) .subscribe()로 콜백 기반 응답 처리 메인 스레드는 응답 기다리지 않음, 논블로킹 체험 가능 ⚖️ 비교 요약 항목 CompletableFuture WebClient (WebFlux) 스레드 점유 O (다른 스레드가 일 함) X (논블로킹 방식) 비동기 처리 방식 Future 기반 리액티브 스트림 (Mono/Flux) 논블로킹 체험 가능 여부 부분적으로 (Thread 풀에 의존) O (진짜 논블로킹) 사용 목적 간단한 비동기 로직 고성능, 동시성 높은 네트워크 호출",
    "tags": "spring",
    "url": "/spring/2025-04-09-non-blocking/"
  },{
    "title": "[TIL] JPA 주요 애너테이션, CompletableFuture",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #38 📅 작성일: 2025-04-08 🔄 최종 수정: 2025년 04월 09일 🍀 새롭게 배운 것 JPA 주요 애너테이션 10개 CompletableFuture 비트코인 대시보드 개발 중 비동기 처리를 위해 공부했다. 1. JPA에서 자주 쓰는 애너테이션 10선 범주 대표 애너테이션 기능 엔티티 지정 @Entity, @Table 클래스 → 테이블로 매핑 필드 매핑 @Id, @GeneratedValue, @Column 변수 → 컬럼으로 매핑 관계 매핑 @OneToOne, @OneToMany, @ManyToOne, @ManyToMany 엔티티 간 관계 지정 기타 @Embedded, @Embeddable, @Transient 등 부가 설정 🧠 요약 정리표 애너테이션 설명 예시 @Entity 테이블 매핑 객체 클래스 위에 @Table 테이블 이름 지정 @Table(name=\"members\") @Id PK 설정 필드 위에 @GeneratedValue 자동 생성 PK 전략 IDENTITY, AUTO 등 @Column 컬럼 설정 이름, 길이, null 여부 등 @Transient DB에 저장 안 됨 계산용 필드 등 @ManyToOne 등 관계 설정 외래키 매핑 @JoinColumn 외래키 이름 설정 member_id 등 @Embedded VO 포함 Address 같은 값 객체 @Enumerated Enum 타입 저장 방식 STRING 권장 2. CompletableFuture : JAVA 비동기 프로그래밍 도구 Spring에서 @Async와 함께 씀 백그라운드에서 비동기 처리하고, 나중에 결과 받기 최적 백그라운드 작업, 병렬처리, API응답 지연 없는 작업에 유용하게 활용됨 기본적인 사용 예제 CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; { // 백그라운드에서 실행될 코드 return \"Hello, Sungwoo!\"; }); future.thenAccept(result -&gt; { System.out.println(\"결과: \" + result); }); supplyAsync() : 비동기 작업 시작 thenAccept() : 결과가 오면 처리 🍎 오늘의 문제 상황 비트코인 대시보드의 첫 페이지 로딩이 너무 느려서 render배포에 실패했다. 복잡한 API 호출이 문제가 된 것 같다. CompletableFuture를 사용해서 병렬처리를 할까 했지만 DB에 API 응답들을 저장하여 API호출을 줄이는 방법을 선택했다. 🦄 느낀 점 API를 연결하는게 문제가 아니라, 어떤 로직으로 어떻게 데이터를 처리할 것인지가 중요한 것 같다.",
    "tags": "TIL Java til",
    "url": "/til/2025-04-08-til/"
  },{
    "title": "[Spring] JPA vs MyBatis",
    "text": "JPA란? MyBatis란? 🔍 JPA vs MyBatis JPA vs MyBatis 비유로 이해하기 JPA vs MyBatis 코드로 비교하기 사용 방식 차이 요약 장단점 비교 실무에 쓰는 방법 한줄 정리 📌 JPA란? (Java Persistence API) 자바에서 관계형 데이터베이스(RDB)를 객체로 다룰 수 있게 해주는 표준 API. SQL을 직접 작성하지 않아도 객체처럼 DB 데이터를 저장/조회/수정/삭제 가능. 구현체 중 가장 유명한 것은 Hibernate고, Spring에서 주로 이걸 씀. JPA 핵심 용어 용어 설명 Entity DB 테이블과 매핑되는 자바 클래스 EntityManager JPA의 핵심! DB와 객체 사이의 작업을 처리하는 도구 Persistence Context (영속성 컨텍스트) 엔티티를 관리하는 JPA 내부 메모리 공간 JPQL (Java Persistence Query Language) 객체 지향 쿼리 언어. SQL과 유사하지만, 테이블이 아닌 클래스/필드 단위로 작동 📌 MyBatis란? 자바에서 SQL을 직접 작성해서 데이터베이스와 통신할 수 있게 해주는 프레임워크. SQL 중심의 프로그래밍이 가능하고, 복잡하고 세밀한 쿼리 제어에 유리함. XML 또는 어노테이션 기반으로 SQL을 작성하고, 쿼리 결과를 자바 객체와 매핑해줌. Spring과도 쉽게 통합 가능하며, 실무에서는 여전히 널리 사용됨. MyBatis 핵심 용어 용어 설명 Mapper 인터페이스 SQL 문장을 호출하는 자바 인터페이스. XML과 1:1 매칭되어 동작함 Mapper XML 실제 SQL이 작성되는 파일. &lt;select&gt;, &lt;insert&gt; 등 태그로 구성됨 SqlSession DB 연결과 SQL 실행을 담당하는 핵심 객체 (JDBC의 Connection 역할) ResultMap 쿼리 결과를 자바 객체에 정밀하게 매핑할 때 사용하는 설정 #{} / ${} SQL 파라미터 바인딩 방식. #{}는 안전한 바인딩, ${}는 SQL 인젝션 주의 TypeAlias 자바 클래스의 이름을 짧게 별칭으로 사용할 수 있도록 하는 기능 🔍 JPA vs MyBatis 항목 JPA MyBatis 개발 방식 자동 매핑 (객체 중심) 수동 매핑 (SQL 중심) 핵심 개념 객체를 DB에 자동 매핑 직접 SQL 작성 + 매핑 학습 곡선 좀 더 높음 (추상화 많음) 비교적 쉬움 (SQL 그대로 작성) 유연성 추상화 많아 덜 유연함 SQL 작성 자유로움 성능 제어 ORM에 맡김 (튜닝 어려움) 직접 SQL 작성으로 제어 쉬움 대표 도구 Hibernate (JPA 구현체) MyBatis 프레임워크 JPA vs MyBatis 비유로 이해하기 ☝️ JPA = 자동세탁기 👕 세탁기 안에 옷(객체)을 넣으면 → 알아서 물(쿼리) 넣고, 빨고, 말리고 → 깨끗한 결과(조회된 객체)를 자동으로 꺼내줌! → 개발자는 “옷만 넣고 결과만 받으면 됨” → 단, 세탁 방식은 기계가 알아서 함 (튜닝 어려움) ✌️ MyBatis = 손빨래 🧼 개발자가 직접 물 붓고, 비비고, 헹구고 어떤 SQL 쿼리를 쓰고, 어떤 칼럼을 어떤 필드에 넣을지도 직접 지정 → 개발자는 “컨트롤을 많이 할 수 있음” → 다만 귀찮고 실수할 가능성 있음 🧩 JPA vs MyBatis 코드로 비교하기 ✅ JPA 예제 (Hibernate 기반) @Entity public class Member { @Id @GeneratedValue private Long id; private String name; } // 저장 Member m = new Member(\"Sungwoo\"); entityManager.persist(m); // 조회 Member result = entityManager.find(Member.class, m.getId()); 👉 SQL 없이 객체만 조작하면 됨! → INSERT, SELECT, UPDATE, DELETE를 자동으로 처리 ✅ MyBatis 예제 &lt;!-- mapper.xml --&gt; &lt;select id=\"findMemberById\" parameterType=\"long\" resultType=\"Member\"&gt; SELECT id, name FROM members WHERE id = #{id} &lt;/select&gt; // 자바 코드 Member m = memberMapper.findMemberById(1L); 👉 SQL을 내가 직접 작성함 → DB 구조가 복잡하거나 튜닝이 필요할 땐 더 유리 ✅ 사용 방식 차이 요약 항목 JPA MyBatis SQL 작성 ❌ 안 함 (자동) ✅ 직접 함 객체 ↔ DB 매핑 자동 처리 명시적 지정 코드 양 적음 많음 유지보수 테이블 구조 바뀌면 자동 적용 SQL 전부 수정해야 함 복잡한 쿼리 어려움 (JPQL, QueryDSL) 자유롭고 세밀하게 가능 ✅ 장단점 비교 🟢 JPA의 장점 생산성 높음 (코드 적게 작성) 객체 지향적으로 설계 가능 유지보수 편함 (쿼리 덜 바꿈) 캐싱, 지연 로딩, 영속성 컨텍스트 등 부가기능 풍부 JapRepository를 상속하면 Spring Data JPA가 자동으로 구현체를 만들어서 사용할 수 있게 해줌 자세히 정리한 포스트 👉 JPA Query Method 🔴 JPA의 단점 처음 배울 때 어렵고 추상화가 깊음 성능 튜닝 어려움 복잡한 쿼리 작성이 불편함 (JOIN, GROUP BY 등) 🟢 MyBatis의 장점 SQL을 자유롭게 짤 수 있어 → DB 성능 튜닝 유리 복잡한 쿼리나 데이터 조작에 강함 개발자 컨트롤이 높음 🔴 MyBatis의 단점 반복 코드 많음 (SQL + 매핑 따로) 유지보수 힘듦 (테이블 구조 바뀌면 SQL 전부 바꿔야 함) 객체 지향 구조 만들기 어렵고, 연결이 느슨함 ✅ 실무에 쓰는 방법 상황 실무 선택 단순한 CRUD 위주의 서비스 JPA (빠르고 코드 간결) 복잡한 SQL 다루는 시스템 MyBatis 대기업/공공 시스템 아직도 MyBatis 많음 스타트업/신규 프로젝트 JPA + QueryDSL 조합 인기 둘 다 필요 일부는 JPA, 일부는 MyBatis 혼용 (실제로 많음) 📌 한줄 정리 “JPA는 객체 중심의 ORM 프레임워크로, DB와의 데이터 처리를 추상화해 코드 생산성을 높여줍니다. 반면 MyBatis는 SQL 중심의 프레임워크로, 복잡한 쿼리나 성능 튜닝이 필요한 경우에 유리합니다. 프로젝트 성격에 따라 두 기술을 선택하거나 병행할 수 있습니다.”",
    "tags": "spring",
    "url": "/spring/2025-04-05-jpa-mybatis/"
  },{
    "title": "[TIL] JPA / MyBatis, AOP가 IoC한테 다 잡아 먹혔다",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #37 📅 작성일: 2025-04-04 🔄 최종 수정: 2025년 04월 09일 🍀 새롭게 배운 것 JPA / MyBatis 둘의 정확한 차이점과 코드 예제를 보기 위해 비교 및 비유를 통해 개념을 알아보았다. 블로그에 정리했다. JPA / MyBatis 강사님이 “AOP가 IoC한테 다 잡아 먹혔다”고 하셨는데, 이게 무슨 뜻인지 모르겠어서 알아보았다. (Spring Boot) Spring (특히 Spring Boot)에서 AOP와 IoC 컨테이너가 어떻게 결합되어 있는지를 강조하는 말 🎯 용어 정리 ✅ IoC (Inversion of Control, 제어의 역전) 객체를 내가 직접 만들고 관리하는 게 아니라, Spring이 대신 생성하고 주입(DI)해주는 개념 즉, Spring이 “제어권”을 가짐 우리는 클래스만 만들고, Spring 컨테이너가 빈(bean)으로 관리함 ✅ AOP (Aspect Oriented Programming, 관점 지향 프로그래밍) 핵심 로직과 공통 로직을 분리하기 위한 개념 로깅, 트랜잭션, 보안 체크 같은 걸 핵심 비즈니스 로직과 따로 분리해서 관리 대표적인 키워드: @Aspect, @Before, @After, @Around 📌 “AOP가 IoC한테 잡아먹혔다”는 말의 뜻 ✔️ 번역하자면… “이제 AOP가 별도로 동작하는 게 아니라, 전부 Spring의 IoC 컨테이너에서 빈으로 관리되고 제어된다는 의미” 🔍 실제 의미 과거엔? AOP가 독립적인 개념처럼 설명됐고, 설정도 직접 해야 했고 (@EnableAspectJAutoProxy, XML 설정 등) 지금은? Spring Boot에서는 AOP 기능이 전부 IoC 컨테이너 안에서 작동함 즉, 우리가 작성한 @Aspect 클래스도 Spring이 빈으로 등록해서 관리함 ➡ 이제 AOP는 Spring의 IoC 기반에서 움직이는 부가기능이 된 것. ➡ “Spring이 모든 걸 컨트롤한다” = “AOP조차도 IoC의 지배 아래 있다” 🔄 Spring Boot에서 바뀐 점 ✅ 설정이 훨씬 단순해짐 @Configuration @EnableAspectJAutoProxy public class AppConfig {} ➡ Spring Boot에선 이런 설정 생략 가능! ➡ @Aspect 달고 빈으로 등록만 하면 자동 적용됨 ✅ AOP 적용 대상도 빈(bean)만 됨 @Component @Aspect public class LoggingAspect { @Before(\"execution(* com.example.service.*.*(..))\") public void logBefore() { System.out.println(\"메서드 실행 전!\"); } } ➡ com.example.service 안의 메서드들이 AOP 대상이 되려면? ➡ 그 클래스들이 전부 빈이어야 함 ➡ Spring IoC 컨테이너가 관리하는 객체만 AOP 가능 👉 이게 바로 “AOP가 IoC에게 먹혔다”는 말의 핵심 포인트 📌 쉽게 요약하면 과거 AOP 지금(Spring Boot 기반 AOP) 독립적으로 설정해야 함 Spring Boot가 자동 설정 AOP가 Spring과 독립적인 느낌 AOP도 IoC 컨테이너 안에 완전히 포함 @EnableAspectJAutoProxy 필요 생략 가능 (자동 구성됨) AOP 대상 따로 인식 빈으로 등록된 객체만 AOP 적용 가능 ✅ 백엔드 개발자로서 이렇게 말하면 좋다. “Spring Boot에서는 AOP 기능이 Spring IoC 컨테이너 안에 통합돼 있어서, Aspect도 결국 빈으로 등록되어야 동작합니다. 과거에는 AOP 설정을 별도로 했지만, 지금은 Spring Boot의 자동 설정 덕분에 IoC 중심으로 모두 통합되어 관리되죠. 그래서 AOP도 결국 IoC의 흐름 안에서 작동한다고 볼 수 있습니다.” 🔍 실무에서 AOP를 쓰는 예 메서드 실행 시간 측정 로그인 체크 트랜잭션 처리 공통 로그 출력 @Around(\"execution(* com.example..*(..))\") public Object logTime(ProceedingJoinPoint joinPoint) throws Throwable { long start = System.currentTimeMillis(); Object result = joinPoint.proceed(); long end = System.currentTimeMillis(); System.out.println(\"실행 시간: \" + (end - start) + \"ms\"); return result; }",
    "tags": "TIL Java til",
    "url": "/til/2025-04-04-til/"
  },{
    "title": "[TIL] 오버플로우, 언더플로우, 버퍼 오버플로우 위험성",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #36 📅 작성일: 2025-04-03 🔄 최종 수정: 2025년 04월 09일 🍀 새롭게 배운 것 오버플로우, 언더플로우 버퍼 오버플로우가 왜 위험한지 궁금해서 이것도 알아보았다. 🔷 1. 숫자에서의 오버플로우 &amp; 언더플로우 ✔️ 정의 오버플로우 (Overflow): 값이 표현할 수 있는 범위를 초과한 경우 언더플로우 (Underflow): 값이 표현할 수 있는 최솟값보다 작아지는 경우 ✔️ 예시: 정수(int)의 범위 초과 unsigned char x = 255; x = x + 1; // -&gt; x는 0이 됨! (오버플로우) 📌 왜 0이 될까? unsigned char은 0~255까지만 저장 가능 (8bit) 255 + 1 = 256 → 표현할 수 없음 → 0부터 다시 시작 (mod 256) signed char y = 127; y = y + 1; // -&gt; y는 -128이 됨 (signed overflow) ✔️ 오버플로우 숫자 예시 타입 최대값 설명 unsigned char 255 (2⁸-1)   unsigned short 65535 (2¹⁶-1)   unsigned int 약 42억 (2³²-1 = 4,294,967,295)   signed int -2,147,483,648 ~ 2,147,483,647   🔷 2. 스택, 큐, 리스트 등 자료구조에서의 오버/언더플로우 ✔️ 오버플로우 스택이 가득 찬 상태에서 push하면 발생 큐가 가득 찬 상태에서 enqueue하면 발생 Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); stack.setSize(3); // 최대 3개 stack.push(1); stack.push(2); stack.push(3); stack.push(4); // ❌ StackOverflowError ✔️ 언더플로우 스택에서 비어 있는데 pop하면 발생 큐에서 요소 없는데 dequeue하면 발생 Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;(); q.poll(); // 비었는데 빼면 null 반환 (언더플로우) 📌 비유 오버플로우: 컵에 물을 넘치게 부음 언더플로우: 컵에서 물을 꺼내려 했는데, 이미 텅 비어 있음 🔷 3. 메모리에서의 오버플로우 (Stack Overflow, Buffer Overflow) 이건 C/C++에서 아주 심각한 보안 문제를 일으키는 부분. 💣 스택 오버플로우 (Stack Overflow) 함수를 재귀적으로 너무 많이 호출해서 스택 메모리를 넘쳐버림 💣 버퍼 오버플로우 (Buffer Overflow) 고정된 크기의 메모리 배열(buffer)을 넘어서 데이터를 쓰는 것 공격자는 이걸 이용해서 악성 코드 실행, 프로그램 흐름 장악 void vulnerable(char *input) { char buf[10]; strcpy(buf, input); // 길이 확인 안함 } int main() { vulnerable(\"AAAAAAAAAAAAAAAAAAAAAAAAA\"); // 💥 buffer overflow } 📌 해킹의 대표 기술 공격자가 buf 뒤에 있는 return address를 덮어씌워서, 자기 코드로 프로그램 흐름을 강제로 바꿔버림 → 시스템 장악 🚫 해결 방법: Rust 언어 사용 C/C++의 위험한 메모리 접근을 차단하기 위해 미국 국무부(DoS)에서도 권장 Rust는 메모리 안전(memory safety)을 컴파일 타임에 강제함 fn main() { let mut v = vec![1, 2, 3]; println!(\"{}\", v[100]); // panic! 런타임에서 안전하게 막아줌 } 배열 범위를 벗어나면 컴파일 또는 런타임에서 즉시 멈춰버림 (→ 보안상 안전) ✅ 전체 요약 범주 오버플로우 언더플로우 예시 문제 정수 범위 초과 → 값이 초기로 순환 최솟값보다 작음 → 값 왜곡 unsigned char x = 255 + 1 잘못된 계산 자료구조 공간 초과 시 push 등 비어 있는데 pop stack.push(4) when full 런타임 오류 메모리 스택 깊이 초과 / 버퍼 초과 거의 없음 char buf[10]; strcpy(buf, input); 해킹 가능 보안 대책 Rust, 메모리 안전 언어 컴파일러 경고, 타입 안전 Rust, Swift OS/국가 차원 도입 중 🔥 1. 왜 버퍼 오버플로우가 위험한가? ✅ 메모리는 일렬로 연결된 공간이야 함수를 실행하면 스택(stack)에 다음과 같은 순서로 저장돼: [로컬 변수] [리턴 주소] ← 함수가 끝난 뒤 어디로 돌아갈지 주소 이걸 공격자가 조작할 수 있다면? ➡ 함수가 끝난 뒤 돌아갈 주소를 자기 마음대로 바꿀 수 있어! ➡ 해커가 원하는 코드로 흐름을 바꿔버릴 수 있음!! 😱 💣 2. 실전 예시로 보기 (C 코드) void vulnerable(char *input) { char buf[10]; strcpy(buf, input); // 🔥 위험! 길이 체크 안 함 } 공격 입력: vulnerable(\"AAAAAAAAAA\\x90\\x90\\x90\\x90\\xDE\\xAD\\xBE\\xEF\"); \"AAAAAAAAAA\" → buf[10] 꽉 채움 \\x90...\\xEF → 리턴 주소를 덮어씀! 💀 3. 해커가 하는 짓 📌 목적: 리턴 주소를 조작해서 자신이 심어둔 쉘코드(shellcode) 로 흐름을 튼다! jmp *shellcode_address → 쉘 실행, 백도어 오픈 공격자가 만든 악성 코드를 버퍼 바로 뒤에 몰래 숨겨두고 리턴 주소를 그 코드 위치로 덮어씀 함수가 끝나는 순간 → 해커 코드 실행 🧠 비유로 이해해보자 너가 엘리베이터를 타고 10층(정상 리턴 주소)으로 가야 되는데, 누군가가 몰래 버튼 회로를 바꿔서 지하 해커실(해커 코드) 로 보내버린 것과 같아. 📍 왜 C/C++에서 잘 터지나? 포인터(pointer), 직접 메모리 접근, 길이 체크 안함 strcpy(), gets(), sprintf() 같은 함수들: 길이 제한이 없음 → 💥 🛡️ 대책: 메모리 안전 언어 (Rust, Swift 등) Rust 예시: let arr = [1, 2, 3]; println!(\"{}\", arr[10]); // 컴파일 또는 런타임에서 panic! Rust는: 배열 접근 시 범위 검사(bound check) 함 포인터를 마음대로 조작 못함 사용 후 자동으로 메모리 해제 (ownership) ➡ 해커가 리턴 주소에 접근 불가능 ➡ 버퍼 오버플로우로는 뚫을 수 없음 🔐 실제 피해 사례 해킹 사건 설명 MS Blaster 웜 (2003) 버퍼 오버플로우로 윈도우 서비스 제어 Heartbleed (2014) OpenSSL에서 메모리 무단 접근 SolarWinds (2020) 내부 시스템 오염 후, 취약점 타고 들어감 ➡ 대부분이 C/C++ 기반 시스템에서 발생",
    "tags": "TIL til",
    "url": "/til/2025-04-03-til/"
  },{
    "title": "[TIL] DTO vs VO vs Entity, DTO/DAO/Repository",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #35 📅 작성일: 2025-04-02 🔄 최종 수정: 2025년 04월 09일 🍀 새롭게 배운 것 DTO vs VO vs Entity 약간씩 다른 비슷한 개념인 것 같은데, 어떤 것이 정확히 다른지 알아보기 위해 블로그에 정리해보았다. DTO vs VO vs Entity DTO, DAO 이름이 비슷한데 역할이 다른 것 같아 아래에 정리해보았다. 공부하다 보니 Repository와 DAO도 비슷한 개념인 것 같아서 아래에 같이 정리했다. 📦 DTO (Data Transfer Object) 💡 데이터 “전달용” 객체 ✅ 개념 계층 간(Controller ↔ Service, Frontend ↔ Backend 등) 데이터를 주고받기 위한 객체 순수 데이터만 담는 클래스 (getter/setter만 있는 경우 많음) ✅ 예시 public class UserDTO { private String name; private int age; } ✅ 용도 API 요청/응답 데이터 전달 DB Entity와 분리된 가벼운 데이터 구조 🗃️ DAO (Data Access Object) 💡 DB에 접근하는 역할을 하는 객체 ✅ 개념 실제로 DB와 연결되어 데이터를 저장하거나 불러오는 역할 SQL 실행, JPA 사용 등 DB 처리 로직을 담당 ✅ 예시 public interface UserDAO { UserEntity findById(Long id); void save(UserEntity user); } ✅ 용도 DB 연동 로직을 캡슐화해서 Service 계층에서 쉽게 사용하도록 함 DB 종류가 바뀌어도 DAO만 바꾸면 되게 설계 가능 📌 핵심 비교 정리 항목 DTO DAO 의미 Data Transfer Object Data Access Object 역할 데이터 전달 전용 DB 접근/처리 전용 내용 필드 + getter/setter 메서드 (save, find 등 DB 작업) 위치 Controller ↔ Service 계층 사이 등 Service ↔ DB 사이에서 사용 비유 택배 상자 (데이터만 담음) 택배기사 (DB에서 데이터를 꺼내옴) Repositoryvs DAO ✅ 공통점 둘 다 데이터에 접근하기 위한 객체 보통 DB에서 데이터를 가져오거나 저장하는 역할을 한다. ✅ DAO (Data Access Object) 📌 정의 DAO는 데이터베이스에 직접 접근해서 데이터를 CRUD(Create, Read, Update, Delete)하는 객체 💡 특징 기술 중심: SQL, JDBC, MyBatis 같은 구체적인 구현 기술을 다룰 때 자주 씀. DB와 직접 소통하는 코드를 포함. 예전 Java에서 많이 쓰던 방식. 📦 예시 public class UserDao { public User findById(int id) { // JDBC, SQL 직접 사용 } public void save(User user) { // INSERT 쿼리 } } ✅ Repository (Spring에서의 의미) 📌 정의 Repository는 도메인 객체의 컬렉션처럼 다루기 위한 추상화된 계층이 💡 특징 비즈니스 관점에서 설계: “데이터 저장소”처럼 보이도록 추상화. Spring에서는 보통 @Repository 어노테이션 붙임. JPA에서는 CrudRepository, JpaRepository 등을 상속받아 간단하게 사용 가능. SQL보다 객체 지향적인 도메인 중심 접근. 📦 예시 @Repository public interface UserRepository extends JpaRepository&lt;User, Long&gt; { User findByEmail(String email); } 🔍 DAO vs Repository 요약 비교 항목 DAO Repository 의미 데이터에 접근하는 객체 도메인 저장소를 추상화한 객체 초점 기술 (SQL, JDBC, MyBatis) 비즈니스/도메인 중심 (JPA, ORM 기반) 구현 방식 구현체를 직접 만듦 인터페이스 + Spring Data JPA가 구현체 제공 어노테이션 사용 없음 (전통적인 Java 방식) @Repository 사용 대표 기술 JDBC, MyBatis Spring Data JPA, Hibernate ✨ 결론적으로… DAO는 전통적인 방식으로, 데이터베이스 중심의 설계. Repository는 도메인 중심의 설계 방식이며, Spring에서는 더 추상화된 계층 요즘 Spring 프로젝트에서는 대부분 Repository 패턴을 쓴다. 특히 JPA랑 궁합이 잘 맞는다.",
    "tags": "TIL til",
    "url": "/til/2025-04-02-til/"
  },{
    "title": "[Spring] DTO vs VO vs Entity",
    "text": "DTO vs VO vs Entity 📦 DTO vs VO 📦 Entity vs VO 📦 Entity와 DTO로 분리해야하는 이유 코드 예제 💬 면접 시 설명 예시 🚀 Java 17부터는 record로 VO를 만들기 더 쉬워짐! DTO vs VO vs Entity Entity는 DB와 매핑되는 핵심 객체, DTO는 데이터 전달용 객체, VO는 값 자체에 의미가 있는 불변 객체 Entity는 저장용, DTO는 전달용, VO는 표현용 객체 DTO : Data Transfer Object ➡️ 데이터 전달용 객체 (계층 간, 네트워크 등) 🚐 손님에게 배달될 포장된 도시락 음식점 → 배달기사 → 고객까지 전달하는 용도 💡 클라이언트와 데이터 주고받는 운반용 객체! 💡 메뉴명, 수량, 요청사항 등 담겨 있고, 전달 중에 수정될 수도 있음 (상황에 따라 포장을 다르게 담을 수 있다.) 외부에 노출되는 API요청이나 응답은 Entity가 아닌 DTO를 통해 전달함으로써 보안성과 유연성을 확보 🔴 DTO는 데이터를 “옮기는 상자” VO : Value Object ➡️ 값을 표현하는 객체 (의미 있는 불변 값) 🍱 도시락 자체 만들어지면 바꿀 수 없음 (불변) 메뉴가 같으면 같은 도시락 취급 값 자체가 의미 있음 - 예: 좌표, 돈, 날짜, 주소 등 🔴 VO는 의미 있는 값을 담은 “정체성 있는 객체” “무엇을 나타내는 값인지”가 중요한 객체 Entity ➡️ 실제 DB 테이블과 연결된 핵심 객체 🍱 도시락 안의 구성 요소 (밥, 반찬, 소스 등) 소중하기 때문에 주방 안에서만 써야 함 Entity는 VO를 포함할 수 있음 DB와 직접 연결된 객체이기 때문에 식별자가 존재하며 상태가 바뀔 수 있음 🔴 Entity는 “누구인지”를 식별할 수 있는 객체 📦 DTO vs VO 구분 DTO VO 목적 데이터 전달 값 표현 가변성 가변(mutable) 불변(immutable) equals/hashCode 기준 주소 (기본) 값 기준으로 재정의 주 사용 위치 Controller ↔ Service ↔ API 도메인 내부, 로직 내 값 처리 예시 회원 요청 객체, 응답 DTO 등 Money, Address, Coordinate 등 생성 시 언제든 생성 가능 생성 후에는 값 변경 ❌ 📦 Entity vs VO 항목 Entity VO 의미 DB 테이블과 1:1 매핑되는 객체 의미 있는 작은 값 단위 객체 식별자 (ID) 있음 (PK, 고유값) 없음 (값 자체로 구별) 불변성 보통 가변 보통 불변 (final) 관리 위치 DB와 연결되는 핵심 모델 Entity 안의 필드나 계산용 값 📦 Entity와 DTO로 분리해야하는 이유 굳이 클래스를 2개로 나누지 않고 그냥 Entity 하나로 다 처리하면 안 되는 이유! 구체적인 이유 5가지 보안 Entity에는 민감한 필드(비밀번호 등)가 있을 수 있음 ➡️ 그대로 외부에 노출하면 위험 유연성 API 요청/응답마다 필요한 필드가 다름 ➡️ DTO로 맞춤 설계 가능 엔티티 보호 DTO로 외부와 통신 ➡️ Entity는 내부에서만 안전하게 관리 유효성 검사 분리 @Valid, @NotNull등 검증 로직은 DTO에만 적용 Entity는 DB와 연결된 순수한 모델이여야 함으로 비즈니스 룰, 요청 유효성 검증 같은 책임이 없어야 한다. JPA의 역할은 저장, 조회인데 검증 로직이 섞이면 책임이 뒤엉킴 (SRP(Single Responsibility Principle) 위반) 레이어 분리 원칙 Controller ↔ Service ↔ Repository 역할 구분이 명확해짐 “Controller” : 클라이언트와 통신 (DTO 입출력) “Service” : 비즈니스 로직 (DTO 🔁 Entity 변환, 로직 처리) “Repository” : DB 접근 (Entity 전용) DTO와 Entity를 나누지 않고 Controller, Service에서 Entity를 직접 다루면 한 객체가 너무 많은 계층을 넘나듬 (의존성 얽힘) 책임이 명확하지 않음 (수정 시 어디를 고쳐야 할지 모름) 보안 이슈 발생 가능 (불필요한 필드 노출) 코드 예제 ✅ DTO (값 전달용, 가변 객체) public class MemberDTO { private String name; private int age; // 생성자 public MemberDTO(String name, int age) { this.name = name; this.age = age; } // getter &amp; setter (값 변경 가능!) public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } } setName(), setAge()처럼 값은 변경 가능 주로 Controller 🔁 Service 🔁 Client 간 데이터 전달용 ✅ VO (값 표현용, 불변 객체) public class Money { private final int amount; public Money(int amount) { this.amount = amount; } public int getAmount() { return amount; } // 값 기반 equals, hashCode @Override public boolean equals(Object o) { if (this == o) return true; if (!(o instanceof Money)) return false; Money money = (Money) o; return amount == money.amount; } @Override public int hashCode() { return Integer.hashCode(amount); } } 필드가 final, setter없음 → 불변 객체 equals() 재정의 → 값이 같으면 같은 객체로 간주 주로 비즈니스 로직 내부에서 의미 있는 값 표현용 ✅ Entity @Entity public class Member { @Id @GeneratedValue private Long id; private String name; private String password; // 노출되면 안 되는 정보 } 💬 면접 시 설명 예시 “DTO는 계층 간 데이터를 전달할 때 사용하는 객체로, 보통 가변이고 네트워크나 컨트롤러에 노출됩니다. 반면 VO는 불변 객체로, 값 자체가 의미를 가지며 equals와 hashCode를 통해 같은 값을 같다고 간주해 도메인 모델 내에서 활용됩니다. Entity는 DB와 직접 연결된 객체로 식별자가 존재하며 상태가 바뀔 수 있습니다. 외부에 노출되는 API 요청이나 응답은 Entity가 아닌 DTO를 통해 전달함으로써 보안성과 유연성을 확보할 수 있습니다.” 🚀 Java 17부터는 record로 VO를 만들기 더 쉬워짐! public record Coordinate(int x, int y) {} final, 불변성, equals/hashCode 자동 구현! 값 객체(VO)를 표현할 때 record는 아주 강력한 도구",
    "tags": "spring",
    "url": "/spring/2025-04-02-dto-vo/"
  },{
    "title": "[TIL] HttpClient/ RestTemplate/ WebClient, 논블로킹 vs 비동…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #34 📅 작성일: 2025-04-01 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 ✅ HttpClient, RestTemplate, WebClient Java에서 REST API와 통신할 수 있도록 하는 HTTP 클라이언트 공부하다 비슷한 개념들의 성능적 차이점을 알고 싶어 블로그에 HttpClient, RestTemplate, WebClient의 차이점에 대해 적어놓았다, RestTemplate ✅ 논블로킹 (Non-blocking) vs 비동기 (Asynchronous) 항목 비동기 논블로킹 개념 작업을 요청하고 바로 다음 코드 실행 (응답 기다리지 않음) 리소스(쓰레드 등)를 점유하지 않음 초점 시간(언제 실행될지 모름) 리소스 사용 여부 예시 콜백, Future, Promise, Mono read()호출 시 즉시 리턴 관련성 비동기 처리는 대부분 논블로킹 방식으로 구현됨 논블로킹이 항상 비동기인 건 아님 ✅ 보일러 플레이트 → 롬복 보일러 플레이트를 공부하다 롬복 개념과 비슷한 것이 있는 것 같아 어떤 관계가 있는지 알아보고 각각 개념에 대해서 자세히 정리해보았다. BoilerPlate와 Lombok ✅ 패키지, 모듈, 라이브러리, 프레임워크, 스켈레톤, 템플릿 한눈에 이 개념들에 대해 정리하고 싶어서 아래와 같이 만들었다! 💬 “Spring 프레임워크로 만든 스켈레톤 프로젝트에서, controller 패키지에 로그인 모듈 넣고, 이메일 템플릿을 Thymeleaf로 렌더링, Jackson 라이브러리로 JSON 파싱한다.” 개념 비교표 (한눈에 보기) 용어 개념 요약 백엔드 개발자가 알아야 할 포인트 패키지 클래스/파일들을 기능별로 묶은 폴더 Java, Python 등에서 파일 구조 잡을 때 사용 모듈 독립적으로 동작할 수 있는 기능 단위 기능 분리 → 유지보수/테스트/재사용에 중요 라이브러리 특정 기능을 수행하는 코드 집합 필요할 때 꺼내 쓰는 도구 (예: Gson, Lodash) 프레임워크 개발 구조를 잡아주는 뼈대 + 기능 제공 정해진 방식대로 개발 (Spring, Express 등) 스켈레톤 기본 구성만 갖춘 “빈 프로젝트” 프로젝트 시작 시 빠르게 셋업 가능 템플릿 반복되는 코드/구조를 미리 만들어둔 것 보일러플레이트 줄이기 (이메일 템플릿, HTML 구조 등) 🔍 하나씩 간단하게 설명 + 예시 1. 패키지 (Package) 📁 폴더처럼 코드 정리하는 단위 Java: com.myapp.controller, Python: myapp.utils 구조적 관리, 이름 충돌 방지 👉 왜 중요? → 프로젝트가 커질수록 패키지 구조 잘 잡는 게 유지보수 핵심 2. 모듈 (Module) 📦 독립적인 기능 단위 (예: 사용자 인증 모듈, 결제 모듈) 재사용 가능, 유닛 테스트 용이 👉 왜 중요? → 기능별로 나눠 개발하면 협업·유지보수가 쉬워짐 3. 라이브러리 (Library) 📚 함수/클래스를 모아놓은 도구 상자 내가 직접 작성하지 않고 가져다 쓰는 코드 예: Gson (JSON 파싱), JUnit (테스트) 👉 왜 중요? → 개발 효율성 급상승, 같은 기능 굳이 직접 안 만들어도 됨 4. 프레임워크 (Framework) 🏗️ 일정한 구조 + 기능 제공 개발자가 코드만 붙이면 동작함 (제어 흐름은 프레임워크가 담당 - IoC) 예: Spring, Express, Flask 👉 왜 중요? → 표준 구조로 팀 개발 가능, 학습 곡선 있지만 익히면 강력함 5. 스켈레톤 (Skeleton) 🦴 초기 프로젝트 구조만 갖춘 상태 (빈 틀) Spring Initializr가 생성해주는 구조 = 스켈레톤 보일러플레이트만 있는 기본 프로젝트 👉 왜 중요? → 빠르게 프로젝트 시작할 수 있음 6. 템플릿 (Template) 📄 반복 구조를 미리 만들어 놓은 코드 or UI HTML 이메일 템플릿, JSP 템플릿, 코드 생성 템플릿 등 👉 왜 중요? → 개발 생산성 증가, 디자인/구조 통일",
    "tags": "TIL til",
    "url": "/til/2025-04-01-til/"
  },{
    "title": "[Spring] HttpURLConnection, RestTemplate, WebClient",
    "text": "한눈에 보는 비교표 1. HttpURLConnection 2. RestTemplate 3. WebClient 현업 개발자들은 어떻게 생각할까? 간단 정리 선택 가이드 Java 환경에서 사용되는 HTTP 클라이언트인 HttpURLConnection, RestTemplate, WebClient 비교 🧱 1. HttpURLConnection (자바 기본 제공) 🚗 2. RestTemplate (Spring 제공, 동기) 🛸 3. WebClient (Spring WebFlux 제공, 비동기 &amp; 논블로킹) 📌 먼저, 한눈에 보는 비교표 항목 HttpURLConnection RestTemplate WebClient 제공 Java SE 표준 Spring Web (3.x~) Spring WebFlux (5.x~) 방식 동기 + 블로킹 동기 + 블로킹 비동기 + 논블로킹 쓰기 쉬움 ❌ 불편하고 코드 길다 ✅ 간결함 ✅ (조금 복잡하지만 유연함) 권장도 ❌ 현업에서 거의 안 씀 ⚠️ Spring 5부터 비권장 ✅ 최신 표준 성능 느림, 커넥션 재활용 어려움 괜찮음, 단순 요청에는 충분 (블로킹) 고성능 (Netty 기반), MSA에서 더 좋음 활용 Java 기본 네트워크 통신 간단한 API 호출 MSA, API Gateway, 대규모 호출 등 미래 방향 - Deprecated 예정 (Spring 6에서는 제거될 수 있음) Spring이 권장하는 표준 방식 ✅ 1. HttpURLConnection — Java 기본 클래스 URL url = new URL(\"https://api.example.com/data\"); HttpURLConnection conn = (HttpURLConnection) url.openConnection(); conn.setRequestMethod(\"GET\"); BufferedReader in = new BufferedReader(new InputStreamReader(conn.getInputStream())); String inputLine; StringBuilder content = new StringBuilder(); while ((inputLine = in.readLine()) != null) { content.append(inputLine); } in.close(); conn.disconnect(); ❌ 단점 코드가 너무 장황하고 귀찮음 커넥션 풀도 없음 (직접 관리해야 함) 에러 핸들링이 불편함 ✅ 장점 Spring 없이도 동작 (가벼운 프로젝트, 시험용 앱에 쓸 수 있음) 🚨 실무에선 거의 안 씀. RestTemplate/WebClient로 대체. ✅ 2. RestTemplate — 동기 &amp; 블로킹 방식의 Spring HTTP 클라이언트 RestTemplate restTemplate = new RestTemplate(); String response = restTemplate.getForObject(\"https://api.example.com/data\", String.class); → 응답이 올 때까지 기다림. 동기 처리. ✅ 장점 코드가 아주 간단함 Spring 기반이라 다양한 옵션 (converter, interceptor 등) 연동 쉬움 ⚠️ 단점 동기 + 블로킹이라, 요청 수가 많으면 쓰레드 고갈 위험 Spring 5 이후로 점점 사용 비권장됨 📢 Spring 공식 문서: “RestTemplate은 더 이상 발전하지 않으며, WebClient 사용을 권장함.” 🔧 주요 메서드들 메서드 설명 getForObject() GET 요청 후, 결과를 객체로 받음 getForEntity() GET 요청 후, 전체 응답(ResponseEntity) 받음 postForObject() POST 요청 후, 결과를 객체로 받음 postForEntity() POST 요청 후, 전체 응답 받음 put() PUT 요청 (응답 없음) delete() DELETE 요청 ✅ 3. WebClient — 비동기 &amp; 논블로킹 방식의 최신 HTTP 클라이언트 WebClient webClient = WebClient.create(); webClient.get() .uri(\"https://api.example.com/data\") .retrieve() .bodyToMono(String.class) .subscribe(result -&gt; System.out.println(\"결과: \" + result)); System.out.println(\"여긴 먼저 실행됨!\"); // 비동기니까 이게 먼저 출력될 수도 있음 ✅ 장점 논블로킹 + 비동기 처리 대규모 트래픽 처리에 유리 기능 확장도 쉬움 (OAuth2, Retry, Timeout 등) ❗ 단점 처음 배울 땐 리액티브 스트림(Mono/Flux)이 좀 낯설 수 있음 🌐 현업에서는 WebClient가 기본이 되고 있어! 특히 MSA(마이크로서비스) 환경에서는 거의 필수! 🔍 현업 개발자들은 어떻게 생각할까? “HttpURLConnection은 진짜로 아무것도 없을 때 테스트용으로만 씀” “RestTemplate은 작고 단순한 서비스에서는 아직도 많이 씀” “WebClient는 대규모 시스템이나 MSA, API Gateway에서 표준처럼 쓰이고 있음” 🧑‍💻 간단 정리 : “HttpURLConnection은 Java에서 기본 제공하는 HTTP 클라이언트지만, 코드가 장황하고 관리가 어렵기 때문에 Spring에서는 RestTemplate이나 WebClient를 사용합니다. RestTemplate은 동기 방식으로 간단한 API 호출에는 적합하지만, Spring 5부터는 WebClient처럼 비동기 + 논블로킹 방식을 사용하는 것이 대세입니다.” 🎁 선택 가이드 사용 상황 추천 방식 가볍게 테스트용 API 호출 RestTemplate or WebClient.block() 복잡한 서비스 간 통신, 고성능 서버 WebClient Java만 사용하는 초간단 도구 개발 HttpURLConnection (단, 실무에는 비권장) Spring 5 이상 + 새로운 프로젝트 WebClient를 사용하는 게 미래지향적",
    "tags": "spring",
    "url": "/spring/2025-04-01-resttemplate/"
  },{
    "title": "[Etc] 💣 SQL Injection",
    "text": "SQL Injection이란? Spring 관점에서 SQL Injection 방지법 요약 SQL Injection이란? SQL Injection이란, 사용자가 입력한 값을 통해 원래 의도하지 않은 SQL문을 실행하게 만들어 데이터베이스의 데이터를 탈취하거나 조작하는 공격 🔍 예시 (Spring 쓰기 전 일반 JDBC 코드 기준): String sql = \"SELECT * FROM users WHERE username = '\" + username + \"'\"; 만약 username에 아래와 같은 값을 입력하면? ' OR '1'='1 그러면 쿼리가 이렇게 바뀜: SELECT * FROM users WHERE username = '' OR '1'='1' → 모든 유저 정보가 다 조회됨 😱 → 비밀번호 없이 로그인도 가능해짐 🔐 Spring 관점에서 SQL Injection 방지법 ✅ 1. JDBC 직접 사용 시: PreparedStatement 필수! String sql = \"SELECT * FROM users WHERE username = ?\"; PreparedStatement pstmt = conn.prepareStatement(sql); pstmt.setString(1, username); // 자동으로 문자열 escape 처리 이렇게 하면 ' OR '1'='1 같은 입력도 그냥 문자열로 인식되므로 안전하다. ✅ 2. Spring JDBC Template 사용 시 String sql = \"SELECT * FROM users WHERE username = ?\"; User user = jdbcTemplate.queryForObject(sql, new Object[]{username}, userRowMapper); 여기서도 ?를 사용해서 바인딩하면 PreparedStatement가 적용되므로 안전하다. ✅ 3. JPA / Spring Data JPA 사용 시 JPA는 SQL을 직접 작성하지 않고 엔티티 중심으로 데이터를 다루기 때문에 기본적으로 SQL Injection에 강함! 🔸 예시: User user = userRepository.findByUsername(username); 이런 방식은 내부적으로 PreparedStatement를 사용하기 때문에 안전함. 🔸 커스텀 JPQL 사용 시에도 파라미터 바인딩 필수! @Query(\"SELECT u FROM User u WHERE u.username = :username\") User findByUsername(@Param(\"username\") String username); ✅ :username 형태로 파라미터 바인딩하면 OK ❌ 아래처럼 문자열 직접 연결하면 위험: @Query(\"SELECT u FROM User u WHERE u.username = '\" + username + \"'\") 🚨 Spring 배우는 입장에서 조심할 포인트 요약 상황 안전한 방법 주의할 점 JDBC 직접 사용 PreparedStatement 문자열 직접 연결 ❌ JdbcTemplate ? 자리 바인딩 사용 쿼리 조합 ❌ JPA / Spring Data JPA 파라미터 바인딩 (:param) JPQL 문자열 직접 붙이기 ❌ QueryDSL 완전 안전 (타입 기반 쿼리) - 사용자 입력값 처리 입력 검증, 길이 제한 필터 없이 바로 사용 ❌ 🎯 마무리 요약 SQL Injection = 사용자가 입력한 값을 통해 악성 SQL 실행 Spring에서는 기본적으로 PreparedStatement 방식이므로 잘 쓰면 안전함 하지만 직접 쿼리 짜거나, 문자열로 SQL을 조합하는 경우 주의! ORM(JPA) + 파라미터 바인딩 방식으로 작성하면 거의 대부분 안전하게 막을 수 있음",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-03-31-sql-injection/"
  },{
    "title": "[TIL] Spring에서 interface와 abstract class",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #33 📅 작성일: 2025-03-28 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 Spring을 공부하다가 interface와 abstract class 개념이 헷갈려서 둘 사이에 어떤 관계가 있는지 알아보았다. 인터페이스를 추상 클래스가 상속받는 경우는 고급개념이라고 한다.. ✅ 인터페이스(interface)란? 일종의 기약(약속). 어떤 기능을 반드시 구현해야 한다는 걸 명시해주는 것. 예: interface Animal { void sound(); } → Animal 인터페이스를 구현하는 클래스는 sound()를 반드시 구현해야 함. ✅ 추상 클래스(abstract class)란? 일부는 구현되어 있고, 일부는 구현이 안 된 중간 단계의 클래스 공통 기능은 구현하고, 필수 구현 사항은 abstract로 남김. ✅ 그럼 인터페이스를 추상 클래스가 “상속받는”다는 건? public interface Animal { void sound(); void eat(); } public abstract class AbstractAnimal implements Animal { // 일부만 구현함 @Override public void eat() { System.out.println(\"This animal eats food.\"); } // sound()는 구현 안 함 → 자식 클래스가 구현하게 만듦 } 👉 이렇게 쓰는 이유? 공통 로직을 추상 클래스에서 한 번만 구현하고, 각 서브 클래스는 나머지 인터페이스 기능만 구현하면 되니까 코드가 더 깔끔해진다. 💡 Spring에서 자주 쓰이는 이유 예를 들어, 여러 서비스 클래스가 공통적인 작업(예: 로깅, 에러 처리 등)을 해야 할 때: public interface MyService { void doSomething(); } public abstract class AbstractMyService implements MyService { protected void log(String msg) { System.out.println(\"[LOG] \" + msg); } } → 이렇게 추상 클래스에서 공통 기능을 넣어두면, 실제 서비스 클래스에서는 doSomething()만 구현하면 돼서 유지보수가 쉬워진다. 🔁 정리하자면! 인터페이스: “이 기능은 꼭 만들어야 해!”라고 강제. 추상 클래스: “공통 코드는 여기 있어. 너는 나머지만 구현해!” 인터페이스를 추상 클래스가 상속받는 것: 공통 기능은 추상 클래스가 제공하고, 나머지는 자식 클래스에게 위임하는 깔끔한 구조. class, interface, abstract class를 통한 설계 예시 // 인터페이스 interface Flyable { void fly(); } interface Attackable { void attack(); } // 추상 클래스 abstract class Character { void move() { System.out.println(\"이동 중...\"); } abstract void specialSkill(); } // 구체 클래스 class Warrior extends Character implements Attackable { public void attack() { System.out.println(\"검으로 공격!\"); } public void specialSkill() { System.out.println(\"분노 발동!\"); } } class Fairy extends Character implements Flyable { public void fly() { System.out.println(\"훨훨 날기~\"); } public void specialSkill() { System.out.println(\"마법 사용!\"); } } 이런 식으로 하면 공통 기능은 추상 클래스, 특수 능력은 인터페이스로 조합해서 유연한 설계가 가능.",
    "tags": "TIL Spring til",
    "url": "/til/2025-03-28-til/"
  },{
    "title": "[TIL] Github Gist, SQL Injection",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #32 📅 작성일: 2025-03-27 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 Github Gist 자주 사용하는 코드를 저장해 curl로 사용하니 너무 편해서 어떤 목적으로 만들어졌는지, 어떤 역할을 하는지 알아보았다. SQL Injection 강의로 새롭게 배운 개념! 블로그에 정리해두었다. (https://nan0silver.github.io/miscellaneous/2025-03-31-sql-injection/) ✅ 1. Gist란? GitHub Gist는 GitHub에서 제공하는 서비스로, 작은 코드 파일이나 문서를 웹에 간단하게 올리고 공유할 수 있게 해주는 기능 GitHub Gist는 간단하게 코드를 공유하거나 저장할 수 있는 도구로, 마치 작은 Git 저장소처럼 작동 코드 조각(snippet), 설정 파일, 메모 등을 쉽게 저장하고 다른 사람과 공유할 수 있음 ✅ 2. Gist의 역할 역할 설명 📦 코드 스니펫 저장소 자주 쓰는 코드 조각을 저장해두고 필요할 때 꺼내 쓸 수 있음 🔗 공유 링크 생성 gist를 만들면 고유 URL이 생겨서, 친구나 동료에게 간단히 공유할 수 있음 👀 코드 리뷰 다른 사람이 네 Gist를 보고 의견을 남길 수도 있음 (공개 설정인 경우) ⏱️ 빠른 테스트 간단한 코드 테스트나 예제 공유에 적합 🧾 문서/메모 저장 마크다운(.md)도 지원해서, 간단한 문서나 메모 용도로도 사용 ✅ 3. 종류는 두 가지! 종류 설명 🔓 Public Gist 누구나 볼 수 있음. 검색도 가능하고 공유도 쉬움 🔒 Secret Gist 링크를 아는 사람만 볼 수 있음. 완전한 비공개는 아님! ✅ 4. 어떻게 써? (1) Gist 만들기 GitHub 계정 로그인 gist.github.com 접속 파일 이름, 내용 작성 Public 또는 Secret 선택 “Create public/secret gist” 클릭! (2) Gist 활용 예시 자주 사용하는 Bash 스크립트 저장 Flask 서버 예제 코드 공유 친구한테 “이거 이렇게 하면 돼” 하고 코드 보내기 Markdown으로 프로젝트 설명 써서 저장 JSON 형식 설정파일 공유 (ex: .eslintrc, package.json 일부) ✅ 5. 특징 요약 Git 기반이어서 버전 관리 자동으로 됨 깃허브 계정 있으면 누구나 사용 가능 웹 인터페이스로 쉽게 작성하고 수정 가능 ✨ 예시 예를 들어, 자주 쓰는 Python 코드가 있다고 가정: def say_hello(name): return f\"Hello, {name}!\" 이걸 Gist로 만들어서 링크로 저장해두면, 나중에 다른 프로젝트에서 그냥 링크 들어가서 복붙하거나, 다른 사람한테 “이거 써봐” 하고 줄 수 있다.",
    "tags": "TIL Git til",
    "url": "/til/2025-03-27-til/"
  },{
    "title": "[TIL] REST API vs GraphQL, 멱등성",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #31 📅 작성일: 2025-03-24 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 REST API vs GraphQL REST API는 알지만 GraphQL은 처음 들어서 비교해서 찾아보았다. 멱등성 API에 대해 더 찾아보다 멱등성이라는 단어 뜻을 잘 모르겠어서 이것 또한 공부해보았다. 🆚 REST API vs GraphQL 항목 REST API GraphQL 형식 여러 개의 URL (엔드포인트) 단 하나의 URL 요청 방식 HTTP 메서드 (GET, POST 등) GraphQL 쿼리 언어로 요청 데이터 반환 고정된 형식 (필드가 많을 수도 적을 수도 있음) 원하는 데이터만 선택 가능 과fetching/underfetching 있음 (필요한 것보다 많이/적게 받을 수 있음) 없음 (딱 원하는 데이터만 받음) 버전 관리 버전 필요 (ex. /v1, /v2) 필요 없음 (쿼리로 해결 가능) 🍔 비유로 이해하기 🍱 REST API는 세트 메뉴 예를 들어 /users/1에 요청하면: { \"id\": 1, \"name\": \"Seongwoo\", \"email\": \"abc@abc.com\", \"posts\": [...], \"followers\": [...] } 나는 name만 필요했는데, 이것저것 다 받아옴 → overfetching 🍔 GraphQL은 뷔페 스타일 같은 유저 정보를 GraphQL로 요청하면: query { user(id: 1) { name email } } 그럼 딱 이것만 받아온다: { \"data\": { \"user\": { \"name\": \"Seongwoo\", \"email\": \"abc@abc.com\" } } } → 필요한 것만 쏙쏙! ✅ 각 방식의 장단점 🔹 REST API 장점 간단하고 익숙함 (HTTP만 알면 됨) 웹 캐싱, 로깅 등 기존 기술과 잘 맞음 단점 불필요한 데이터 많이 받거나, 여러 번 요청해야 할 수 있음 (overfetching, underfetching) 버전 관리 필요할 수 있음 🔹 GraphQL 장점 원하는 데이터만 선택 가능 (쿼리 자유도 높음) 한 번 요청으로 여러 리소스도 OK 버전 관리 필요 없음 단점 쿼리 구조 학습 필요 캐싱이나 보안 관리가 REST보다 복잡함 단순한 API에는 오버스펙일 수 있음 📌 실제 선택 기준 상황 추천 단순하고 전통적인 API (ex. 블로그, 게시판) REST API 클라이언트가 다양하고 데이터 구조가 복잡함 (ex. 모바일, 웹 앱 모두 지원) GraphQL 프론트엔드 개발자와 백엔드 협업이 많고, 데이터 요청을 세밀하게 제어하고 싶다 GraphQL ✅ 멱등성(Idempotence)이란? “요청을 몇 번 보내든 결과가 같으면 멱등하다” (결과가 한 번 보냈을 때랑, 열 번 보냈을 때랑 똑같음) 🎨 비유로 이해하기 ☕ 카페에서 “아이스 아메리카노 하나 주세요” 라고 한 번 말했을 때: 직원이 커피를 하나 만들어줌. 근데 내가 실수로 같은 말 3번 반복: “아아 하나 주세요!” “아아 하나 주세요!” “아아 하나 주세요!” 🔥 멱등하지 않은 행동 → 커피 3잔 나옴 (요청마다 결과가 바뀜) → 커피를 여러 잔 주문하게 됨 = 멱등하지 않음 🧊 반면에 “제 테이블 물 좀 치워주세요!”라고 요청했을 때 직원이 한 번 치웠고, 내가 두 번 더 말해도 → 테이블은 이미 깨끗하니까 더 이상 바뀌는 게 없어 ✅ 멱등한 행동 → 몇 번 말해도 결과가 같다 ✅ HTTP에서의 멱등성 메서드 멱등성 설명 GET ✅ 있음 몇 번 조회해도 데이터는 그대로 DELETE ✅ 있음 이미 지운 자원은 또 지워도 아무 일 없음 PUT ✅ 있음 같은 데이터로 덮어쓰기 = 결과 동일 PATCH ⚠️ 보통 있음 일부 수정이 동일하면 멱등, 하지만 상황에 따라 다름 POST ❌ 없음 새 데이터 생성 = 요청마다 다른 결과 생김 (예: id가 달라짐) 📦 예시 코드로 보기 (유저 정보 수정) PUT (멱등함) PUT /users/1 { \"name\": \"Seongwoo\", \"email\": \"woo@email.com\" } → 몇 번 요청해도 name, email은 똑같이 덮어씀 = 멱등함 POST (멱등하지 않음) POST /users { \"name\": \"Seongwoo\", \"email\": \"woo@email.com\" } → 요청할 때마다 새로운 유저 생성됨 (id=2, id=3…) = 결과 계속 달라짐 🎯 멱등성은 왜 중요할까? 통신 오류/재전송 시 안전하게 설계 같은 요청이 여러 번 가도 데이터 꼬임 없음 캐싱/로깅/트랜잭션 처리에 유리 GET, PUT 등은 중간에 캐시해도 무방 안정성 높은 API 설계 가능 ✏️ 정리 한 줄 요약 멱등성 = 요청을 여러 번 보내도 결과가 똑같은 성질",
    "tags": "TIL til",
    "url": "/til/2025-03-24-til/"
  },{
    "title": "[TIL] DBaaS, Docker",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #30 📅 작성일: 2025-03-20 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 DBaaS Docker 잘 알지 못하고 듣기만 했던 두 개념에 대해 알아보았다. 🗄️ DBaaS (Database as a Service) ✅ 개념 클라우드에서 제공하는 데이터베이스 서비스 사용자는 설치나 관리 없이 데이터베이스를 바로 사용 가능 ✅ 장점 직접 서버에 DB 설치할 필요 없음 백업, 복구, 보안, 스케일링 등 관리 자동화 빠르게 배포 가능 ✅ 대표 서비스 Firebase Realtime DB / Firestore Amazon RDS Google Cloud SQL Supabase (PostgreSQL 기반) ✅ 사용 예시 프로젝트에서 DB 인프라 없이 바로 클라우드에서 PostgreSQL 사용하고 싶을 때 → Supabase 연결해서 바로 쿼리 날림 🐳 Docker ✅ 개념 애플리케이션을 컨테이너(Container) 라는 가상환경에 패키징해서 실행하는 기술 코드 + 실행 환경을 같이 묶음 ✅ 장점 어떤 환경에서도 동일하게 실행됨 (로컬, 서버, 클라우드 어디서나 OK) 설치 복잡한 개발 환경도 이미지 한 방으로 구축 가능 배포 자동화 (CI/CD)와 찰떡궁합 ✅ 주요 개념 이미지(Image): 실행에 필요한 모든 걸 담은 템플릿 컨테이너(Container): 이미지를 실행한 실제 인스턴스 Dockerfile: 이미지를 만들기 위한 스크립트 ✅ 사용 예시 백엔드 서버 + DB + 프론트 구성 → Docker로 각각 컨테이너 구성해서 한 번에 실행 docker-compose up",
    "tags": "TIL DevOps til",
    "url": "/til/2025-03-20-til/"
  },{
    "title": "[Algorithm] 소수 빠르게 찾는 법",
    "text": "기본 소수 판별 에라토스테네스의 체 Miller-Rabin 소수 판별법 1️⃣ 기본 소수 판별 (O(√N)) 어떤 숫자 N이 소수인지 판별하는 가장 기본적인 방법은 1과 자기 자신을 제외한 다른 수로 나누어떨어지는지 확인하는 것 🔥 2부터 √N까지 나누어보자! 소수가 아니라면 작은 약수를 가지고 있기 때문 코드 예제 public class PrimeCheck { public static boolean isPrime(int n) { if (n &lt; 2) return false; for (int i = 2; i &lt;= Math.sqrt(n); i++) { if (n % i == 0) return false; } return true; } public static void main(String[] args) { System.out.println(isPrime(29)); //true System.out.println(isPrime(100)); //false } } 2️⃣ 에라토스테네스의 체 (O(N log log N)) 여러 개의 소수를 빠르게 찾는 방법 1부터 N까지의 수 중에서 소수를 모두 찾아야 하는 경우 🔥 방법 2부터 시작해서 배수들을 모두 제거 남은 수들만 소수로 판별 장점 한 번 계산해 두면 특정 범위 내에서 빠르게 소수 여부를 판별할 수 있음. 코드 예제 import java.util.*; public class SieveOfEratosthenes { public static List&lt;Integer&gt; sieveOfEratosthenes(int n) { boolean[] isPrime = new boolean[n+1]; Arrays.fill(isPrime, true); isPrime[0] = isPrime[1] = false; for (int i = 2; i * i &lt;= n; i++) { if (isPrime[i]) { for (int j = i*i; j &lt;= n; j += i) { isPrime[j] = false; } } } //소수 리스트 생성 } } 3️⃣ Miller-Rabin 소수판별법 (O(log N)) 소수 판별이 자주 필요할 때 N이 엄청 크면 밀러-라빈 소수판별법을 사용해야함 10^18이상의 큰 수가 소수인지 판별할 때 암후학, 해시 관련 문제에서 사용 🔥 확률적 알고리즘 코드 예제 import java.util.Random; public class MillerRabin { public static boolean isPrime(long n, int k) { // k는 테스트 횟수 if (n &lt; 2) return false; if (n == 2 || n == 3) return true; if (n % 2 == 0) return false; // n - 1 = 2^r * d 형태로 변환 long d = n - 1; int r = 0; while (d % 2 == 0) { r++; d /= 2; } Random rand = new Random(); // Miller-Rabin 테스트 실행 for (int i = 0; i &lt; k; i++) { long a = 2 + rand.nextLong(n - 3); // 2 ≤ a ≤ n-2 long x = powerMod(a, d, n); // x = a^d % n if (x == 1 || x == n - 1) continue; boolean isComposite = true; for (int j = 0; j &lt; r - 1; j++) { x = powerMod(x, 2, n); // x = x^2 % n if (x == n - 1) { isComposite = false; break; } } if (isComposite) return false; // 합성수 판별 } return true; // 소수 판별 } // (base^exp) % mod 연산 (빠른 거듭제곱) private static long powerMod(long base, long exp, long mod) { long result = 1; base %= mod; while (exp &gt; 0) { if ((exp &amp; 1) == 1) { // 홀수 지수 처리 result = (result * base) % mod; } base = (base * base) % mod; // 제곱 exp &gt;&gt;= 1; // 지수 나누기 2 } return result; } public static void main(String[] args) { System.out.println(isPrime(15485863, 5)); // true (소수) System.out.println(isPrime(1000000007, 5)); // true (소수) System.out.println(isPrime(1000000008, 5)); // false (합성수) } }",
    "tags": "algorithm",
    "url": "/algorithm/2025-03-20-is-prime/"
  },{
    "title": "[TIL] Spring Boot 기반의 MSA에서 오류 처리 방식",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #29 📅 작성일: 2025-03-19 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 Spring Boot 기반의 MSA(마이크로서비스 아키텍처)에서 오류 처리 방식 💥 오류(Error)는 왜 발생할까? 데이터베이스(DB) 장애 → “내가 터질게!” (예: AWS RDS 다운) 외부 API 장애 → “FCM(푸시 서버) 안 돼요!” (예: 결제 서버 점검 중) 서버 자체 장애 → “레디스(캐시 DB)가 서버비 미납으로 종료” 네트워크 문제 → “WAS(웹 애플리케이션 서버) 연결 끊김” 트래픽 과부하 → “주식 거래 사이트 폭주!” ⚙️ 오류를 처리하는 방법 (AOP &amp; MSA 관점) 1. “Plan B” 대체 시스템을 사용 서비스에서 DB나 API 장애가 발생하면, 다음과 같은 방법으로 처리합니다. 대체 DB/API 호출: 메인 DB가 죽으면 백업 DB 사용 캐시(Cache) 활용: Redis, Memcached 등으로 데이터를 빠르게 제공 Failover 시스템: 다른 서버로 트래픽을 분산 예제: 데이터베이스 장애 발생 시 대체 DB 호출 try { return mainDatabase.query(\"SELECT * FROM users\"); } catch (DatabaseException e) { return backupDatabase.query(\"SELECT * FROM users\"); // 대체 DB 사용 } 2. 오류 감지 &amp; 처리 (AOP, Exception Handling) AOP(Aspect-Oriented Programming)로 공통 로직 처리 AOP를 사용하면, 각 서비스에서 일일이 예외처리를 할 필요 없이 한 곳에서 관리할 수 있습니다. 📌 예제: 오류를 자동 감지하고 로깅 @Aspect @Component public class LoggingAspect { @Around(\"execution(* com.example.service.*.*(..))\") public Object logErrors(ProceedingJoinPoint joinPoint) throws Throwable { try { return joinPoint.proceed(); } catch (Exception e) { System.err.println(\"에러 발생: \" + e.getMessage()); throw e; // 오류를 컨트롤러까지 던짐 } } } 3. 컨트롤러에서 최종 응답 처리 서비스에서 처리할 수 없는 심각한 오류가 발생하면 컨트롤러에서 최종 결정합니다. 📌 예제: HTTP 상태 코드 반환 @RestController @RequestMapping(\"/api\") public class UserController { @GetMapping(\"/user\") public ResponseEntity&lt;String&gt; getUser() { try { return ResponseEntity.ok(userService.getUserData()); } catch (DatabaseException e) { return ResponseEntity.status(HttpStatus.SERVICE_UNAVAILABLE).body(\"DB 장애 발생!\"); } catch (Exception e) { return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body(\"서버 오류!\"); } } } 🛠 결과: 정상: 200 OK DB 장애: 503 Service Unavailable 서버 장애: 500 Internal Server Error 4. 트래픽 증가 대응 (스케일링) 사용자가 많아지면 서버가 버티지 못할 수도 있습니다. 이럴 때 오토 스케일링(Auto Scaling)을 사용합니다. Kubernetes(K8s) 활용: 컨테이너 단위로 서버 자동 확장 HPA(Horizontal Pod Autoscaler): CPU 사용량이 일정 수준 이상이면 자동으로 서버 개수를 늘림 로드 밸런서 (LB, Load Balancer): 트래픽을 여러 서버에 분산 📌 예제: K8s에서 HPA 설정 apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: my-app-hpa spec: maxReplicas: 5 # 최대 5개 서버까지 확장 minReplicas: 2 # 최소 2개 유지 targetCPUUtilizationPercentage: 80 # CPU 사용량 80% 이상이면 서버 추가 🛠 결과: 사용자가 많아지면 → 서버 자동 증가 사용자가 줄어들면 → 서버 자동 축소 🔎 🔥 전체적인 오류 처리 흐름 📌 오류 발생 시 시스템이 어떻게 대처하는지 정리 (각 단계에서 어떻게 대응하는지 확인) 서비스 실행 사용자가 웹사이트에 접속 요청을 컨트롤러가 서비스로 전달 예기치 못한 장애 발생 데이터베이스 장애 발생! 결제 시스템 응답 없음! 서비스 대응 대체 API/DB 호출 대체할 게 없다면 → 오류 던짐 컨트롤러에서 최종 오류 처리 500 에러 반환 사용자가 알아볼 수 있도록 “잠시 후 다시 시도하세요” 메시지 출력 스케일링 및 복구 K8s가 서버를 확장하여 복구 진행 시스템이 정상적으로 돌아옴 📌 한눈에 보는 아키텍처 개념도 (시각화) 📊 Spring Boot 3 &amp; MSA 아키텍처에서 오류 처리 및 대응 과정 [ 시스템 오류 대응 흐름 ] [User] ↓ 요청 [Controller] ↓ [Service] ----&gt; [Database] ❌ 장애 발생! ↓ ↓ [대체 API/DB 호출] 🟢 정상 응답 or ❌ 대체 실패 ↓ [Controller] ⚠️ 오류 처리 ↓ [View] \"오류가 발생했습니다. 다시 시도하세요.\" 🏁 결론: 오류를 어떻게 효과적으로 처리할까? AOP를 활용해 예외처리를 한 곳에서 관리 모든 서비스에 일일이 if-else 조건을 넣지 않고, 공통으로 처리 가능 대체 시스템(Plan B) 준비 DB 장애 시 백업 DB 사용 API 장애 시 캐시/대체 API 활용 컨트롤러에서 최종 응답 제어 사용자에게 적절한 오류 메시지를 제공 트래픽 증가 시 자동 확장 Kubernetes, HPA, 로드 밸런서를 활용하여 서버 자동 확장",
    "tags": "TIL Spring Project til",
    "url": "/til/2025-03-19-til/"
  },{
    "title": "[TIL] HttpServlet VS Servlet, 실무에서 Servlet을 쓰는가?",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #28 📅 작성일: 2025-03-17 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 HttpServlet VS Servlet HttpServlet은 Servlet의 하위 개념(자식 클래스) 실무에서 Servlet을 쓰는가? Spring을 더 많이 사용! HttpServlet VS Servlet Servlet은 기본 틀(interface)이고, HttpServlet은 그걸 확장해서 HTTP 웹 요청을 처리하는 클래스 Spring이나 Java 웹 개발할 때는 대부분 HttpServlet을 상속해서 웹 요청을 처리 1️⃣ Servlet (인터페이스) Java에서 웹 요청을 처리하기 위한 기본 설계도 (interface) HTTP뿐만 아니라 FTP, SMTP 등 다양한 프로토콜도 처리할 수 있도록 설계된 아주 범용적인 규격이야. 그래서 실제 웹 개발에서는 직접 사용하기보다는, 이걸 확장한 HttpServlet을 더 자주 사용. 📌 선언 예시: public interface Servlet { void init(ServletConfig config); void service(ServletRequest req, ServletResponse res); void destroy(); ... } 2️⃣ HttpServlet (클래스) HttpServlet은 GenericServlet을 상속받고, HTTP 요청만 처리하도록 만든 클래스 즉, 웹 브라우저가 보내는 GET, POST, PUT, DELETE 같은 HTTP 방식의 요청을 처리하는 데 특화돼 있음 📌 선언 예시: public class HttpServlet extends GenericServlet { protected void doGet(HttpServletRequest req, HttpServletResponse res) { ... } protected void doPost(HttpServletRequest req, HttpServletResponse res) { ... } } 🚀 서블릿(Servlet)을 그대로 쓰는 경우? (거의 안 씀) 서블릿(Servlet)은 Java로 웹 애플리케이션을 만들 때 가장 기본적인 기술이야. 하지만 지금은 거의 직접 사용하지 않음! 대신, Spring 같은 프레임워크가 서블릿을 감싸서(Wrapping) 쉽게 사용할 수 있도록 도와준다. 🔥 서블릿(Servlet)이란? 서블릿(Servlet)은 Java로 웹 서버에서 동작하는 프로그램. 웹 브라우저가 요청하면 서버에서 응답을 보내주는 역할을 함 💡 쉽게 말하면, “웹 요청을 처리하는 Java 프로그램” ❌ 그런데, 왜 직접 안 쓰지 않을까? 서블릿을 직접 쓰면 복잡하고, 코드가 길어지고, 관리가 어려움 예를 들어, 서블릿을 직접 만들면 이렇게 길고 복잡한 코드가 필요하다: import java.io.IOException; import javax.servlet.ServletException; import javax.servlet.annotation.WebServlet; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; @WebServlet(\"/hello\") public class HelloServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\"text/html\"); response.getWriter().println(\"&lt;h1&gt;Hello, Servlet!&lt;/h1&gt;\"); } } 위처럼 서블릿을 직접 쓰면 코드가 길고, 설정이 많고, 유지보수가 어려움! 그래서 대부분의 Java 웹 개발자는 Spring 프레임워크를 사용 ✅ Spring이 서블릿을 감싸서(Wrapping) 쉽게 만들어줌! Spring은 서블릿을 내부적으로 사용하면서도 개발자가 쉽게 웹 애플리케이션을 만들 수 있도록 도와준다. Spring을 쓰면 위 서블릿 코드 대신, 이렇게 간단하게 쓸 수 있다: import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/hello\") public class HelloController { @GetMapping public String sayHello() { return \"Hello, Spring!\"; } } Spring이 내부적으로 서블릿을 다 처리해 주기 때문에 코드가 간결해지고 유지보수도 쉬움 그래서 현재 Java 웹 개발은 Spring을 기본으로 사용하고, 서블릿을 직접 쓰는 경우는 거의 없음 🎯 하지만 서블릿을 직접 쓰는 경우도 있음! 전자정부 프레임워크(eGovFrame) 한국 정부 및 공공기관에서 많이 쓰는 프레임워크인데, 내부적으로 서블릿을 사용함. Spring 기반이지만, 서블릿과 JSP를 함께 쓰는 방식이 남아 있음. 매우 가벼운 웹 애플리케이션을 만들 때 Spring은 기능이 많아서 무겁기 때문에, 가끔 간단한 프로젝트에서 서블릿을 직접 쓰기도 함. 기존 레거시 시스템 유지보수 옛날에 만든 시스템이 서블릿을 기반으로 개발되어 있다면, 그걸 유지보수해야 할 수도 있음. 🔢 서블릿의 최신 버전? (Servlet 4 vs 6) 서블릿도 계속 발전하는데, 최신 버전은 Servlet 6.0이야! ✅ Servlet 4.0 (2017년, Java EE 8) HTTP/2 지원 (속도 개선) 비동기 요청 개선 (더 빠른 응답 가능) ✅ Servlet 6.0 (2022년, Jakarta EE 10) Java 21 지원 (최신 Java 버전 호환) 구식 API 제거 (레거시 코드 정리) 보안 개선 (더 안전한 웹 애플리케이션 개발 가능) 🔥 결론 1️⃣ 서블릿을 직접 쓰는 경우는 거의 없다! 2️⃣ 대부분 Spring 같은 프레임워크가 서블릿을 감싸서(Wrapping) 제공함. 3️⃣ 하지만 전자정부 프레임워크 같은 경우에는 서블릿을 직접 사용할 수도 있음. 4️⃣ 서블릿 최신 버전은 6.0 (Jakarta EE 10 기준). 하지만 대부분 Spring을 쓰기 때문에 신경 쓸 일이 많지는 않음. 📌 즉, 요즘 Java 웹 개발은 대부분 “Spring으로 한다”",
    "tags": "TIL til",
    "url": "/til/2025-03-17-til/"
  },{
    "title": "[Spring] Spring VS Servlet",
    "text": "Servlet과 Spring의 차이 Servlet Spring Servlet vs Spring 비교 정리 표 결론 🌐 Servlet과 Spring의 차이: 쉽게 이해하기 Servlet과 Spring은 Java로 웹 애플리케이션을 개발할 때 사용하는 기술 하지만 Servlet은 아주 기본적인 웹 기술이고, Spring은 이를 확장한 강력한 프레임워크 🍽️ 비유: 레스토랑 운영 방식으로 이해하기 Servlet = “직접 주문받고 요리하고 서빙하는 작은 식당” Spring = “자동 주문 시스템과 직원이 있는 대형 레스토랑” Servlet: 직접 요청을 처리하는 원시적인 방식 Servlet은 웹 요청을 처리하는 가장 기본적인 방법 개발자가 요청을 받고, 응답을 만들고, HTML을 직접 작성해야 함. Servlet의 특징 ✅ 웹 요청을 직접 받아서 응답을 생성함. ✅ 하지만 HTML 응답을 직접 만들어야 해서 코드가 길어짐. ✅ 데이터베이스 연결, 보안 등 추가 기능을 직접 구현해야 함. Servlet 예제 (Java 코드로 HTML 만들기) @WebServlet(\"/hello\") public class HelloServlet extends HttpServlet { protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\"text/html\"); PrintWriter out = response.getWriter(); out.println(\"&lt;html&gt;&lt;body&gt;\"); out.println(\"&lt;h1&gt;Hello, Servlet!&lt;/h1&gt;\"); out.println(\"&lt;/body&gt;&lt;/html&gt;\"); } } 문제점: HTML을 직접 만들고 응답을 구성해야 해서 코드가 길고 불편함 데이터베이스 연결이나 보안 기능을 추가하려면 개발자가 직접 구현해야 함. Spring: 웹 개발을 쉽게 만들어주는 프레임워크 Spring은 Servlet을 더 쉽게 사용할 수 있도록 만든 프레임워크 기본적인 요청 처리는 Servlet과 비슷하지만, Spring을 사용하면 자동화된 기능이 많아서 개발이 편리. Spring의 특징 ✅ 요청을 쉽게 처리할 수 있도록 @Controller와 @RestController 제공. ✅ HTML을 직접 만들지 않고, JSON이나 템플릿을 사용해서 응답을 쉽게 생성할 수 있음. ✅ 데이터베이스 연결, 보안 기능, API 호출 등을 자동으로 지원함. Spring 예제 (더 간단한 코드) @RestController public class HelloController { @GetMapping(\"/hello\") public String sayHello() { return \"Hello, Spring!\"; } } ``` 🚀 **Spring을 사용하면 Servlet보다 훨씬 간결하고 직관적이다.** Servlet vs Spring 비교 정리 항목 Servlet Spring 요청 처리 방식 직접 요청을 받고 응답을 작성 @Controller와 @RestController로 간단하게 처리 코드 복잡도 HTML을 직접 만들어야 해서 복잡 JSON이나 템플릿 사용 가능 (코드가 간결) 데이터베이스 연결 직접 구현해야 함 JPA, MyBatis 등의 지원 보안 및 인증 직접 구현해야 함 Spring Security 제공 개발 속도 설정이 많고 코드가 길다 자동 설정 덕분에 개발이 빠름 🚀 결론: Spring이 Servlet보다 훨씬 편리하다! Servlet은 기본적인 웹 요청 처리를 할 수 있지만, 직접 HTML을 만들고 보안, 데이터베이스 연결 등을 다 처리해야 함. Spring은 이런 것들을 자동화해주기 때문에 개발이 훨씬 쉬워지고, 유지보수도 편하다.",
    "tags": "spring",
    "url": "/spring/2025-03-17-servlet-vs-spring/"
  },{
    "title": "[Etc] 🤖 Layered Architecture &amp; MVC pattern",
    "text": "레이어드 아키텍쳐(Layered Architecture)란? MVC란? 레이어드 아키텍쳐와 MVC를 함께 사용 레이어드 아키텍쳐(Layered Architecture)란? 여러 수평 레이어가 수직적으로 쌓인 구조 (상위 레이어에서 하위 레이어로 단방향 의존성) 각 계층이 명확한 역할을 가지며, 하위 계층만 접근할 수 있도록 설계하여 유지보수성과 확장성을 높이는 것이 목적 Presentation Layer (프레젠테이션 계층) : 1층로비, 방문객 맞이하고 안내 예시: Spring Boot의 Controller 사용자와 직접 상호작용하는 계층 (예: 웹 UI, API 컨트롤러) 사용자의 입력을 받아 비즈니스 로직을 호출하고, 응답을 반환 Business Logic Layer (비즈니스 로직 계층) : 실제 회사 업무 설계 및 규칙 수립 예시: Spring Boot의 Service 핵심 비즈니스 로직을 처리하는 계층 도메인 규칙을 적용하여 데이터 검증 및 가공 수행 Data Access Layer (데이터 접근 계층) : 비즈니스 레이어의 명령 실행 예시: Spring Boot의 Repository 데이터베이스와 직접 상호작용하는 계층 DAO(Repository)를 통해 데이터를 저장하고 조회하는 역할 Database Layer (데이터베이스 계층) : 필요한 정보 저장 및 검색 실제 데이터를 저장하는 물리적 데이터베이스 (MySQL, PostgreSQL 등) 데이터 흐름 요청 → 컨트롤러 → 서비스 → 레포지토리 사용 이유 모듈화: 각 레이어가 독립적이라 변경 사항이 영향을 최소화 유지보수성: 비즈니스 로직(Service)과 DB 접근(Repository)을 분리 테스트 용이: 단위 테스트 작성이 쉬움 (ex: Service 레이어만 Mock 테스트 가능) 레이어 간 관계 [클라이언트] ↓ [Presentation Layer] → Controller ↓ [Business Logic Layer] → Service ↓ [Data Access Layer] → Repository (DAO) ↓ [Database Layer] → DB (MySQL, PostgreSQL) 상위 계층(Presentation)은 하위 계층(Business Logic)만 호출할 수 있음. 데이터베이스 관련 로직이 비즈니스 로직과 분리되어 유지보수가 쉬움. MVC란? Model-View-Controller Model : 요리사가 실제 음식을 준비하고 만드는 작업 View : 음식의 플레이팅 Controller : 고객의 주문을 받고, 요리사에게 전달하여 완성된 요리를 테이블에 서빙 (백엔드) 3개의 요소가 유기적으로 협력 사용자 인터페이스와 비즈니스 로직 분리 데이터 흐름 요청 → 컨트롤러 → 모델 → 뷰 사용 이유 역할 분리: View, Model, Controller가 독립적으로 동작하여 유지보수 용이 유연한 확장: UI 변경(View)이나 비즈니스 로직(Model)을 따로 수정 가능 재사용성 증가: 같은 Model을 여러 View에서 사용 가능 레이어드 아키텍쳐와 MVC를 함께 사용 둘을 함께 사용하면 유지보수성과 확장성이 좋아진다. Controller는 최대한 가볍게 (Thin Controller, Fat Service) 비즈니스 로직은 Service Layer에서 처리 (SRP 원칙 준수) 둘을 함께 사용했을 때 관계 흐름 (요청 → 응답) 사용자 (Client) 가 요청을 보냄 Controller (입력 처리, 요청 매핑) Service (비즈니스 로직 처리) Repository (데이터베이스 접근) Service → Controller 로 응답 반환 Controller → View (또는 JSON) MVC는 역할을 분리하고, 레이어드 아키텍처는 각 계층을 더 체계적으로 조직화하여 유지보수성과 확장성을 높인다",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-03-17-layered-architecture/"
  },{
    "title": "[TIL] JSP에서 정적 리소스 서빙",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #27 📅 작성일: 2025-03-13 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 JSP에서 정적 리소스 서빙할때 알아야 할 것이 정확히 무엇이 있는지 알아보았다. 📄 JSP (Java Server Pages) HTML + Java 코드 혼합으로 동적 웹 페이지를 생성하는 기술. 백엔드에서 view(화면) 역할을 할 때 사용됨. 최근에는 Thymeleaf 같은 템플릿 엔진으로 대체되기도 하지만, JSP는 여전히 많은 레거시 시스템에서 사용 중. 🖼️ 정적 리소스 서빙 (Serving Static Resources) ✅ 정적 리소스란? 서버에서 별도 처리 없이 그대로 내려주는 파일들 👉 이미지, CSS, JavaScript, 폰트 등 ✅ JSP에서 정적 리소스를 서빙할 때 알아야 할 점 위치 일반적으로 /webapp 또는 /resources 하위에 위치 예: /webapp └── /css └── /js └── /images 접근 경로 JSP에서 링크를 걸 때는 절대 경로 or 상대 경로를 정확히 써야 함. 예: &lt;link rel=\"stylesheet\" href=\"${pageContext.request.contextPath}/css/style.css\" /&gt; &lt;script src=\"${pageContext.request.contextPath}/js/script.js\"&gt;&lt;/script&gt; web.xml 설정 (보통 기본적으로 설정되어 있지만 알아두면 좋음) &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;/resources/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 서블릿이 아닌 파일은 직접 서빙됨 JSP 같은 동적 리소스는 Servlet에서 처리 정적 리소스는 ServletContainer(Tomcat 등)가 자동으로 처리 ⚠️ 주의할 점 정적 리소스를 JSP 내부에 두지 말기 예: WEB-INF/views 안에 넣으면 브라우저에서 접근 못 함 (보안상 보호된 경로임) 브라우저 캐싱 문제 있을 수 있음 → 버전 넘버링 (style.css?v=1.0) 같은 기법 사용 📌 요약 항목 설명 정적 리소스 서버에서 처리 없이 그대로 전달하는 파일 (JS, CSS, 이미지 등) 저장 위치 보통 webapp 폴더 내 /css, /js, /images 등 폴더 접근 방법 ${pageContext.request.contextPath}/css/style.css 형식으로 경로 지정 서빙 주체 Tomcat 같은 WAS(Web Application Server)가 자동 서빙 주의사항 WEB-INF 폴더 안에 넣으면 안 보임, 경로 설정 정확히 해야 함",
    "tags": "TIL JavaScript til",
    "url": "/til/2025-03-13-til/"
  },{
    "title": "[TIL] Redirect vs Forward",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #26 📅 작성일: 2025-03-12 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 리다이렉트 vs 포워드 비슷한 개념인 것 같은데 어떤 부분이 정확히 다른지 알아보았다. 🔁 리다이렉트 (Redirect) 개념: 서버가 클라이언트에게 다른 URL로 이동하라고 응답함. 작동 방식: 클라이언트(브라우저)가 새로운 요청을 다시 보냄 (새 HTTP 요청). 주소창: 변경됨 (새로운 URL로 바뀜). 용도 예시: 로그인 후 메인 페이지로 이동, 외부 사이트로 이동 등. ✔ 특징 요약: 클라이언트가 다시 요청함 (2번 요청 발생). URL이 변경됨. 세션이나 flash 같은 일시적 데이터 사용 시 주의. 브라우저 히스토리에 기록됨. 🔄 포워드 (Forward) 개념: 서버 내부에서 다른 리소스로 요청을 전달함. 작동 방식: 클라이언트는 한 번의 요청만 보내고, 서버 내부에서 처리 리소스를 바꿔줌. 주소창: 변경되지 않음. 용도 예시: form 제출 후 처리 결과를 같은 도메인의 JSP나 컨트롤러로 넘길 때. ✔ 특징 요약: 서버가 내부적으로 리소스 전달. URL이 변경되지 않음. 데이터 유지 가능 (request 범위). 브라우저 히스토리에 기록되지 않음. ✅ 요약 표 구분 Redirect Forward 요청 횟수 2번 (클라이언트 → 서버 → 다시 클라이언트) 1번 (서버 내부 처리) URL 변경 O X 데이터 유지 어렵다 (세션 등 필요) request에 저장 가능 사용 목적 다른 페이지로 완전히 이동 시 같은 서버 내 로직 처리 시",
    "tags": "TIL til",
    "url": "/til/2025-03-12-til/"
  },{
    "title": "[TIL] Java record, HttpClient / HttpRequest / HttpRes…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #25 📅 작성일: 2025-03-09 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 Java record -&gt; 블로그 정리 HttpClient, HttpRequest, HttpResponse ✅ Java에서 HttpClient, HttpRequest, HttpResponse 활용법과 차이점 Java에서는 HTTP 요청을 보내고 응답을 받기 위해 java.net.http 패키지의 HttpClient, HttpRequest, HttpResponse 를 사용합니다. (Java 11 이상에서 사용 가능) 1️⃣ HttpClient, HttpRequest, HttpResponse 개념 및 차이점 클래스 역할 특징 HttpClient HTTP 요청을 보내는 역할 클라이언트 설정, 요청 실행 (send()) HttpRequest HTTP 요청을 정의하는 객체 URL, HTTP 메서드 (GET, POST 등), 헤더 설정 HttpResponse HTTP 응답을 담는 객체 서버의 응답 코드, 응답 본문, 헤더 저장 2️⃣ 기본 사용법 🔹 HttpClient를 사용한 GET 요청 예제 import java.net.URI; import java.net.http.HttpClient; import java.net.http.HttpRequest; import java.net.http.HttpResponse; public class HttpClientExample { public static void main(String[] args) throws Exception { // 1️⃣ HttpClient 생성 HttpClient client = HttpClient.newHttpClient(); // 2️⃣ HttpRequest 생성 (GET 요청) HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(\"https://jsonplaceholder.typicode.com/posts/1\")) .GET() .build(); // 3️⃣ HttpResponse 받기 (동기 방식) HttpResponse&lt;String&gt; response = client.send(request, HttpResponse.BodyHandlers.ofString()); // 4️⃣ 응답 출력 System.out.println(\"응답 코드: \" + response.statusCode()); System.out.println(\"응답 본문: \" + response.body()); } } 📌 실행 결과 (예시) 응답 코드: 200 응답 본문: { \"userId\": 1, \"id\": 1, \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\", \"body\": \"quia et suscipit...\" } 3️⃣ HttpClient, HttpRequest, HttpResponse의 주요 기능 ✅ 1. HttpClient: HTTP 요청을 보내는 역할 HttpClient.newHttpClient() → 기본 HttpClient 생성 HttpClient.newBuilder() → 사용자 정의 설정 가능 (타임아웃, 인증 등) send(request, BodyHandlers.ofString()) → 동기 요청 sendAsync(request, BodyHandlers.ofString()) → 비동기 요청 ✅ 2. HttpRequest: HTTP 요청 정의 .uri(URI.create(\"URL\")) → 요청할 URL 지정 .GET() / .POST() / .PUT() / .DELETE() → HTTP 메서드 설정 .header(\"Header-Name\", \"value\") → 헤더 추가 .timeout(Duration.ofSeconds(10)) → 요청 제한 시간 설정 🚀 정리 간단한 요청: send() 비동기 요청: sendAsync() JSON 데이터 전송: POST(BodyPublishers.ofString(json)) 응답 핸들링: response.statusCode(), response.body() 🐬 깃블로그 정리 Java Record",
    "tags": "TIL Java til",
    "url": "/til/2025-03-09-til/"
  },{
    "title": "[JAVA] record",
    "text": "record란? record의 특징 기존 클래스 vs record 비교 record 내부 동작 record 주요 기능 record 사용 방법 정리 ✅ record란? (Java 14+) record는 Java 14부터 도입된 새로운 클래스 유형으로, 불변(immutable)한 데이터 객체를 간결하게 표현할 수 있도록 설계되었습니다. 👉 기존의 DTO(Data Transfer Object), VO(Value Object) 등을 만들 때 코드를 대폭 줄여줍니다. 1️⃣ record의 특징 자동으로 생성자, getter, toString(), equals(), hashCode() 제공 불변 객체 (Immutable) Java의 일반적인 클래스처럼 사용 가능 Compact Constructor(압축된 생성자) 지원 상속 불가능 (final 클래스처럼 동작) 2️⃣ 기존 클래스 vs record 비교 🔹 기존 방식: Java 클래스로 DTO 만들기 class Person { private final String name; private final int age; public Person(String name, int age) { this.name = name; this.age = age; } public String getName() { return name; } public int getAge() { return age; } @Override public String toString() { return \"Person{name='\" + name + \"', age=\" + age + \"}\"; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Person person = (Person) o; return age == person.age &amp;&amp; Objects.equals(name, person.name); } @Override public int hashCode() { return Objects.hash(name, age); } } getter, toString(), equals(), hashCode()를 직접 구현해야 해서 코드가 길어짐. 🔹 record를 사용한 간단한 구현 record Person(String name, int age) {} 위처럼 한 줄만 작성하면 동일한 기능을 제공함! 자동으로 getter, toString(), equals(), hashCode()가 생성됨. 3️⃣ record의 내부 동작 위의 record Person(String name, int age)는 자동으로 다음과 같이 동작합니다: public final class Person { private final String name; private final int age; public Person(String name, int age) { // 생성자 자동 생성 this.name = name; this.age = age; } public String name() { return name; } // getter 자동 생성 public int age() { return age; } @Override public boolean equals(Object o) { /* 자동 생성 */ } @Override public int hashCode() { /* 자동 생성 */ } @Override public String toString() { return \"Person[name=\" + name + \", age=\" + age + \"]\"; } } 💡 이름이 getName()이 아니라 name()인 점이 특징! 4️⃣ record의 주요 기능 ✅ 1. 기본 사용 record Person(String name, int age) {} public class Main { public static void main(String[] args) { Person p = new Person(\"Alice\", 25); System.out.println(p.name()); // Alice (getter) System.out.println(p.age()); // 25 (getter) System.out.println(p); // Person[name=Alice, age=25] } } name()과 age()가 getter 역할을 함 (getName()이 아님) toString()이 자동 생성됨 → Person[name=Alice, age=25] ✅ 2. Compact Constructor (압축된 생성자) 기본적으로 record는 모든 필드가 자동 초기화되지만, 추가 검증 로직을 넣을 수도 있음. record Person(String name, int age) { public Person { if (age &lt; 0) { throw new IllegalArgumentException(\"나이는 0 이상이어야 합니다.\"); } } } 위처럼 생성자에서 유효성 검사를 추가 가능. ✅ 3. 메서드 추가 가능 record도 일반적인 클래스처럼 메서드를 추가할 수 있음. record Circle(double radius) { public double area() { return Math.PI * radius * radius; } } public class Main { public static void main(String[] args) { Circle c = new Circle(5); System.out.println(\"원의 넓이: \" + c.area()); // 원의 넓이: 78.5398... } } record는 단순히 데이터를 저장하는 역할이지만, 관련 메서드를 추가하는 것도 가능. ✅ 4. 상속 불가능 (final 클래스처럼 동작) record는 자동으로 final로 선언되므로 상속이 불가능함. record Parent(String name) {} // 오류: record는 상속할 수 없음 class Child extends Parent {} // ❌ 컴파일 오류 왜 Java는 record를 final로 만든걸까? 불변성(Immutable)을 유지하려고 record는 모든 필드가 final이고, 생성 이후 변경이 불가능함 누가 상속해서 setter를 추가하거나, 내부 상태를 바꾸면 record의 의도가 무너짐! 자동 생성된 메서드의 안정성 보장 equals(), hashCode(), toString()등을 자동 생성해주는데, 누가 상속해서 equals()만 살짝 바꾸면 일관성이 깨짐 -&gt; 버그의 근원 Java에서 상속은 “행위” 확장에 적합 하지만 record는 “데이터”만 표현하고 싶을때 쓰는 구조 즉, 철학이 다르다. record는 POJO(Plain Old Java Object)보다 더 “데이터 그 자체”에 집중 🔴 하지만 인터페이스는 구현 가능 interface Printable { void print(); } public record User(String name, int age) implements Printable { public void print() { System.out.println(\"User: \" + name + \", \" + age); } } 행위를 정의하는 인터페이스는 데이터 구조와 상관없기 때문에 구현할 수 있다! 5️⃣ record를 언제 사용할까? ✅ 불변 객체(Immutable Object)가 필요할 때 ✅ DTO, VO (Data Transfer Object, Value Object)를 만들 때 ✅ 간단한 데이터 저장용 클래스가 필요할 때 ✅ 불필요한 getter, toString(), equals() 코드 작성을 줄이고 싶을 때 ❌ 상속을 해야 하는 경우에는 record를 사용할 수 없음 ❌ 데이터 변경이 필요한 경우 (Mutable Object)는 record보다 일반 클래스를 사용 6️⃣ 정리 특징 일반 클래스 record 코드 길이 길다 (필드, 생성자, getter, toString(), equals(), hashCode()) 짧다 (한 줄로 가능) 불변성(Immutable) X (final 필드 필요) ✅ 기본적으로 불변 자동 생성 X (수동으로 작성해야 함) ✅ 생성자, getter, toString() 자동 생성 상속 가능 여부 ✅ 가능 ❌ 불가능 (final 클래스처럼 동작) 데이터 변경 가능 (setter 추가 가능) ❌ 변경 불가능 🚀 결론: record를 사용하면 불변 객체를 쉽게 만들 수 있으며, DTO나 VO 같은 데이터 클래스를 훨씬 간결하게 표현할 수 있다! 🚀",
    "tags": "java",
    "url": "/java/2025-03-09-record/"
  },{
    "title": "[JAVA] 동시성 처리 (Concurrency)",
    "text": "JAVA에서 동시성 스레드 (Thread) 비동기 처리 (Aysnc) 분산 처리 (Distribute) 핵심 키워드 및 정리 JAVA에서 동시성 여러 작업을 동시에 겹쳐서 처리하는 것 한 번에 여러 일을 수행하며 일의 효율성을 높임 크게 3가지 관점에서 접근 가능하다. 스레드 (Thread) 비동기 (Async) 분산 (Distributed) 스레드 (Thread) 스레드는 프로세스 내에서 실제 작업을 수행하는 작업 단위 한 개의 프로그램(프로세스)은 여러 개의 스레드를 가질 수 있음 멀티 스레드 (Multi-thread) 하나의 프로세스에서 여러 스레드를 동시에 실행하는 방식 자바에서는 주로 JVM(Java Virtual Machine)이 여러 스레드를 관리해줌 ex) 웹 서버(Servlet, Spring)에서는 사용자 요청마다 별도의 스레드를 생성해서 동시에 많은 요청을 처리할 수 있게 함 🔥 중요한 이유 효율성 향상 CPU 자원을 최대한 활용할 수 있음 응답성 향상 동시에 여러 요청을 처리할 수 있음 하지만 최근 자바 프레임워크(Spring)는 스레드를 자동으로 관리해주기 때문에 개발자가 직접 스레드를 관리할 일이 많지 않음 JVM과 프레임워크가 이미 효율적으로 관리해줌 비동기 처리 (Async) 비동기란 “요청을 보낸 뒤 결과를 기다리지 않고 다음 작업을 진행”하는 방식 동기 (Synchronous) 하나의 요청이 끝날 때까지 기다림 비동기 (Asynchronous) 요청이 처리되는 동안 다른 작업 수행 자바에서 비동기 처리를 지원하는 방법 CompletableFuture : 자바 비동기 처리 클래스 자바스크립트의 async/await와 비슷한 방식 🔥 중요한 이유 빠른 응답성 요청 처리 중에도 사용자가 대기하지 않고, 시스템의 다른 작업 수행 가능 높은 확장성 비동기 처리를 하면 서버가 많은 요청을 효율적으로 관리 가능 분산 처리 (Distributed) 분산처리는 “하나의 서버가 아닌, 여러 대의 서버가 나누어서 작업을 처리하는 방식” 서버 하나만 운영하는 것부다 작은 여러 서버(클러스터)를 운영하면 비용이 줄어듬 대규모 서비스나 성장한 서비스에서 자주 사용됨 분산 환경에서 자주 사용되는 기술 Redis 메모리 기반 데이터 저장소로, 분산락(Distributed Lock)울 구현할 때 사용 예를 들어, 여러 서버가 하나의 데이터를 동시에 수정하지 못하게 관리하는 방식 Kafka 메시지 큐(Message Queue)로, 서버간 메시지를 주고받고, 작업을 순차적으로 처리할 때 사용됨 클러스터(Cluster) 여러 대의 서버가 협력하여 요청을 나누어 처리 (MSA와 비슷한 개념) 🔥 중요한 이유 비용 효율성 큰 서버 하나보다 여러 작은 서버가 경제적 안정성 및 확장성 한 서버가 문제가 생기더라도 서비스는 계속 운영됨 핵심 키워드 및 정리 스레스 (Thread) 멀티 스레드 -&gt; JVM, Servlet, Spring 스레드는 직원이다. 회사(JVM, Servlet, Spring)가 직원(스레드)을 잘 관리하면, 일(요청 처리)이 효율적이다. 비동기 (Async) CompletableFuture, async/await 비동기는 배달앱이다. 주문을 넣고 기다리지 않고, 다음 일을 진행한다. 분산처리 (Distributed) Redis, Kafka, 클러스터 분산처리는 프랜차이즈이다. 큰 가게 하나보다 작은 여러 가게가 효율적이고 비용도 절감된다.",
    "tags": "java",
    "url": "/java/2025-03-09-concurrency/"
  },{
    "title": "[TIL] 정적・동적 프로퍼티, HTML, JavaScript, Java에서 프로퍼티 차이",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #24 📅 작성일: 2025-03-08 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 1. 정적 프로퍼티(Static Property) vs. 동적 프로퍼티(Dynamic Property) 1. 정적 프로퍼티 (Static Property) 클래스 단위로 관리되는 속성으로, 특정 인스턴스에 속하지 않고 클래스 자체에 속함. 모든 인스턴스가 공유함. static 키워드를 사용하여 선언. 2. 동적 프로퍼티 (Instance Property) 각 인스턴스에 개별적으로 존재하는 속성. 새로운 인스턴스가 생성될 때마다 독립적으로 할당됨. ✅ 코드 예제 (Java) class Car { static int totalCars = 0; // 정적 프로퍼티 (클래스 변수) String model; // 동적 프로퍼티 (인스턴스 변수) public Car(String model) { this.model = model; totalCars++; // 모든 객체가 공유하는 변수 증가 } // 정적 메서드 (클래스 변수 사용 가능) static void showTotalCars() { System.out.println(\"총 자동차 수: \" + totalCars); } } public class Main { public static void main(String[] args) { Car car1 = new Car(\"Tesla\"); Car car2 = new Car(\"BMW\"); System.out.println(\"Car 1 모델: \" + car1.model); // 개별 인스턴스 값 System.out.println(\"Car 2 모델: \" + car2.model); Car.showTotalCars(); // 정적 변수는 클래스명으로 접근 } } 📝 출력 결과 Car 1 모델: Tesla Car 2 모델: BMW 총 자동차 수: 2 🔍 요약 구분 정적 프로퍼티 (Static) 동적 프로퍼티 (Instance) 선언 방법 static 키워드 사용 일반 변수 선언 속하는 대상 클래스 자체 개별 인스턴스 공유 여부 모든 인스턴스가 공유 각 인스턴스마다 별도 존재 접근 방법 클래스명.변수명 객체명.변수명 정적 프로퍼티는 클래스 전체에서 공유해야 하는 데이터(예: 총 객체 수, 공용 설정값) 관리에 사용하고, 동적 프로퍼티는 개별 객체의 상태를 저장할 때 사용하면 된다! 🚀 2. HTML, JavaScript, Java에서 “프로퍼티(Property)”의 차이 정리 구분 HTML JavaScript Java 프로퍼티 의미 HTML 요소의 속성(Attribute)과 연결된 내부 상태 객체(Object)의 속성(Key-Value 쌍) 클래스의 멤버 변수(필드) 정적/동적 여부 정적 (HTML 태그에서 선언됨) 동적 (런타임 중 추가/삭제 가능) 정적 (컴파일 시 고정, 객체 생성 후 변경 불가) 접근 방식 element.property (DOM API 사용) object.property 또는 object[\"property\"] getter/setter 메서드 사용 예제 &lt;input type=\"text\" value=\"Hello\"&gt; → document.querySelector(\"input\").value { name: \"Alice\", age: 25 } → person.name private String name; → getName() / setName() 변경 가능 여부 변경 가능 (input.value = \"New Value\") 변경 가능 (person.age = 30) 직접 변경 불가 (private + getter/setter 필요) 캡슐화 없음 (HTML 요소에 직접 접근) 없음 (자유롭게 접근 가능) 있음 (private로 보호, 메서드를 통해 접근) 동작 방식 DOM 요소의 속성과 연결 프로토타입 기반 객체 모델 사용 클래스 기반 객체 모델 사용 📌 각 프로퍼티 개념 예제 1️⃣ HTML 프로퍼티 &lt;input id=\"myInput\" type=\"text\" value=\"Hello\" /&gt; &lt;script&gt; let input = document.getElementById(\"myInput\"); console.log(input.value); // \"Hello\" input.value = \"New Value\"; // 프로퍼티 변경 가능 &lt;/script&gt; 2️⃣ JavaScript 프로퍼티 const person = { name: \"Alice\", age: 25, }; console.log(person.name); // \"Alice\" person.age = 30; // 프로퍼티 변경 가능 delete person.age; // 동적으로 삭제 가능 3️⃣ Java 프로퍼티 class Person { private String name; // 프로퍼티 (멤버 변수) public String getName() { // Getter return name; } public void setName(String name) { // Setter this.name = name; } } public class Main { public static void main(String[] args) { Person person = new Person(); person.setName(\"Alice\"); System.out.println(person.getName()); // \"Alice\" } } 🎯 결론 HTML 프로퍼티 → DOM 요소의 속성과 연결됨 (element.property 형태) JavaScript 프로퍼티 → 객체의 속성(Key-Value)로 동적 추가/삭제 가능 Java 프로퍼티 → 클래스의 멤버 변수이며, getter/setter를 통해 접근 (캡슐화 적용됨) 각 언어에서 “프로퍼티(Property)” 개념이 다르게 적용되지만, 공통적으로 객체나 요소의 속성을 나타내는 개념이라는 점은 비슷함! 🚀 🍎 오늘의 문제 상황 프로퍼티에 대해 여러 언어에서 듣다보니 정확히 어떤 개념인지 혼동되어 너무 헷갈렸다. 비교하며 찾아보니 프로퍼티에 대해 더욱 이해가 되는 것 같다. 🦄 느낀 점 여러 언어를 배우다보니 각 언어별로 개념을 정확히 알고 있어야겠다.",
    "tags": "TIL Java JavaScript HTML til",
    "url": "/til/2025-03-08-til/"
  },{
    "title": "[TIL] immutable/final/const, Java Concurrency",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #23 📅 작성일: 2025-03-07 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 immutable, final, constant의 차이점 자바에서 동시성 처리 관련 내용 스레드 (Thread) 비동기 처리 (Async) 분산 처리 (Distribute) 🍎 오늘의 문제 상황 위의 내용들을 아는 내용이라고 생각했는데, 막상 말로 설명하려고 하니 간단하게 설명하는게 쉬운 일이 아니다. 🦄 느낀 점 이렇게 보일때 다시 한번 생각해보고, 집고 넘어가는 걸 습관화 해야할 것 같다. 🐬 깃블로그 정리 immutable, final, constant의 차이점 Java 동시성 처리",
    "tags": "TIL Java til",
    "url": "/til/2025-03-07-til/"
  },{
    "title": "[TIL] 레이어드 아키텍쳐, MVC, 보일러 플레이트",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #22 📅 작성일: 2025-03-06 🔄 최종 수정: 2025년 03월 27일 🍀 새롭게 배운 것 레이어드 아키텍쳐 VS MVC 보일러 플레이트 🍎 오늘의 문제 상황 프로젝트의 폴더별 역할이 헷갈려서 이게 무슨 패턴인지 확실히 정립되지 않았다. 레이어드 아키텍쳐와 MVC를 공부해 각 폴더 벌 역활을 정확히 한 후 이해하기 시작했다. 🦄 느낀 점 이해가 안될땐 tree src를 사용해 정확히 패턴과 역할을 알고 코드를 보는 것이 좋을 것 같다. 싱글톤을 사용해 보일러 플레이트를 사용하는 연습을 해봐야 겠다 🐬 깃블로그 정리 레이어드 아키텍쳐 VS MVC 보일러 플레이트",
    "tags": "TIL til",
    "url": "/til/2025-03-06-til/"
  },{
    "title": "[Etc] 🎞️ Boilerplate와 Lombok",
    "text": "보일러플레이트(Boilerplate)란? 보일러플레이트의 특징 예제 코드 Lombok 롬복의 장점 Spring에서의 보일러플레이트 해결 구조 보일러플레이트에 대해 알아보고, spring에서 보일러플레이트를 줄여주는 도구 중 하나인 롬복에 대해 알아보자. 보일러플레이트(Boilerplate)란? 소프트웨어 개발에서 반복적으로 사용되는 사용되는 기본 코드 템플릿 🔥 즉, “매번 새로 작성해야하는 기본 코드세트”를 보일러플레이트라고 함 의미 원래는 인쇄 산업에서 반복적으로 사용되는 금속판을 의미 이후 소프트웨어 개발에서도 “반복적으로 작성해야하는 코드 덩어리”를 의미하게 되었다. 보일러플레이트의 특징 반복적인 코드 프로젝트를 시작할 때 매번 작성해야하는 코드들이 포함됨 예를 들어, 웹 애플리케이션을 만들 때 기본적인 프로젝트 구조, 설정 파일, 인증 로직 등이 해당 반복적이니 안좋다고 여겨질 수 있지만, 완전히 없애는게 목적이 아니라 최소화하고 효율화하는 것이 핵심! 템플릿화 코드 재사용성을 높이고, 개발 시간을 줄여줌 예를 들어, React, Express, Spring Boot같은 프레임워크에서는 보일러플레이트 코드가 포함된 템플릿이 제공됨 프레임워크 및 라이브러리에서 자주 사용됨 React : create-react-app이 기본적인 프로젝트 구조와 설정을 자동으로 생성 Express : express-generator를 사용하면 기본적인 Express 프로젝트 생성 Spring Boot : Spring Initializr를 사용사면 기본적인 설정이 포함된 프로젝트 생성 예제 코드 Spring Boot 보일러플레이트 import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } Lombok 롬복(Lombok)은 보일러플레이트 코드를 줄여주는 도구 중 하나 하지만 Spring 전체가 보일러플레이트 문제를 해결하는 구조고, 롬복은 그 중 일부분 Java에서 반복적으로 작성하는 코드들 (getter, setter, constructor 등)을 어노테이션으로 자동 생성해주는 라이브러리 주요 어노테이션 정리 어노테이션 설명 @Getter 모든 필드에 getter 생성 @Setter 모든 필드에 setter 생성 @ToString toString() 자동 생성 @EqualsAndHashCode equals()와 hashCode() 자동 생성 @NoArgsConstructor 기본 생성자 생성 @AllArgsConstructor 모든 필드를 받는 생성자 생성 @RequiredArgsConstructor final 필드만 받는 생성자 생성 @Data Getter + Setter + ToString + EqualsAndHashCode + @RequiredArgsConstructor 포함된 종합 패키지 @Builder 빌더 패턴 자동 생성 (.builder()로 객체 생성 가능) 예시: ✅ 일반적인 Java 코드 (보일러플레이트 많음) public class User { private String name; private int age; public User() {} public String getName() { return name; } public void setName(String name) { this.name = name; } // ... 반복 } ✅ 롬복 사용 import lombok.Data; @Data public class User { private String name; private int age; } @Data 하나로 getter/setter/toString/equals/hashCode/constructor 전부 생성됨 🎉 💡 롬복의 장점 ✂️ 코드가 짧아져서 가독성이 좋아짐 🚫 getter/setter 작성 실수 방지 🧪 테스트 코드도 간편해짐 ⏱ 코드 작성 속도 급상승 🔄 리팩토링할 때 수정할 코드 줄어듦 Spring에서의 보일러플레이트 해결 구조 도구 / 개념 역할 Spring Boot 설정파일, 서버 실행 등 기본 구조 자동화 Spring MVC 구조 컨트롤러/서비스/리포지토리 구조 정형화해서 반복 패턴 통일 Spring Initializr 프로젝트 기본 뼈대 자동 생성 롬복(Lombok) DTO나 엔티티에서 반복되는 getter/setter 등 제거 의존성 주입 (DI) 객체 생성과 의존성 연결을 Spring이 대신 처리",
    "tags": "spring",
    "url": "/spring/2025-03-06-boiler-plate/"
  },{
    "title": "[Etc] immutable, final, constant",
    "text": "Immutable final const Immutable (불변) 생성 후 객체 자체의 상태를 변경할 수 없음 Java의 키워드는 아님, 다양한 언어에서 사용되는 객체의 속성 개념 객체와 관련됨 특징 모든 필드가 final이고 private setter 메서드가 없음 모든 가변 참조 필드가 방어적 복사를 통해 보호됨 중요한 점 불변 객체는 멀티 스레드 환경에서 안전하게 사용 가능 내부 상태를 변경하는 메서드를 제공하지 않아야 함. 예 : String, Integer, BigDecimal String 클래스는 자바에서 대표적인 불변 객체 String객체를 한 번 생성하면 내부 값이 변경되지 않음. 새로운 값을 할당하려면 새로운 객체가 만들어짐. String s1 = \"Hello\"; String s2 = s1.concat(\" World\"); System.out.println(s1); // 여전히 \"Hello\" Final (최종, 변경 불가) 한 번 할당되면 값을 변경할 수 없는 변수 또는 참조 Java의 키워드 특징 변수에 사용 : 초기화 후 재할당 불가 메서드에 사용 : 오버라이딩 불가 클래스에 사용 : 상속 불가 중요한 점 final은 참조의 변경을 막지만, 참조가 가리키는 객체의 내용 변경은 막지 않음 실무에서 활용 메서드 파라미터 메서드 내에서 파라미터 값이 변경되지 않도록 보장 public void processUser(final User user) { ... } 람다 표현식 람다에서 외부 변수를 사용할 때는 반드시 final 또는 effectively final이어야 함 final String prefix = \"User-\"; userList.stream() .map(user -&gt; prefix + user.getName()) .forEach(System.out::println); 스레드 안정성 멀티스레드 환경에서 불변성 보장에 도움 Const (상수) 프로그램 전체에서 변경되지 않는 고정 값 Java의 키워드 특징 일반적으로 static final로 선언 클래스 로딩 시점에 초기화 관례적으로 대문자와 언더스코어 사용 (UPPER_SNAKE_CASE) 예 public static final int MAX_USERS = 100; static 상수(const)와 자주 함께 사용되는 변수 클래스 수준에서 사용되며, 객체가 아닌 클래스에 종속됨 클래스 로딩 시 한 번만 초기화되며 모든 객체가 공유",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-03-06-immutable/"
  },{
    "title": "[TIL] 함수형 인터페이스 FunctionalInterface, Logger",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #21 📅 작성일: 2025-03-05 🔄 최종 수정: 2025년 04월 08일 🍀 새롭게 배운 것 함수형 인터페이스 @FunctionalInterface @FunctionalInterface는 Java에서 함수형 인터페이스를 명시적으로 선언할 때 사용하는 어노테이션입니다. 1. 함수형 인터페이스란? 추상 메서드를 단 하나만 가지는 인터페이스입니다. 람다 표현식과 메서드 레퍼런스를 사용할 수 있게 해줍니다. @FunctionalInterface 어노테이션을 사용하면 컴파일러가 함수형 인터페이스 규칙을 강제합니다. 함수형 인터페이스인지 검증해줍니다. 만약 두 개 이상의 추상 메서드를 선언하면 컴파일 오류가 발생합니다. @FunctionalInterface interface InvalidInterface { void method1(); void method2(); // 오류 발생: 함수형 인터페이스는 추상 메서드가 하나만 있어야 함! } java: Unexpected @FunctionalInterface annotation 대표적인 함수형 인터페이스 예제 (Java 기본 제공) Runnable (메서드: void run()) Callable&lt;T&gt; (메서드: T call()) Supplier&lt;T&gt; (메서드: T get()) Consumer&lt;T&gt; (메서드: void accept(T t)) Function&lt;T, R&gt; (메서드: R apply(T t)) Predicate&lt;T&gt; (메서드: boolean test(T t)) Function&lt;String, Integer&gt; lengthFunction = str -&gt; str.length(); System.out.println(lengthFunction.apply(\"Hello\")); // 5 @FunctionalInterface를 꼭 써야 하나요? 아니요. 어노테이션 없이도 함수형 인터페이스는 작동합니다. 하지만 @FunctionalInterface를 사용하면 가독성이 좋아지고, 실수를 방지할 수 있습니다. 즉, “이 인터페이스는 함수형 인터페이스다”라고 명시적으로 선언하는 용도입니다. ✅ 사용하면 좋은 경우: 팀원에게 코드의 의도를 명확히 전달하고 싶을 때 실수로 여러 개의 추상 메서드를 선언하는 것을 방지하고 싶을 때 결론 @FunctionalInterface는 단 하나의 추상 메서드를 가지는 함수형 인터페이스를 선언할 때 사용하며, 컴파일러가 이를 검증해 주는 역할을 합니다. 람다와 함께 사용하면 코드를 더 간결하게 작성할 수 있습니다! 🚀 Logger가 System.out.println보다 좋은 점 Logger는 println보다 훨씬 강력하고 유용한 기능을 제공 Logger vs println 비교 구분 Logger System.out.println 출력 방식 로그 레벨별로 출력 가능 단순한 콘솔 출력 출력 조절 필요에 따라 로그 출력 On/Off 가능 항상 출력됨 로그 파일 저장 가능 (파일로 기록 가능) 직접 파일에 저장하려면 추가 코드 필요 출력 포맷 형식 지정 가능 (날짜, 로그 레벨, 클래스명 포함 가능) 단순 문자열 출력 병렬 처리 멀티스레드 환경에서 안전하게 사용 가능 동기화가 필요할 수 있음 성능 대량의 로그를 효율적으로 처리 (필요하지 않은 로그는 출력하지 않고, 비동기적으로 처리할 수도 있어 성능이 우수) 성능 최적화 없음 예외 처리 log.log(Level.SEVERE, \"Error\", exception) 처럼 예외 정보를 함께 로깅 가능 예외 출력은 e.printStackTrace()로 별도로 해야 함 언제 Logger를 써야 할까? 상황 Logger 사용 여부 간단한 테스트 출력 ❌ System.out.println 사용 디버깅 / 오류 분석 ✅ Logger 사용 운영 환경 로그 기록 ✅ Logger 필수 멀티스레드 프로그램 ✅ Logger 사용 로그 파일 저장 필요 ✅ Logger 사용",
    "tags": "TIL til",
    "url": "/til/2025-03-05-til/"
  },{
    "title": "[TIL] HashMap의 초기 크기 설정",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #20 📅 작성일: 2025-02-26 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 HashMap의 초기 크기 설정(new HashMap&lt;&gt;(N))이 성능 최적화에 중요한 영향을 미친다. 불필요한 리사이징을 방지하면 메모리 사용량과 실행 시간을 줄일 수 있다./ getOrDefault()를 사용하면 containsKey() + get()을 따로 호출할 필요가 없어 코드가 간결해진다. 🍎 오늘의 문제 상황 백준 “숫자 카드 2” 문제를 해결하는 과정에서, 첫 번째 개선 코드(2번째 코드)를 제출했더니 실행 시간은 늘어났지만 메모리는 줄어드는 현상이 발생했다. 원인 분석 2번째 코드에서는 HashMap&lt;Integer, Integer&gt; hashMap = new HashMap&lt;&gt;();을 사용하여 기본 크기(16)에서 시작했음. 데이터 개수 N이 클 경우, HashMap이 자동으로 리사이징(재할당)되면서 성능 저하 발생. 3번째 코드에서 new HashMap&lt;&gt;(N)을 사용하여 초기 크기를 설정함으로써, 불필요한 리사이징을 방지하고 성능을 최적화할 수 있었다. ✅ 해결 과정 HashMap&lt;Integer, Integer&gt; hashMap = new HashMap&lt;&gt;(N); N을 초기 크기로 설정하면 초기 배열 크기가 충분히 커서 리사이징이 발생하지 않음. 메모리 사용량은 줄어들고, 실행 속도는 향상됨. 🦄 느낀 점 데이터 개수가 클 때, HashMap의 초기 크기를 설정하는 것이 중요하다. 메모리 최적화뿐만 아니라 실행 시간도 개선될 수 있다. 단순한 코드 변경 하나가 큰 성능 차이를 만들 수 있으므로, 성능 튜닝을 할 때는 실행 시간과 메모리 사용량을 모두 확인하는 습관이 필요하다. 🐬 참고 자료 숫자 카드 2",
    "tags": "TIL til",
    "url": "/til/2025-02-26-til/"
  },{
    "title": "[JAVA] 🚀 ArrayList vs 배열(int[]) 성능 비교",
    "text": "ArrayList&lt;Integer&gt;는 언제 더 유리할까? int[] 배열이 더 유리한 경우 성능 비교 실험 (Java) 결론: 언제 ArrayList를 쓰고, 언제 배열(int[])을 써야 할까? 추가 : HashMap&lt;Integer, Integer&gt;와의 성능 비교 🚀 ArrayList vs 배열(int[]) 성능 비교   ArrayList&lt;Integer&gt; int[] 배열 저장 방식 내부적으로 동적 배열(Object[]) 사용 고정 크기의 int[] 배열 사용 메모리 사용량 Integer 객체를 사용하여 오버헤드가 큼 int 원시 타입 사용 (메모리 효율적) 속도 (읽기/쓰기) 일반적으로 int[]보다 느림 빠름 (메모리 직접 접근) 크기 변경 가능 여부 가능 (add(), remove() 등 제공) 불가능 (고정 크기) 사용 편의성 유동적인 크기 조절이 가능 크기 변경이 불가능하여 유연성이 떨어짐 📌 ArrayList&lt;Integer&gt;는 언제 더 유리할까? 크기가 가변적인 데이터를 다룰 때 (add()로 쉽게 추가 가능) 삭제, 삽입이 자주 발생할 때 (remove() 메서드 활용 가능) 제네릭(List&lt;T&gt;)을 활용해야 할 때 🚀 예제: ArrayList 사용 시 ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(10); // 값 추가 list.add(20); list.remove(0); // 첫 번째 요소 삭제 크기가 유동적으로 변할 수 있음 (add(), remove() 사용 가능) 그러나 내부적으로 Integer 객체를 사용하므로 메모리 사용량이 큼 (int보다 많은 메모리 차지) 📌 int[] 배열이 더 유리한 경우 고정된 크기의 데이터를 다룰 때 (메모리 절약 가능) 빠른 접근 속도가 필요할 때 메모리에 직접 접근 (O(1)) 가능 성능 최적화가 필요한 경우 (특히 대량 데이터) 🚀 예제: int[] 사용 시 int[] arr = new int[3]; arr[0] = 10; arr[1] = 20; arr[2] = 30; 메모리를 int 타입 크기만큼만 사용(불필요한 Integer 객체 생성 없음) 읽기/쓰기 속도가 빠름 ⏳ 성능 비교 실험 (Java) 내가 직접 ArrayList&lt;Integer&gt;와 int[]의 속도를 비교하는 코드를 실행해볼게! 아래 코드로 같은 데이터를 저장하고 조회하는데 걸리는 시간을 비교해보자. import java.util.ArrayList; public class PerformanceTest { public static void main(String[] args) { int SIZE = 10_000_000; // 1천만 개의 데이터 테스트 // 1️⃣ 배열 테스트 long startTime = System.nanoTime(); int[] array = new int[SIZE]; for (int i = 0; i &lt; SIZE; i++) { array[i] = i; } long endTime = System.nanoTime(); System.out.println(\"배열(int[]) 실행 시간: \" + (endTime - startTime) / 1_000_000 + \" ms\"); // 2️⃣ ArrayList 테스트 startTime = System.nanoTime(); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(SIZE); for (int i = 0; i &lt; SIZE; i++) { list.add(i); } endTime = System.nanoTime(); System.out.println(\"ArrayList 실행 시간: \" + (endTime - startTime) / 1_000_000 + \" ms\"); } } ⏳ 성능 테스트 결과 (대략적인 차이) 테스트 환경: 10,000,000개의 데이터를 저장하는 경우 (결과는 실행 환경에 따라 다를 수 있음) 데이터 크기 int[] 배열 (배열) ArrayList&lt;Integer&gt; (리스트) 10,000,000개 데이터 저장 30~50ms 100~200ms ✅ 배열(int[])이 ArrayList&lt;Integer&gt;보다 약 3~5배 빠름! 📌 결론: 언제 ArrayList를 쓰고, 언제 배열(int[])을 써야 할까? 상황 ArrayList&lt;Integer&gt; int[] 배열 데이터 크기가 가변적일 때 ✅ 추천 (자동 크기 증가) ❌ 비효율적 (고정 크기) 빠른 읽기/쓰기 성능이 필요할 때 ❌ 상대적으로 느림 ✅ 빠름 (메모리 직접 접근) 메모리 사용량 최적화가 필요할 때 ❌ Integer 객체로 인해 메모리 낭비 ✅ int 원시 타입이므로 메모리 절약 삭제/삽입이 자주 발생할 때 ✅ remove() 지원 ❌ 배열 크기 고정이라 비효율적 성능이 중요하다면 int[] 배열이 훨씬 빠르고 메모리도 절약된다! 🚀 크기가 변하는 데이터를 다룰 때는 ArrayList&lt;Integer&gt;가 편리하다. ✅ 데이터 개수가 많고, 읽기/쓰기 성능이 중요하다면 int[]을 사용하는 것이 좋다. ⚡ 일반적인 상황에서는 ArrayList&lt;Integer&gt;를 쓰는 게 개발 편의성 면에서 좋다. 즉, 고정된 크기라면 배열을 쓰고, 크기가 유동적이면 ArrayList를 쓰는 게 정답! 😃 추가 : HashMap&lt;Integer, Integer&gt;와의 성능 비교 데이터 구조 실행 속도 (초) 특징 배열 (int[]) 가장 빠름 (0.03~0.05초) 메모리 직접 접근 (고정 크기) ArrayList (ArrayList&lt;Integer&gt;) 중간 (0.1~0.2초) 동적 크기 조정 가능 HashMap (HashMap&lt;Integer, Integer&gt;) 가장 느림 (0.3~0.5초) 키-값 매핑 (빠른 탐색) 3️⃣ HashMap (HashMap&lt;Integer, Integer&gt;) 속도: 가장 느림 (배열보다 약 5~10배 느림) 이유: 내부적으로 해시 함수(Hashing) 사용 → 빠른 탐색(O(1)) 가능 하지만 키-값 저장 방식이라 메모리 오버헤드가 큼 장점: 데이터 검색이 O(1) (거의 즉각적) 키 기반으로 빠르게 값에 접근 가능 언제 사용하면 좋을까? Key-Value 형태의 데이터 저장이 필요할 때 데이터 조회 속도가 중요한 경우 (탐색이 많을 때) 💡 결론 사용 목적 추천 자료 구조 고정된 크기의 데이터 int[] (배열) 크기가 유동적인 리스트 ArrayList&lt;Integer&gt; 빠른 탐색이 필요한 경우 HashMap&lt;Integer, Integer&gt; 즉, ✔ 빠른 연산이 필요하면 int[] 배열 ✔ 동적 크기가 필요하면 ArrayList&lt;Integer&gt; ✔ 키-값 조회가 많다면 HashMap&lt;Integer, Integer&gt;",
    "tags": "java",
    "url": "/java/2025-02-25-arraylist-array/"
  },{
    "title": "[JAVA] SOLID 원칙",
    "text": "1. 단일 책임 원칙 2. 개방-폐쇄 원칙 3. 리스코프 치환 원칙 4. 인터페이스 분리 원칙 5. 의존성 역전 원칙 SOLID 원칙 객체지향 프로그래밍(OOP)에서 SOLID 원칙이란, 유지보수와 확장이 쉬운 소프트웨어를 만들기 위한 5가지 설계 원칙 각각의 원칙의 첫글자를 따서 만든 약자. 1. SRP (Single Responsibility Principle) 🔴 단일 책임 원칙 정의 하나의 클래스는 단 하나의 책임(기능)만 가져야 한다. 즉, 클래스가 변경될 이유는 오직 하나여야 한다/ 의미 클래스가 너무 많은 역할을 담당하게 되면, 유지보수나 확장 시 하나의 변경 사항이 다른 기능까지 의도치 않게 영향을 줄 수 있음 하나의 클래스가 단 하나의 목적만 수행하도록 하면, 코드 관리가 쉬워지고 명확해짐 예시 ❌ 나쁜 예시 : 회원 관리 클래스가 로그인, 회원정보 관리, 이메일 발송까지 전부 담당 ✅ 좋은 예시 : 로그인 클래스, 회원정보 관리 클래스, 이메일 발송 클래스를 각각 따로 분리 2. OCP (Open/Closed Principle) 🟠 개방-폐쇄 원칙 정의 소프트웨어의 구성 요소(클래스, 모듈, 함수 등)는 확장에는 열려있고, 변경에는 닫혀있어야 한다. 의미 새로운 기능을 추가할 때 기존 코드를 수정하지 않고도 기능을 확장할 수 있어야 함. 예시 ❌ 나쁜 예시 : 새로운 결제 방식을 추가할 때마다 기존의 결제 클래스를 직접 수정 ✅ 좋은 예시 : 결제 방식 인터페이스를 정의하고, 이를 구현한 클래스(신용카드 결제, 페이팔 결제 등)를 추가함으로써 기존 코드 수정 없이 확장 가능 3. LSP (Liskov Substitution Principle) 🟡 리스코프 치환 원칙 정의 자식 클래스는 언제나 부모 클래스를 대체할 수 있어야 함. 부모 클래스가 사용되는 곳에 자식 클래스를 넣었을 때도 프로그램이 정확히 동작해야 함 의미 상속 관계를 올바르게 설계해 자식 클래스가 부모 클래스의 본질적인 특성을 바꾸지 않아야 한다. 자식 클래스는 부모 클래스가 가진 모든 속성과 메서드를 위반 없이 사용할 수 있어야함 예시 ❌ 나쁜 예시 : ‘정사각형’ 클래스를 ‘직사각형’의 자식 클래스로 만들었지만, 가로세로를 독립적으로 조정할 수 없어서 예상한 동작이 깨지는 경우 ✅ 좋은 예시 : ‘도형’이라는 부모 클래스를 상속하여 ‘직사각형’, ‘정사각형’, ‘삼각형’ 등으로 각자 독립적으로 확장하여 서로 간섭 없이 동작 4. ISP (Interface Segregation Principle) 🟢 인터페이스 분리 원칙 정의 클라이언트는 자신이 사용하지 않은 메서드에 의존하지 않아야 함. 하나의 일반적인 인터페이스보다 여러 개의 구체적이고 세분화된 인터페이스를 사용하는 것이 좋음 의미 하나의 크고 범용적인 인터페이스보다, 용도에 따라 작고 명확하게 구분된 인터페이스를 제공하는 것이 좋음 클라이언트가 필요로 하는 최소한의 메서드만 포함한 인터페이스를 만들어야함 예시 ❌ 나쁜 예시 : 하나의 인터페이스에 “프린트, 팩스, 복사, 스캔” 기능을 모두 넣어서 일부만 사용하는 프린터 기기같이 모든 메서드를 구현해야하는 경우 ✅ 좋은 예시 : “프린트 인터페이스”, “팩스 인터페이스”, “복사 인터페이스”, “스캔 인터페이스”로 나눠서 필요한 기능만 구현하도록 제공 5. DIP (Dependency Inversion Principle) 🔵 의존성 역전 원칙 정의 고수준 모듈은 저수준 모듈의 구현에 의존해서는 안되며 둘 다 추상화에 의존해야함 또한, 추상화(인터페이스나 추상 클래스)는 세부 사항에 의존해서는 안되고, 세부 사항이 추상화에 의존해야함 의미 클래스가 특정 구현(구체적 클래스)이 아닌, 추상화된 인터페이스에 의존하도록 설계해야 함. 이는 의존 관계룰 유연하게 만들어 유지보수 및 확장이 편리해지게 횜 예시 ❌ 나쁜 예시 : 데이터베이스 클래스가 특정 DB(에: MySQL)에 직접 의존하는 코드 설계 ✅ 좋은 예시 : 데이터베이스 인터페이스를 정의하고, 이를 구현하는 다양한 DB클래스(MySQL, PostgreSQL 등)를 만들어 상위 모듈이 인터페이스에만 의존하도록 설계 SOLID 원칙을 지켰을 때의 장점 유지보수 용이성 코드 확장 용이성 가독성 및 코드 품질 향상 테스트 용이성",
    "tags": "java",
    "url": "/java/2025-02-23-solid/"
  },{
    "title": "[Etc] 🔑 Access Token과 Refresh Token 완벽 정리",
    "text": "Access Token과 Refresh Token이란? Access Token Refresh Token Access Token vs. Refresh Token 비교 Access Token과 Refresh Token을 사용하는 이유 Access Token과 Refresh Token을 활용한 인증 흐름 Access Token &amp; Refresh Token 보안 고려 사항 실제 코드 구현 (Java, Spring Security) 1. Access Token과 Refresh Token이란? OAuth 2.0을 사용할 때 핵심이 되는 토큰 토큰 종류 역할 유효 기간 사용 목적 Access Token API 요청 시 인증을 위한 토큰 짧음 (몇 분~1시간) 사용자가 인증된 후 API 접근 Refresh Token Access Token이 만료되었을 때 새 토큰 발급 김 (며칠~몇 달) Access Token을 갱신 2. Access Token ✅ Access Token이란? 사용자가 OAuth 인증을 마치면 Authorization Server가 발급하는 단기 유효 토큰. 이 토큰을 API 요청의 Authorization 헤더에 포함하여 사용. 일반적으로 Bearer Token 방식으로 사용됨. 🎯 Access Token 사용 예시 HTTP 요청에서 Access Token을 포함하여 API 호출: GET /user/profile HTTP/1.1 Host: api.example.com Authorization: Bearer ACCESS_TOKEN ⏳ Access Token의 유효 기간 보안상 짧은 시간(몇 분~1시간 정도) 만 유지됨. Access Token이 만료되면 더 이상 API를 호출할 수 없음. 해결 방법: Refresh Token을 사용하여 새로운 Access Token 발급. 3. Refresh Token ✅ Refresh Token이란? Access Token이 만료되었을 때, 새로운 Access Token을 요청할 수 있도록 제공되는 장기 토큰. Access Token과 다르게, Refresh Token 자체로는 API 요청을 보낼 수 없음. 일반적으로 다시 로그인하지 않고도 인증을 연장할 때 사용. 🎯 Refresh Token 사용 예시 Access Token이 만료되면, Refresh Token을 이용하여 새 Access Token을 요청: POST /auth/token HTTP/1.1 Host: auth.example.com Content-Type: application/x-www-form-urlencoded grant_type=refresh_token&amp; client_id=YOUR_CLIENT_ID&amp; client_secret=YOUR_CLIENT_SECRET&amp; refresh_token=YOUR_REFRESH_TOKEN ⏳ Refresh Token의 유효 기간 며칠~몇 달까지 유지 가능 (보안 정책에 따라 다름). 일반적으로 기기 변경, 비밀번호 변경, 보안 위험 감지 시 강제 만료됨. 4. Access Token vs. Refresh Token 비교   Access Token Refresh Token 목적 API 요청 인증 새로운 Access Token 발급 유효 기간 짧음 (몇 분~1시간) 김 (며칠~몇 달) 보관 위치 클라이언트 저장 클라이언트 저장 (보안 필요) 보안 위험 탈취되면 API 무단 접근 가능 탈취되면 새로운 Access Token 발급 가능 사용 가능 횟수 여러 번 API 요청 가능 1회 또는 제한적 사용 5. Access Token과 Refresh Token을 사용하는 이유 Access Token만 사용하면? 보안상 유효 기간을 길게 설정할 수 없음. 토큰이 만료될 때마다 사용자가 다시 로그인해야 함 → 불편함. Refresh Token을 추가하면? Access Token을 자주 갱신할 수 있음 → 보안 강화. 사용자가 다시 로그인할 필요 없이 자동으로 인증 연장 가능. 👉 Refresh Token을 사용하면 보안과 사용자 편의성 모두 향상됨. 6. Access Token과 Refresh Token을 활용한 인증 흐름 1️⃣ 사용자가 로그인 &amp; 권한 부여 → OAuth 서버가 Access Token과 Refresh Token 발급 2️⃣ 클라이언트가 API 요청 → Authorization: Bearer Access_Token 포함하여 요청 3️⃣ Access Token이 만료됨 → API 서버가 401 Unauthorized 응답 반환 4️⃣ Refresh Token을 사용해 새 Access Token 요청 → 새 Access Token 발급 후 다시 API 요청 가능 5️⃣ Refresh Token도 만료됨 → 사용자는 다시 로그인 필요 👉 Access Token은 API 요청을 인증하는 용도, Refresh Token은 새로운 Access Token을 발급하는 용도! 👉 보안이 중요한 만큼 저장 방식과 유효 기간을 잘 관리해야 함! 🚀 7. Access Token &amp; Refresh Token 보안 고려 사항 ✅ Access Token 보안 유효 기간을 짧게 설정 (몇 분~1시간) HTTPS 사용 필수 (네트워크 스니핑 방지) 탈취되면 API 접근 가능 → 짧은 유효 기간이 보안성을 보장 ✅ Refresh Token 보안 보안 저장소 사용 (예: 모바일 앱에서는 Secure Storage) HTTP 요청 시 노출되지 않도록 주의 (쿠키 또는 안전한 저장소에 보관) 유출 시 즉시 무효화 필요 (서버에서 토큰 무효화 기능 추가) 🚨 탈취 방지 방법 Refresh Token을 클라이언트에서 안전하게 저장 브라우저: HttpOnly Secure Cookie 사용 모바일 앱: Secure Storage / Keychain 사용 Refresh Token 재사용 방지 (One-Time Refresh Token) Refresh Token을 사용할 때마다 새 Refresh Token을 발급하고 이전 것은 무효화 IP &amp; 디바이스 검증 Refresh Token 사용 시 IP 주소와 디바이스 정보를 확인하여 이상 감지 시 무효화 토큰 암호화 및 서명 JWT 기반 Access Token은 서명(Signature) 을 포함하여 위변조 방지 8. Access Token &amp; Refresh Token 실제 코드 구현 (Java, Spring Security) 🔹 Access Token &amp; Refresh Token 발급 API 예제 (Spring Boot) @RestController @RequestMapping(\"/auth\") public class AuthController { @PostMapping(\"/token\") public ResponseEntity&lt;?&gt; getToken(@RequestParam String refreshToken) { if (isValidRefreshToken(refreshToken)) { String newAccessToken = generateNewAccessToken(); return ResponseEntity.ok(newAccessToken); } else { return ResponseEntity.status(HttpStatus.UNAUTHORIZED).body(\"Invalid Refresh Token\"); } } private boolean isValidRefreshToken(String token) { // Refresh Token 검증 로직 return token.equals(\"valid-refresh-token\"); // 예제 코드 } private String generateNewAccessToken() { // 새로운 Access Token 생성 (JWT 사용 가능) return UUID.randomUUID().toString(); } }",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-02-22-token/"
  },{
    "title": "[Etc] OAuth란?",
    "text": "OAuth 개념과 특징 OAuth 1.0 vs. OAuth 2.0 OAuth 2.0 상세 동작 방식 OAuth 2.0 Grant Types (인증 방식) OAuth 2.0의 주요 용어 OAuth 2.0을 실제 코드로 구현 OAuth의 장점 &amp; 단점 OAuth란? 서드파티 애플리케이션이 사용자 인증 정보를 직접 다루지 않고, 다른 서비스의 인증을 통해 특정 리소스에 접근할 수 있도록 하는 인증 및 권한 부여 프로토콜 “카카오 로그인”, “구글 로그인”, “페이스북 로그인” 같은 기능이 OAuth를 사용한 대표적인 사례 1. OAuth 개념과 특징 ✅ OAuth의 핵심 개념 인증(Authentication): 사용자가 누구인지 확인하는 과정 권한 부여(Authorization): 사용자가 특정 리소스에 대한 액세스를 허용하는 과정 토큰 기반 인증: ID/비밀번호 대신 Access Token을 사용하여 API 요청 안전한 인증 방식: 클라이언트가 직접 사용자 계정 정보를 저장하지 않아 보안 강화 ✅ OAuth 동작 방식 사용자가 서드파티 앱에서 로그인 버튼 클릭 OAuth 서버(예: Google, Kakao)가 사용자에게 로그인 페이지 제공 사용자가 로그인하고 권한을 승인 OAuth 서버가 서드파티 앱에 Authorization Code 제공 서드파티 앱이 Authorization Code를 사용하여 Access Token 요청 Access Token을 통해 리소스 서버(API)에 접근하여 데이터 제공 2. OAuth 1.0 vs. OAuth 2.0 OAuth는 1.0과 2.0 두 가지 버전이 있으며 현재는 OAuth 2.0이 표준. 특징 OAuth 1.0 OAuth 2.0 출시 2010년 이전 2012년 이후 보안 방식 HMAC-SHA1 서명 Bearer Token 방식 암호화 필수 여부 요청마다 암호화 필요 HTTPS만 사용하면 됨 사용성 복잡함 간단하고 확장성이 좋음 클라이언트 유형 웹 앱 중심 모바일, 웹, 서버, IoT 지원 인증 방식 Access Token, Secret Key Access Token, Refresh Token 💡 현재 OAuth 2.0을 대부분 사용 3. OAuth 2.0 상세 동작 방식 🔑 OAuth 2.0의 핵심 개념 Authorization Code: Access Token을 받기 위한 코드 Access Token: API 요청 시 사용하는 인증 키 Refresh Token: Access Token이 만료될 때 새로운 Token을 발급하는 키 Redirect URI: OAuth 서버가 Authorization Code를 전달할 URL OAuth 2.0 인증 과정 1️⃣ 사용자 인증 &amp; 권한 부여 (Authorization Request) 클라이언트가 OAuth 제공자(Google, Kakao 등)에게 로그인 요청 사용자 로그인 후, 권한 허용 여부를 선택 2️⃣ Authorization Code 발급 사용자가 권한을 허용하면, OAuth 서버가 Authorization Code를 클라이언트에게 전달 3️⃣ Access Token 발급 (Token Exchange) 클라이언트는 Authorization Code를 사용해 Access Token 요청 OAuth 서버가 유효성 검증 후, Access Token과 Refresh Token 발급 4️⃣ API 요청 (Resource Access) 클라이언트는 Access Token을 포함하여 API 서버에 요청 API 서버는 토큰을 확인한 후 데이터 반환 5️⃣ Access Token 갱신 (Token Refresh) Access Token이 만료되면, Refresh Token을 사용하여 새로운 Access Token 발급 4. OAuth 2.0 Grant Types (인증 방식) Grant Type 설명 사용 예시 Authorization Code 보안이 뛰어난 방식으로, 서버를 거쳐 Access Token을 받음 웹, 모바일 앱에서 로그인 연동 Implicit Access Token을 직접 발급 (보안 약함) 예전 프론트엔드 앱에서 사용 (현재는 사용 X) Resource Owner Password Credentials (ROPC) 사용자 ID/PW를 직접 입력받아 Access Token 발급 신뢰할 수 있는 앱 (예: 사내 시스템) Client Credentials 클라이언트(서버) 자체가 인증됨 (사용자 없음) 서버 간 API 호출 Device Code 디바이스(스마트 TV 등)에서 로그인 TV, IoT 기기 💡 일반적으로 “Authorization Code” 방식이 가장 많이 사용됨. 5. OAuth 2.0의 주요 용어 용어 설명 Resource Owner (사용자) API의 데이터를 소유한 사용자 Client (클라이언트 앱) 사용자의 데이터를 요청하는 앱 (예: 서드파티 앱) Authorization Server 인증을 담당하는 서버 (Google, Kakao 등) Resource Server API 요청을 처리하는 서버 (Google API, Kakao API 등) Access Token 사용자가 인증된 후 API에 접근할 수 있는 키 Refresh Token Access Token이 만료되었을 때 재발급하는 키 Redirect URI OAuth 서버가 Authorization Code를 전달하는 URL 6. OAuth 2.0을 실제 코드로 구현 (1) Authorization Code 방식 (Java) import java.net.URI; import java.net.http.HttpClient; import java.net.http.HttpRequest; import java.net.http.HttpResponse; public class OAuthExample { public static void main(String[] args) throws Exception { // 1. Authorization Code 요청 String clientId = \"your-client-id\"; String redirectUri = \"https://your-app.com/callback\"; String authUrl = \"https://oauth-provider.com/auth?client_id=\" + clientId + \"&amp;redirect_uri=\" + redirectUri + \"&amp;response_type=code\"; System.out.println(\"Login URL: \" + authUrl); // 2. Access Token 요청 String authCode = \"received-authorization-code\"; String tokenUrl = \"https://oauth-provider.com/token\"; HttpClient client = HttpClient.newHttpClient(); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(tokenUrl)) .header(\"Content-Type\", \"application/x-www-form-urlencoded\") .POST(HttpRequest.BodyPublishers.ofString(\"client_id=\" + clientId + \"&amp;code=\" + authCode + \"&amp;redirect_uri=\" + redirectUri + \"&amp;grant_type=authorization_code\")) .build(); HttpResponse&lt;String&gt; response = client.send(request, HttpResponse.BodyHandlers.ofString()); System.out.println(\"Access Token Response: \" + response.body()); } } 7. OAuth의 장점 &amp; 단점 ✅ 장점 보안성 강화: ID/PW를 직접 저장하지 않고, Access Token으로 인증 편리한 로그인: Google, Kakao 로그인 등 쉽게 연동 가능 API 사용 간편화: 서드파티 서비스와 연동할 때 필수 토큰 만료로 보안 강화: Access Token이 주기적으로 만료되므로 보안성 향상 ❌ 단점 구현이 복잡함: Access Token, Refresh Token 관리 필요 서버 부하 증가: 토큰 발급 및 검증 과정에서 추가적인 요청 발생 Refresh Token 유출 위험: Refresh Token이 유출되면 악용될 가능성 있음",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-02-20-OAuth/"
  },{
    "title": "[Git] 효율적인 Git commit 전략: 단위 결정, 스타일, 충돌 해결 방법",
    "text": "Commit 단위를 결정 짓는 요소 Udacity style Rebase를 잘쓰자! conflict를 해결하는 방법 Commit 단위를 결정 짓는 요소 하나의 목적 / 의도 커밋은 하나의 논리적 작업 단위만 포함한다. 예시 “로그인 버튼 스타일 수정” 과 “API 요청 추가”는 별도 커밋으로 나눔 변경 사항의 크기 가능한 작은 크기로 나누되, 완결성을 가져야 한다. 독립성 독립적으로 동작할 수 있어야 한다. 커밋 후 언제든 코드를 실행하거나 테스트할 수 있어야 한다. 관련성 서로 연관된 변경사항은 하나의 커밋으로 묶는다. 예시: 새로운 기능을 추가하면서 해당 기능의 스타일을 함께 수정하는 경우, 하나의 커밋으로 처리 가능 하지만 독립적인 기능 수정과 스타일 변경은 별도의 커밋으로 분리해야 함. 의미 있는 메시지 커밋 메시지가 변경 사항을 명확하게 설명할 수 있도록 구성해야함 예시 좋은 예 : “사용자 로그인 API 요청 로직 추가” 나쁜 예 : “수정함” 또는 “업데이트” Udacity style Udacity에서 권장하는 커밋 메시지 작성 스타일을 의미 📌 Udacity 커밋 메시지 스타일 type: 설명 (길이 72자 이내) type: 변경 사항의 유형을 나타냄 (예: feat, fix, refactor 등) 설명: 간결하고 명확한 변경 사항 설명 ✅ Udacity 스타일 커밋 메시지 예시 feat: 로그인 API 요청 추가 fix: 비밀번호 입력 검증 로직 수정 refactor: 중복된 코드 제거 및 함수 리팩토링 style: 코드 스타일 정리 (불필요한 공백 제거) docs: README 파일 업데이트 test: 회원가입 유닛 테스트 추가 chore: 패키지 버전 업데이트 🛠 Udacity 스타일 주요 특징 첫 글자는 소문자 사용 Git 커밋 메시지 관례에 따라 소문자로 시작함 커밋 타입을 명확히 구분 feat: 새로운 기능 추가 fix: 버그 수정 refactor: 코드 리팩토링 기능 유지 + 코드의 가독성, 유지보수성, 성능 최적화등 코드 구조 개선 style: 코드 스타일 변경 (기능 변경 없음) 기능 유지 + 들여쓰기, 공백, 줄정리 등 코드 포맷 정리 docs: 문서 수정 test: 테스트 코드 추가/수정 chore: 빌드 및 패키지 관련 작업 제목 길이는 72자 이내로 유지 Git 로그에서 한눈에 보기 쉽게 유지 명령형 사용 \"Fixed login bug\" ❌ → \"fix: 로그인 버그 수정\" ✅ 🎯 Udacity 스타일을 쓰는 이유 협업 시 일관성 있는 커밋 로그 유지 Git 커밋 히스토리 가독성 향상 자동화된 릴리즈 노트 생성 가능 (Conventional Commits 방식과 유사) 커밋 이력이 깔끔하게 정리되고 팀원들이 쉽게 이해할 수 있어 유지보수 및 협업에 유리하다. Rebase를 잘쓰자! 참조하는 commit을 변경하는 명령어 base branch가 변경될 때마다 rebase를 하면 conflict를 최소화할 수 있다. Rebase란? 🔗 [Git] git rebase 블로그에 정리되어 있습니다! conflict를 해결하는 방법, Reset + force push Reset이란? git reset 명령어는 특정 커밋으로 되돌리는 기능을 하며, 되돌리는 방식에 따라 코드 변경 사항을 유지할 수도 있고, 삭제할 수도 있음 git reset의 주요 옵션 --soft 특정 커밋 이전으로 HEAD를 이동하지만, 변경된 파일과 스테이징 영역은 그대로 유지 보통 최근 커밋을 수정하고 다시 커밋할 때 사용 --mixed (기본 옵션) 특정 커밋 이전으로 HEAD 이동, 스테이징 영역은 초기화되지만 작업 디렉터리는 유지됨 --hard 특정 커밋 이전으로 HEAD 이동, 변경된 코드까지 전부 삭제되며 되돌릴 수 없음 Reset 후 force push 사용 로컬에서 git reset을 사용하여 커밋을 변경하면, 원격 저장소와 커밋 이력이 달라져 git push시 conflict가 발생할 수 있다. 이 문제를 해결하기 위해 git push --force를 사용하면, 로컬 브랜치의 변경사항을 강제로 원격 저장소에 반영할 수 있음 conflict 해결 방법으로써의 Reset + force push commit이 여러개인 경우, 중간에 conflict가 난 경우, 이 후의 커밋 모두 conflict가 발생 하지만 git reset으로 커밋을 하나의 커밋으로 만들면 코드 충돌을 빠르게 해결할 수 있음",
    "tags": "git",
    "url": "/git/2025-02-19-git-commit/"
  },{
    "title": "[TIL] 효율적인 git commit 전략",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #19 📅 작성일: 2025-02-18 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 이번에 Git에 대해 다시 공부하면서 두 가지 개념을 중점적으로 정리했다. 효율적인 Git Commit 전략 예전에는 커밋 메시지를 감으로 작성했지만, 최근엔 Udacity 스타일의 커밋 메시지 작성법을 적용해보려 하고 있다. 예: feat: 사용자 프로필 저장 기능 추가 또는 fix: API 응답 포맷 오류 수정 git rebase 완전 정복하기 지금까지는 git merge만을 주로 사용해 협업을 해왔지만, git rebase의 개념은 늘 ‘들어만 봤던’ 상태였다. 이번 기회에 git rebase가 실제로 어떤 상황에서 유용하고, 어떤 흐름으로 작동하는지를 명확히 정리하게 되었다. 🍎 오늘의 문제 상황 🔍 문제 인식 프로젝트를 진행하면서 Git 커밋 로그가 너무 산만하게 흐르는 것을 보며, 자연스럽게 Git 전략에 대한 고민이 생겼다. 특히 git merge만 사용하다 보니 히스토리가 복잡하게 얽히는 문제가 발생했다. 이때 떠오른 것이 git rebase였다. 하지만 막상 스스로 설명하려 하니… “내가 이걸 **‘제대로’ 아는 걸까?” 라는 의문이 들었다. ✅ 해결 과정 Git Merge vs Rebase 차이점 정리 항목 git merge git rebase 브랜치 구조 브랜치가 병합되며 병합 커밋(Merge Commit) 생성 브랜치가 직선적으로 재배열됨 커밋 히스토리 복잡하지만 충돌 이력이 명확히 남음 깔끔하지만 충돌 해결 히스토리는 사라짐 협업 시기 공식 배포 브랜치 병합 시 사용 권장 개인 브랜치 정리용으로 주로 사용 언제 rebase가 유용할까? 큰 조직이나 다수의 협업자들이 있는 경우, 직선적인 커밋 히스토리는 디버깅과 리뷰에 큰 도움이 된다. PR을 올리기 전 개인 브랜치의 커밋을 정리할 때 매우 유용하다. (git rebase -i로 커밋 합치기 등) 작은 프로젝트에서는 merge만 써도 큰 불편은 없었지만, 실제 대규모 프로젝트에서는 rebase의 가치가 커진다는 것을 깨달았다. 🦄 느낀 점 정말로 와닿은 문장: “아는 것과 제대로 아는 것은 다르다.” 나는 git rebase를 ‘안다고 생각했지만’, 정작 쓸 수는 없었다. 이번에 개념과 흐름을 정리하면서 ‘실제로 써먹을 수 있는 지식’으로 바뀌었다. 이제는 협업 시 git log를 깔끔하게 유지하는 것도 개발자의 중요한 역량이라는 걸 알게 되었고, 다음 협업에서는 rebase도 적극적으로 활용해보고 싶다. 💬 TIP 팀원들과 Git 전략을 공유할 때는 merge/rebase 전략을 사전에 정리하고, PR 전에는 git rebase origin/main을 통해 개인 브랜치를 정리해두는 습관이 중요하다! 🐬 깃블로그 정리 [효율적인 git commit 전략] (https://nan0silver.github.io/miscellaneous/2025-02-19-git-commit/) [git rebase] (https://nan0silver.github.io/miscellaneous/2025-01-23-git-rebase/)",
    "tags": "TIL Git til",
    "url": "/til/2025-02-18-til/"
  },{
    "title": "[TIL] JWT 저장방식 HttpOnly Cookies VS LocalStorage",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #18 📅 작성일: 2025-02-17 🔄 최종 수정: 2025년 02월 17일 🍀 새롭게 배운 것 JWT 저장 방식 HttpOnly Cookies VS LocalStorage 🍎 오늘의 문제 상황 1. JWT를 HttpOnly Cookies 방식으로 저장하려고 했지만 CORS 문제로 계속 실패했다. 📌 원인 분석 크롬의 Thrid-party Cookie 제한 백엔드에서 배포한 도메인(banana-flask-app.onrender.com)과 프론트엔드에서 배포한 도메인(banana-project01.github.io)이 달라 쿠키가 전달이 차단되었다. 해결 방법 같은 도메인을 운영하거나, JWT를 localStorage에 저장해 Authorization 헤더에 포함하는 방법이 있다. ✅ 해결 방법 쿠키 대신 JWT를 localStorage에 저장하고, API 요청 시 Authorization 헤더에 추가하는 방식으로 변경했다. JWT 저장 (로그인 성공 시) localStorage.setItem(\"access_token\", jwt_token); API 요청 시 Authorization 헤더 추가 2. 로그인 후 JWT가 포함된 URL로 리디렉션되지만, 토큰이 localStorage에 저장되지 않음 📌 원인 분석 storeTokenFromURL() 함수가 실행되지 않음. window.location.href = \"?token=...\"으로 이동하면 JavaScript 실행 흐름이 초기화됨. DOMContentLoaded 이벤트가 실행되기 전에 storeTokenFromURL()을 호출해야 함. ✅ 해결 방법 페이지 로드 시 storeTokenFromURL() 강제 실행 document.addEventListener(\"DOMContentLoaded\", function () { console.log(\"🔥 페이지 로드 완료, storeTokenFromURL() 실행 대기...\"); storeTokenFromURL(); fetchUserInfo(); }); 토큰을 URL에서 추출하고 localStorage에 저장 3. 로컬 개발 환경에서 로그인 후 토큰이 저장되지 않았다. 📌 원인 분석 로컬 개발 환경 (http://127.0.0.1:5501)에서 로그인 후 localStorage.getItem(“access_token”)이 null로 반환됨. 프론트엔드와 백엔드의 도메인이 다르면 window.location.href를 통한 리디렉션이 정상적으로 작동하지 않을 수 있음. 127.0.0.1에서 개발 중인데, 배포된 banana-project01.github.io 도메인으로 리디렉트되면서 localStorage가 초기화됨. ✅ 해결 방법 Postman에서 Bearer 토큰 인증 테스트 Authorization 헤더에 Bearer 을 수동으로 입력하여 API 호출. 4. 다른 사용자가 로그인 시 500 에러가 발생하였다. 다른 사용자가 로그인하면 KeyError: ‘id’ 또는 IntegrityError: duplicate key value violates unique constraint “user_email_key” 오류 발생. 📌 원인 분석 카카오 &amp; 구글 OAuth 사용자 정보 구조가 다름 → user_info[“id”]가 없을 가능성 있음. 이메일이 없는 경우 기본값 “No Email”을 사용 → 동일한 이메일이 중복되면서 Unique Constraint 오류 발생. ✅ 해결 방법 소셜 로그인 시 get() 사용하여 안전하게 값 가져오기 이메일이 중복되지 않도록 수정 🦄 느낀 점 소셜 로그인을 다 구현했다고 생각했지만, 배포이후 과정에서 복잡한 부분이 많았다. 아직 더 신경 쓰고, 고려해야할 점이 많지만 이 부분을 배우면서 추후에 서비스를 더욱 디벨롭하면 좋을 것같다. 로그인 후 로그인 버튼이 프로필 아이콘으로 바뀌도록 하였지만, 프로필 아이콘 변경에 딜레이가 있다. 마이페이지 구현을 해봐도 좋을 것같다. 또한 사람들이 한꺼번에 서버를 사용하게 되면 어떻게 될지도 테스트해보고 싶다. 무료 버전의 render를 사용해서 서버 운영에서 약간 불안정한 점이 있었다. (cold start) 다음엔 AWS로 구현해보고 싶다. 🐬 참고 자료 [",
    "tags": "TIL til",
    "url": "/til/2025-02-17-til/"
  },{
    "title": "[TIL] Swagger, Naver Login 연동, 게시판 프론트 &amp; 백엔드 연결",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #17 📅 작성일: 2025-02-14 🔄 최종 수정: 2025년 02월 17일 🍀 새롭게 배운 것 Swagger를 통한 API gateway 문서 작업 Naver Login 연동 게시판 프론트 작업 (HTML, CSS, JS) 게시판 프론트와 백엔드 연결 DB 연동 후 게시판 리스트 및 이미지만 가진 포토 후기 게시판 연결 🍎 오늘의 문제 상황 Render를 통해 Flask 서버를 배포했는데, 일정 시간 동안 요청이 없으면 500 Internal Server Error가 발생하는 문제가 있었다. 오랫동안 요청이 없을 경우 서버가 다운된 것처럼 작동하지 않는 문제가 반복적으로 발생했다. 원인 분석 Render의 무료 플랜에서는 일정 시간이 지나면 자동으로 서버가 sleep 상태로 전환된다. 이후 요청이 들어오면 다시 실행되지만, Cold Start(서버가 다시 실행되는 과정) 때문에 첫 번째 요청에서 오류가 발생할 가능성이 높다. Flask의 경우 실행 중이던 특정 환경 변수나 세션 정보가 초기화되면서 예기치 않은 500 에러가 발생할 수 있다. 해결 과정 UptimeRobot을 활용하여 일정 주기로 서버에 요청을 보내는 방법을 적용했다. UptimeRobot에서 5초마다 서버의 엔드포인트에 GET 요청을 보내도록 설정 주기적인 요청을 통해 서버가 계속 활성 상태를 유지하도록 유도 결과적으로 서버가 유지되었다. 🦄 느낀 점 무료 배포 플랫폼에서는 서버 유지 문제를 고려해야겠다. glitch도 같은 문제를 가지고 있다. 이를 위해 주기적으로 요청을 보내는 방식을 사용해야 겠다. 다음에는 AWS의 배포 서비스를 이용해 더 적절한 솔루션을 찾아야 겠다. 🐬 참고 자료 [Swagger 문서] (https://banana-flask-app.onrender.com/apidocs/)",
    "tags": "TIL til",
    "url": "/til/2025-02-14-til/"
  },{
    "title": "[TIL] Supabase 연동 및 Render를 이용한 배포, Flask_CORS",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #16 📅 작성일: 2025-02-13 🔄 최종 수정: 2025년 02월 15일 🍀 새롭게 배운 것 Supabase PostgresSQL 연동 로컬 &amp; 배포 환경 Render를 이용한 배포 Flask_CORS를 이용해 CORS 문제 해결 로그인 성공 후 리디렉션 문제 해결 🍎 오늘의 문제 상황 배포 환경에서 Supabase를 연동할 경우 정상적으로 DB가 연결되었지만, 로컬 환경에서는 핫스팟을 사용할 때만 연결이 되었고, 인터넷이 느려지는 문제가 있었다. 배포 환경에서는 session pooler를 사용해 IPv4로만 접근하도록 설정했다. 로컬에서 배포할 때 연결 방식에 대한 문서를 충분히 확인하지 않고, IPv6 연결 방식으로 시도했었다. 하지만 핫스팟을 사용할 때는 IPv4가 필요하다는 점을 인지하고 IPv4로 연결하자 정상적으로 동작했다. 해결 과정 IPv6 지원 여부 확인 https://test-ipv6.com/ 를 방문하여 확인 연결 방식 수정 로컬에서도 배포 환경과 동일하게 session pooler를 사용하여 IPv4 연결 방식으로 변경함. Supabase 연결 시 Direct Connection 대신 Session Pooler를 사용하도록 .env 설정을 변경함. 🦄 느낀 점 다 해결하고 보니 IPv4와 IPv6을 계속 혼동하고 어지럽게 작업한 것 같아. 잘 모르겠으면 일단 찾아보고 제대로 알고 해결을 하도록 하자.. 그게 시간을 단축하는 길..",
    "tags": "TIL Flask til",
    "url": "/til/2025-02-13-til/"
  },{
    "title": "[TIL] JWT로 Kakao &amp; Google Login, Supabase DB 연동 (Flask)",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #15 📅 작성일: 2025-02-12 🔄 최종 수정: 2025년 02월 12일 🍀 새롭게 배운 것 JWT를 사용한 로그인 flask구현 Kakao Google Supabase PostgresSQL 연동 🍎 오늘의 문제 상황 Supabase Auth를 이용해 간편한 JWT 구현으로 Kakao 로그인을 구현하려고 했지만, 실패했다. 원인 분석 Kakao 로그인 동의항목에 이메일이 권한이 없어 선택되지 못했다. Supabase를 통해 redirect되는 과정에서 이메일을 필수로 요구해서 이 부분을 수정하지 못했다.. 해결 과정 Supabase 대신 Flask에서 직접 Kakao 로그인과 JWT 발급을 구현 Flask-JWT-Extended를 사용하여 사용자 인증 및 JWT 토큰 발급 처리 JWT 발급 시 identity=str(user.id)로 설정하여 422 Error 해결 JWT 인증을 활용한 게시판 기능을 구현하고, Authorization: Bearer YOUR_JWT_TOKEN 방식으로 인증 Postman을 통해 JWT 인증을 테스트하며 401 Unauthorized 문제 해결 🚀 Flask를 활용하여 Supabase 없이 Kakao 로그인을 성공적으로 구현하고 JWT 인증까지 완료! 🦄 느낀 점 flask로 구현하니, 많은 사람들이 하지 않는 방식이라 그런지 공식 문서에서 코드가 없는 문제가 있다. 많은 사람들이 사용하는 툴을 사용하는 것이 문제 해결에 도움이 된다.. 하지만 ChatGPT로 많은 부분 도움받을 수 있었다. Supabase Auth와 DB 모두 사용해보고 싶었는데 약간 아쉬웠다. 다음에는 Next.js로 구현해보고싶다.",
    "tags": "TIL Flask til",
    "url": "/til/2025-02-12-til/"
  },{
    "title": "[TIL] Kakao Login 구현",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #14 📅 작성일: 2025-02-11 🔄 최종 수정: 2025년 02월 14일 🍀 새롭게 배운 것 Flask로 Kakao Login 구현 🍎 오늘의 문제 상황 flask shell 실행 시 Could not locate a Flask application 오류 발생. db.create_all()을 실행해도 데이터베이스 테이블이 생성되지 않음. JSON 응답에서 한글이 깨지는 문제 발생. 원인 분석 FLASK_APP 환경 변수가 설정되지 않아 Flask 애플리케이션을 찾을 수 없었음. db.create_all()을 실행할 때 데이터베이스 초기화 과정 (init_db(app))이 누락되었을 가능성이 있음. JSON 직렬화 시 ensure_ascii=True가 기본값이라 한글이 Unicode 형태로 변환됨. 해결 과정 export FLASK_APP=app_kakao_CRUD.py 설정 후 실행하여 Flask 애플리케이션을 인식하도록 함. init_db(app)를 실행한 후 db.create_all()을 실행하여 테이블이 정상적으로 생성되는지 확인함. json.dumps(…, ensure_ascii=False)를 사용하여 JSON 응답에서 한글이 깨지지 않도록 수정함. 🦄 느낀 점 Flask 개발을 할 때 환경 변수 설정, 데이터베이스 초기화, 세션 관리 등의 기본기를 확실하게 다져야겠다고 느꼈다. 구현하면서 계속 기록하면서 내가 어떤 부분을 놓치고 있는지 적어놓고 공부하는 것을 습관화 해야할 것 같다.",
    "tags": "TIL til",
    "url": "/til/2025-02-11-til/"
  },{
    "title": "[TIL] Express.js, nodemon, dotenv, 다단계 AI호출",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #13 📅 작성일: 2025-02-10 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 Express.js -&gt; Node.js에서 웹 서버를 쉽게 만들 수 있도록 도와주는 프레임워크 Express.js에서 nodemon을 사용한 자동 리빌드 .env파일을 사용한 환경변수 관리 (dotenv) 다단계 AI 호출을 통한 이미지 및 설명 생성 (LLM 활용) 🍎 오늘의 문제 상황 Git에서 step1브랜치를 main브랜치에 병합하려고 했는데, merge과정에서 에러가 발생했다. 원치 않는 .DS_Store파일 때문에 병합이 중단됨 원인 분석 .DS_Store는 macOS에서 자동 생성하는 숨김하일로, Finder가 폴더 정보를 저장하는 용도로 사용됨 asset에 favicon넣는 과정에서 finder를 열어 복붙했는데 거기서 생성된 것 같다.. step1브랜치와 main 브랜치 간에 DS_Store파일이 다르게 존재하면서, Git이 병합 시 덮어씌울 가능성이 있다고 판단해 중단됨 병합 도중 에러가 발생하면서 일부 파일이 삭제된 것처럼 보였음 해결 과정 git reset --hard HEAD를 통해 병합 전 상태로 복구 다시 병합 전에 step1, main에서 DS_Store 제거 정상적으로 병합 진행 .gitignore에 .DS_Store추가해야함 🦄 느낀 점 .DS_Store는 .gitignore에 추가가 필수! Git과 관련해서 에러가 나면 너무 무서워서 당황하는 경향이 있다.. 차분하게 해결책 찾기!! 🐬 깃블로그 정리 [AI호출 통한 이미지 및 설명 생성] (https://github.com/DataPulseX)",
    "tags": "TIL JavaScript til",
    "url": "/til/2025-02-10-til/"
  },{
    "title": "[TIL] JS Callback, Promise, Fetch, Axios",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #12 📅 작성일: 2025-02-06 🔄 최종 수정: 2025년 02월 07일 🍀 새롭게 배운 것 JavaScript 비동기 처리 Callback Promise, async, await JavaScript 네트워크 요청 Fetch, Axios 🍎 오늘의 문제 상황 GitHub Actions를 사용하여 TIL 목록을 자동으로 업데이트하는 작업을 진행했지만, 매번 전체 TIL 리스트가 중보 추가되는 문제가 발생했다. 원인 분석 gh issue list 명령어를 실행할 때마다 최신 TIL 10개를 가져와 덮어쓰기 때문에 기존 목록과 중복된 항목이 계속 추가됨 sort -u로 중복을 제거하려 했지만 이미 있는 내용과 비교하는 기능이 없었음 awk를 사용한 TIL리스트 추출 방식이 정확하지 않아 비교 대상이 제대로 생성되지 않았을 수도 있음 해결 과정 awk대신 sed를 사용하여 TIL List 이후 목록을 정확히 가져옴 grep -Fxvf를 사용하여 기존 리스트에 없는 새로운 TIL만 추출 새로운 TIL이 있는 경우 sed로 기존 TIL 리스트 완전 삭제 후 새로운 TIL을 포함한 리스트 모두 새로 추가 새로 추가된 TIL이 없는 경우 커밋 만들지 않은 코드 추가 🦄 느낀 점 gh issue list가 GitHub의 REST API를 활용하는 방식으로, JS의 fetch나 axios와 유사한 원리로 작동한다고 한다. 스크립트 언어는 처음 봤고, 잘 몰랐었는데 뜯어보니가 작동 방식은 비슷했다. 단순히 자동화를 하는것이 아니라 데이터를 관리하고 처리하는 것이 내가 원하는 기능을 구현한는데 더 중요한 것 같다. 🐬 참고 자료",
    "tags": "TIL JavaScript til",
    "url": "/til/2025-02-06-til/"
  },{
    "title": "[TIL] 시큐어 코딩, glitch, CORS",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #11 📅 작성일: 2025-02-05 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 기초적 시큐어 코딩 (클로저 사용) glitch를 이용한 키 노출 문제 해결 CORS 문제 해결 🍎 오늘의 문제 상황 Glitch에서 Fastify를 사용해 서버를 개발하던 중, 클라이언트에서 API 요청을 보낼 때 CORS 오류가 발생함 Access to fetch at 'https://my-glitch-app.glitch.me/api' from origin 'https://another-site.com' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource. 서버에서 CORS 설정을 올바르게 해주어야 해결할 수 있다. 해결 과정 Fastify에 CORS 플러그인 추가 @fastify/cors 플러그인을 등록하여 모든 도메인에서의 요청을 허용하도록 설정 fastify.register(require('@fastify/cors'), { origin: \"*\", // 모든 도메인에서 요청을 허용 }); CORS 플러그인 설치 무조건 8버전을 설치해야 제대로 실행이 되었다. npm install @fastify/cors@8.0.0 🦄 느낀 점 CORS가 어떤 것인지 몰랐는데, 이번에 해결하면서 알게 되었다. Fastify는 기본적으로 CORS를 막고 있어서 직접 열어줘야 한다는 것을 배웠다. 키 노출을 해결하는 방법으로 환경변수를 활용하는 더 좋은 방법을 배운 것 같다. 🐬 깃블로그 정리 [Gemini를 이용한 메모 태그 추천 서비스] (https://nan0silver.github.io/memoGemini/)",
    "tags": "TIL til",
    "url": "/til/2025-02-05-til/"
  },{
    "title": "[JavaScript] DOM &amp; BOM",
    "text": "DOM (Document Object Model) DOM 기본 구조 DOM의 특징 DOM을 활용한 사례 BOM (Browser Object Model) BOM의 특징 BOM 주요 객체 사용 예제 DOM과 BOM의 차이점 DOM (Document Object Model) 웹페이지의 HTML을 트리 구조로 표현한 객체 모델 document객체를 통해 접근 가능 루트 노드는 항상 document 객체 JavaScript를 통해 브라우저에서 웹 페이지를 동적으로 문서를 조작할 수 있게 하는 API 요소를 추가, 수정, 삭제 가능 필요한 이유 웹 페이지 내용 동적으로 변경 가능 사용자 입력에 따라 인터랙티브한 기능 추가 HTML 요소를 추가, 수정, 삭제 가능 CSS 스타일을 JavaScript로 변경 가능 이벤트 핸들링(클릭, 키보드 입력 등) 가능 DOM 기본 구조 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;My Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 id=\"title\"&gt;Hello, DOM!&lt;/h1&gt; &lt;p class=\"text\"&gt;This is a paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; 이 HTML 문서는 DOM 트리 구조로 변환됨 Document ├── &lt;html&gt; │ ├── &lt;head&gt; │ │ └── &lt;title&gt;My Page&lt;/title&gt; │ ├── &lt;body&gt; │ │ ├── &lt;h1 id=\"title\"&gt;Hello, DOM!&lt;/h1&gt; │ │ └── &lt;p class=\"text\"&gt;This is a paragraph.&lt;/p&gt; DOM 조작 예제 (JavaScript) // 요소 선택 let title = document.getElementById(\"title\"); // &lt;h1&gt; 요소 선택 let text = document.querySelector(\".text\"); // &lt;p&gt; 요소 선택 // 요소 내용 변경 title.innerText = \"Hello, World!\"; text.innerHTML = \"&lt;b&gt;Updated paragraph!&lt;/b&gt;\"; // 요소 스타일 변경 title.style.color = \"blue\"; // 요소 추가 let newParagraph = document.createElement(\"p\"); newParagraph.innerText = \"This is a new paragraph!\"; DOM의 특징 주요 속성 및 메서드 document.body 문서의 &lt;body&gt; 요소 반환 firstElementChile, lastElementChild 첫 번째와 마지막 자식 요소를 반환 children 모든 자식 요소의 컬렉션을 반환 DOM을 활용한 사례 동적 리스트 추가 html &lt;ul id=\"itemList\"&gt;&lt;/ul&gt; &lt;button id=\"addItem\"&gt;Add Item&lt;/button&gt; javascript let button = document.getElementById(\"addItem\"); let list = document.getElementById(\"itemList\"); button.addEventListener(\"click\", function () { let newItem = document.createElement(\"li\"); newItem.innerText = \"New Item\"; list.appendChild(newItem); }); BOM (Browser Object Model) 브라우저 창과 관련된 객체를 제공하는 모델 웹페이지가 아닌 브라우저 자체를 제어할 수 있도록 해주는 API BOM의 특징 웹 브우저 창, URL, 히스토리, 콘솔 등을 조작 가능 window 객체를 통해 접근 가능 대표적인 BOM 객체 window -&gt; 브라우저 창 전체 navigator -&gt; 브라우저 정보 location -&gt; 현재 URL 정보 history -&gt; 방문 기록 관리 screen -&gt; 디바이스 화면 정보 BOM 주요 객체 사용 예제 window console.log(window.innerWidth); //현재 브라우저 창 너비 console.log(window.innerHeight); window.alert(\"This is an alert!\"); navigator console.log(navigator.userAgent); //사용자 브라우저 정보 console.log(navigator.language); //사용 언어 histofy history.back(); //이전 페이지로 이동 history.forward(); //다음 페이지로 이동 DOM과 BOM의 차이점 비교 항목 DOM BOM 역할 HTML 문서를 객체로 표현하여 조작 브라우저 창과 관련된 기능 제공 중심 객체 document 객체 window 객체 조작 대상 HTML 요소, 스타일, 속성 브라우저 창, URL, 히스토리, 화면 정보 사용 예시 &lt;div&gt;, &lt;p&gt; 등의 조작 새 창 열기, 페이지 이동, 알림 띄우기 주요 메서드 .getElementById(), .querySelector(), .innerText alert(), location.href, history.back()",
    "tags": "javascript",
    "url": "/javascript/2025-02-05-dom-bom/"
  },{
    "title": "[TIL] JS BOM, 로컬/세션 스토리지, 직렬화, ??",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #10 📅 작성일: 2025-02-04 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 JavaScript DOM, BOM 로컬 스토리지, 세션 스토리지 직렬화, 역직렬화 null 관련 연산자 (??, .? 등) 🍎 오늘의 문제 상황 배운 내용을 토대로 간단한 예제 구현 중, 입력한 데이터가 새로 고침 후 사라지는 문제 해결위해 노력 로컬 스토리지와 세션 스토리지 예제 구현 시, 객체 데이터를 저장할 때 [object Object]로 출력되는 문제 발생 null 값을 포함하는 데이터에서 undefined 에러가 발생 해결 과정 로컬 스토리지와 세션 스토리지의 차이를 비교하고, JSON.stringfy()와 JSON.parse()를 활용해 객체 데이터를 올바르게 저장 및 불러오기 구현 BOM의 window.onbeforeunload 이벤트를 사용해 페이지 새로고침 시 데이터 저장 ?.과 ??를 사용해 null값이 포함된 데이터 안전하게 처리 🦄 느낀 점 로컬 스토리지에 객체 데이터를 저장하려면 직렬화가 필수 JSON을 다루는 구현은 여러 번 했지만, 직렬화 단어는 익숙하지 않아서 이론 공부의 중요성을 다시금 깨달았다.. 단순한 예제라도 데이터 저장과 상태 관리를 생각하며 구현하는 연습을 해야겠다. 🐬 깃블로그 정리 [Gemini를 이용한 메모 태그 추천 서비스] (https://nan0silver.github.io/memoGemini/) [Local, Session storage] (https://nan0silver.github.io/javascript/2025-02-04-storage/) [직렬화, 역직렬화] (https://nan0silver.github.io/miscellaneous/2025-02-04-serialization/)",
    "tags": "TIL JavaScript til",
    "url": "/til/2025-02-04-til/"
  },{
    "title": "[Etc] 직렬화 (Serialization)와 역직렬화(Deserialization)",
    "text": "직렬화와 역직렬화 직렬화란? 📦 역직렬화란? 📦 ➡️ 💻 언어별 직렬화 및 역직렬화 예시 직렬화(Serialization)과 역직렬화(Deserialization) 💾 ➡️ 💻 직렬화 프로그램에서 사용하는 데이터를 파일이나 네트워크를 통해 전송하거나 저장하기 쉬운 형태로 변환하는 과정 역직렬화 그 반대로, 저장되거나 전송된 데이터를 다시 프로그램에서 사용할 수 있는 원래의 데이터 형태로 복원하는 과정 직렬화 (Serialization) 이란? 📦 직렬화는 메모리 상에 있는 객체나 데이터 구조를 바이트 스트림 형태로 변환하는 것을 의미한다. 마치 택배 상자에 물건을 포장하는 것처럼, 데이터를 “직렬” 형태로 나열하여 보관하거나 전송하기 좋게 만드는 것. 주요 목적: 데이터 저장: 객체의 상태를 파일이나 데이터베이스에 저장하여 영구적으로 보관 💾 데이터 전송: 네트워크를 통해 객체를 다른 시스템으로 전송 🌐 원격 호출 (RPC, RMI): 객체를 네트워크를 통해 다른 시스템의 메소드 인자로 전달 📞 예시: 객체를 JSON이나 XML 형태로 변환하여 텍스트 파일에 저장 객체를 바이너리 형태로 변환하여 네트워크 소켓을 통해 전송 역직렬화 (Deserialization) 이란? 📦 ➡️ 💻 역직렬화는 직렬화된 바이트 스트림을 다시 원래의 객체나 데이터 구조로 복원하는 과정 택배 상자를 열어 내용물을 꺼내는 것과 비슷하게, 직렬화된 데이터를 “역으로 직렬”화하여 프로그램이 이해할 수 있는 형태로 되돌리는 것. 주요 목적: 저장된 데이터 로드: 파일이나 데이터베이스에서 직렬화된 객체를 읽어와 메모리에 복원 💾 ➡️ 💻 전송된 데이터 수신: 네트워크를 통해 수신된 직렬화된 데이터를 객체로 변환 🌐 ➡️ 💻 원격 호출 결과 처리: 원격 시스템으로부터 직렬화된 객체 형태로 결과를 받아 원래 객체로 복원 📞 ➡️ 💻 예시: JSON이나 XML 텍스트 파일을 읽어 객체로 복원 바이너리 데이터를 네트워크 소켓으로부터 읽어 객체로 복원 언어별 직렬화 및 역직렬화 예시 JavaScripnt (Node.js) JavaScript에서는 기본적으로 JSON 객체를 사용하여 직렬화 및 역직렬화를 많이 수행 바이너리 직렬화는 Buffer 객체 등을 활용해야 합니다. // 직렬화 (Serialization) const data = { name: \"David\", city: \"Seoul\" }; const jsonString = JSON.stringify(data); // 📦 -&gt; JSON String console.log(jsonString); // {\"name\":\"David\",\"city\":\"Seoul\"} // 역직렬화 (Deserialization) const loadedData = JSON.parse(jsonString); // JSON String -&gt; 📦 -&gt; 💻 console.log(loadedData); // { name: 'David', city: 'Seoul' } Python Python에서는 pickle 모듈을 사용하여 직렬화 및 역직렬화를 기본적으로 지원한다. JSON, marshal 등 다양한 모듈도 활용 가능 import pickle # 직렬화 (Serialization) data = {'name': 'Alice', 'age': 30} with open('data.pickle', 'wb') as f: pickle.dump(data, f) # 📦 -&gt; 💾 # 역직렬화 (Deserialization) with open('data.pickle', 'rb') as f: loaded_data = pickle.load(f) # 💾 -&gt; 📦 -&gt; 💻 print(loaded_data) # {'name': 'Alice', 'age': 30} Java Java는 java.io.Serializable 인터페이스를 구현한 클래스에 대해 직렬화를 기본적으로 지원합니다. JSON 라이브러리 (Jackson, Gson 등)를 사용하여 JSON 직렬화/역직렬화도 많이 사용됨. import java.io.*; class Person implements Serializable { String name; int age; public Person(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \"Person{name='\" + name + \"', age=\" + age + '}'; } } public class SerializationExample { public static void main(String[] args) { // 직렬화 (Serialization) Person person = new Person(\"Bob\", 25); try (FileOutputStream fileOut = new FileOutputStream(\"person.ser\"); ObjectOutputStream out = new ObjectOutputStream(fileOut)) { out.writeObject(person); // 📦 -&gt; 💾 System.out.println(\"Serialized data is saved in person.ser\"); } catch (IOException i) { i.printStackTrace(); } // 역직렬화 (Deserialization) Person loadedPerson = null; try (FileInputStream fileIn = new FileInputStream(\"person.ser\"); ObjectInputStream in = new ObjectInputStream(fileIn)) { loadedPerson = (Person) in.readObject(); // 💾 -&gt; 📦 -&gt; 💻 } catch (IOException i) { i.printStackTrace(); return; } catch (ClassNotFoundException c) { System.out.println(\"Person class not found\"); c.printStackTrace(); return; } System.out.println(\"Deserialized Person: \" + loadedPerson); // Deserialized Person: Person{name='Bob', age=25} } } Kotlin Kotlin은 Java와 유사하게 java.io.Serializable 인터페이스를 사용하거나, Jackson, Gson 같은 JSON 라이브러리를 활용 Kotlin Serialization library를 사용하여 더 간편하게 직렬화/역직렬화를 할 수도 있음 import kotlinx.serialization.* import kotlinx.serialization.json.* import java.io.* @Serializable data class User(val name: String, val age: Int) fun main() { // 직렬화 (Serialization) val user = User(\"Eve\", 28) val json = Json.encodeToString(User.serializer(), user) # 📦 -&gt; JSON String println(json) # {\"name\":\"Eve\",\"age\":28} // 역직렬화 (Deserialization) val loadedUser = Json.decodeFromString(User.serializer(), json) # JSON String -&gt; 📦 -&gt; 💻 println(loadedUser) # User(name=Eve, age=28) // Java Serializable 사용 (Java와 동일) // ... (Java 예시 코드와 유사) }",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-02-04-serialization/"
  },{
    "title": "[JavaScript] 로컬 스토리지 VS 세션 스토리지",
    "text": "로컬 스토리지 VS 세션 스토리지 데이터 유지 기간 접근 범위 활용 예제 사용 방법 (JavaScript) 로컬 스토리지 (Local Storage) VS 세션 스토리지 (Session Storage) 둘 다 웹 브라우저의 저장소 데이터를 클라이언트 측에 저장할 수 있는 기능을 제공 아래는 차이점을 확인할 수 있다. 데이터 유지 기간 Local Storage 브라우저를 닫아도 데이터가 유지됨 명시적으로 삭제하지 않는 한 영구적으로 저장됨 Session Storage 브라우저의 탭을 닫으면 데이터가 삭제됨 세션동안만 유지됨 세션 : 일정 기간 동안 유지되는 사용자와 시스템 간의 연결 상태 (주로 사용자의 로그인 상태 유지, 임시 데이터 저장에 사용됨) 접근 범위 Local Storage 같은 출처 (Origin, 즉 도메인+프로토콜+포트)가 같다면 모든 탬과 창에서 접근 가능 Session Storage 같은 출처라도 각 탭과 창마다 개별적인 저장소 가짐 다른 탭에서 접근 불가 활용 예제 Local Storage 로그인 정보, 사용자 설정, 테마 설정 등 장기적으로 유지해야하는 데이터 저장 Session Storage 특정 페이지에서만 필요한 임시 데이터 등 일시적인 데이터 저장 사용 방법 (JavaScript) Local Storage // 데이터 저장 localStorage.setItem(\"username\", \"JohnDoe\"); // 데이터 가져오기 console.log(localStorage.getItem(\"username\")); // \"JohnDoe\" Session Storage // 데이터 저장 sessionStorage.setItem(\"sessionUser\", \"JaneDoe\"); // 데이터 가져오기 console.log(sessionStorage.getItem(\"sessionUser\")); // \"JaneDoe\"",
    "tags": "javascript",
    "url": "/javascript/2025-02-04-storage/"
  },{
    "title": "[TIL] JS 화살표함수, 고차함수, DOM, Event",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #9 📅 작성일: 2025-02-03 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 JavaScript 함수 함수 표현식 화살표 함수 this 바인딩 고차함수 (map, filter, reduce) 구조분해 할당 JavaScript DOM, Event 🍎 오늘의 문제 상황 GitHub Pages에서 배포한 웹사이트(여행지 이상형 월드컵)의 OG(Open Graph) 태그가 Slack에서 공유할 때만 미리보기 이미지가 표시되지 않는 문제 발생 노션에서는 정상 표시됨 Slack 개발자 도구 Network 탭에는 200 OK 정상 응답 Metatags.io에서도 OG이미지 정상적으로 뜸 ?v=2 캐시 우회 추가했지만 여전히 안나옴 Slack이 OG캐시를 유지하여, 기존 데이터를 삭제하지 않음.. OG 이미지 파일 크기가 커서 Slack이 불러오지 못했을 수도 있음 해결 과정 OG 이미지 크기 줄이기 magick London.avif -resize 1200x630 -quality 80 London.jpg GitHub raw.githubusercontent.com 대신 외부 이미지 호스팅 사용 Slack 캐시 강제 우회 (?v=2 추가) Slack에서 직접 OG 캐시 삭제 요청 Slack에서 /collapse → /expand 명령어를 입력하면 미리보기를 다시 불러옴 🦄 느낀 점 이미지를 작은 것을 쓰는걸 우선적으로 생각해야 겠다. 1MB 이하로! 덕분에 magick을 설치하고 배우게 되어서 앞으로 이미지 사이즈 줄이는 것을 쉽게 할 수 있을 것 같다. Slack과 카카오톡은 캐싱을 강하게 하는 것 같다. Slack API까지 활용하는 것은 못했지만, 다음에 기회가 된다면 해보겠다. 🐬 깃블로그 정리 [JavaScript 함수] (https://nan0silver.github.io/miscellaneous/2025-01-30-js-function/) [여행지 이상형 월드컵] (https://programmersaibe-nahyun.github.io/TravelWorldcupGame/)",
    "tags": "TIL JavaScript til",
    "url": "/til/2025-02-03-til/"
  },{
    "title": "[JavaScript] 함수",
    "text": "함수 (function) 화살표 함수 고차 함수 (map, filter, reduce) 구조 분해 할당 함수 (function) 함수 선언 function으로 선언 호이스팅 (hoisting) JavaScript에서 변수, 함수 선언, 클래스 등의 선언이 코드 실행 전에 메모리에 미리 할당되는 현상 코드에서 선언이 끌어올려진(hoisted) 것처럼 동작 변수 타입 선언 Hoisting 초기화 여부 선언 전 접근 var ✅ O ✅ (undefined) ✅ 가능 (undefined 반환) let ✅ O ❌ (TDZ 존재) ❌ ReferenceError const ✅ O ❌ (TDZ 존재) ❌ ReferenceError 함수 선언 이전에 호출이 가능 function welcomeMessage(username) { return \"Hi, ${username}!\"; } console.log(welcomeMessage(\"Lily\")); 함수 표현식 이름이 없는 함수를 만들어 변수에 할당하여 정의 호이스팅되지 않으므로, 함수 정의 이후에만 호출 가능 화살표 함수 ES6에서 도입된 간결한 함수 표현 방식 //ex1 const welcomeMessage = (username) =&gt; \"Hi, ${username}!\"; console.log(welcomeMessage(\"Lily\")); //ex2 const calculateArea = (width, height) =&gt; { let area = width * height; return area; }; console.log(calculateArea(5, 10)); // 출력: 50 함수 표현식보다 간결하게 작성 가능함 this 바인딩이 화살표 함수의 정의 위치에서 고정되는 특성을 가짐 this 바인딩 (Binding) this 키워드가 특정 실행 문맥(Excution Context)에서 어떤 객체를 가리키는지 결정되는 과정 JavaScript에서 this는 어떻게, 어디서 호출되었느냐에 따라 값이 달라짐 전통적인 함수와 화살표 함수의 this 바인딩 방식이 다름 전통적인 함수 호출 맥락에 따라 this가 변경될 수 있음 화살표 함수 this가 고정되어 예상치 못한 this의 문제를 방지함 기본적인 this 바인딩 규칙 호출 방식 this가 가리키는 대상 일반 함수 호출 window (브라우저) 또는 undefined (strict mode) 메서드 호출 (객체 안에서) 해당 객체 생성자 함수 새로 생성된 인스턴스 call, apply, bind 사용 명시적으로 지정된 객체 화살표 함수 부모(외부) 스코프의 this 예시 //일반 함수 호출 function showThis() { console.log(this); } showThis(); //브라우저: window, strict mode: undefined //화살표 함수 const user2 = { name: \"Lily\", greet: function() { const arrow = () =&gt; { console.log(this.name); }; arrow(); } }; user2.greet(); //\"Lily\" ``` 고차 함수 map 배열의 각 요소를 변환하여 새로운 배열 생성 원본 배열은 유지 const num = [1, 2, 3]; const mul = num.map((n) =&gt; n * 10); console.log(mul); //[ 10, 20, 30 ] filter 배열에서 조건에 맞는 요소만 반환하여 새로운 배열을 생성 원본 배열은 유지 const words = [\"apple\", \"banana\", \"avocado\", \"cherry\", \"apricot\"]; const aWords = words.filter((word) =&gt; word.startsWith(\"a\")); console.log(aWords); // [\"apple\", \"avocado\", \"apricot\"] reduce 배열의 모든 요소를 순회하며 누적하여 단일 값(accumulator) 생성 초기값 설정 가능 집계 연산에 유용 const numbers = [1, 2, 3, 4, 5]; const product = numbers.reduce((acc, num) =&gt; acc * num, 1); console.log(product); // 120 구조 분해 할당 배열 구조 분해 할당 배열을 개별 변수로 분해 가능 스프레드 연산자(...)로 나머지 요소 처리 가능 const [x, y, ...remaining] = [10, 20, 30, 40, 50]; console.log(x, y, remaining); // 10 20 [30, 40, 50] 객체 구조 분해 할당 객체에서 속성을 변후로 추출 가능 기본값 설정 가능 const { brand, model, year = 2023 } = { brand: \"Tesla\", model: \"Model S\" }; console.log(brand, model, year); // Tesla Model S 2023 중첩된 객체의 속성도 분해하여 사용 가능 const person = { info: { firstName: \"Alice\", lastName: \"Johnson\", }, age: 28, }; const { info: { firstName, lastName }, age, } = person; console.log(firstName, lastName, age); // Alice Johnson 28 함수에서 구조 분해 활용 function displayCar({ brand, model, year }) { console.log(`The car is a ${year} ${brand} ${model}`); } displayCar({ brand: \"Toyota\", model: \"Corolla\", year: 2022 }); // The car is a 2022 Toyota Corolla",
    "tags": "javascript",
    "url": "/javascript/2025-01-30-js-function/"
  },{
    "title": "[JAVA] Generic",
    "text": "Generic이란? Generic의 장점 Generic 사용법 Generic이란? 클래스나 메서드에서 사용할 데이터 타입을 지정하지 않고, 나중에 사용할 때 타입을 결정하는 기능 하나의 값이 여러 다른 데이터 타입들을 가질 수 있도록 하는 방법 클래스 내부에서 지정하는 것이 아닌, 외부에서 사용자에 의해 지정되는 것을 의미 specific 타입을 미리 지정해주는 것이 아닌 필요에 의해 지정할 수 있도록 하는 generic 타입 제네릭을 사용하면 코드의 재사용성을 높이고, 타입 안정성을 보장할 수 있음 ArrayList&lt;T&gt;, HashMap&lt;K, V&gt;같은 자바 컬렉션 프레임워크에서 많이 사용됨 Generic의 장점 타입 안정성 (Type Safety) 보장 제네릭을 사용하면 컴파일 시점에 타입을 검사해서 타입 오류 방지 가능 예를 들어, ArrayList에 String만 저장하도록 지정하면 다른 타입을 추가하는 실수를 막을 수 있음 형변환(Casting) 불필요 제네릭을 사용하면 클래스 외부에서 타입을 지정해주기 때문에 따로 타입을 체크하고 변환할 필요 없음 관리하기 편함 코드의 재사용성 증가 같은 로직을 다양한 데이터 타입에 대해 사용할 수 있어 코드의 중복을 줄일 수 있음 Generic 사용법 import java.util.ArrayList; public class WithGenerics { public static void main(String[] args) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); //제네릭 사용 //ArrayList list = new ArrayList(); 제네릭 미사용 list.add(\"Hello\"); //list.add(123); 오류 발생 (타입 안정성 보장) //제네릭을 사용하지 않으면 오류 발생 X -&gt; 문제 발생 가능 String str = list.get(0); //형변환 없이 바로 사용 가능 System.out.println(str); } } 제네릭 클래스 만들기 // 제네릭 클래스 선언 (T는 타입 매개변수) class Box&lt;T&gt; { private T value; public void setValue(T value) { this.value = value; } public T getValue() { return value; } } public class GenericExample { public static void main(String[] args) { Box&lt;String&gt; stringBox = new Box&lt;&gt;(); //String으로 구체적인 타입 지정 stringBox.setValue(\"Hello\"); System.out.println(stringBox.getValue()); Box&lt;Integer&gt; intBox = new Box&lt;&gt;(); intBox.setValue(100); System.out.println(intBox.getValue()); } } 제네릭 메서드 만들기 class Util { // 제네릭 메서드 선언 public static &lt;T&gt; void printData(T data) { System.out.println(data); } } public class GenericMethodExample { public static void main(String[] args) { Util.printData(\"Hello\"); // String 타입 Util.printData(123); // Integer 타입 Util.printData(3.14); // Double 타입 } } 제네릭 타입 제한 (Bounded Type Parameter) // Number를 상속받은 타입만 사용 가능 (Integer, Double 등) class NumberBox&lt;T extends Number&gt; { private T number; public void setNumber(T number) { this.number = number; } public T getNumber() { return number; } } public class BoundedGenericExample { public static void main(String[] args) { NumberBox&lt;Integer&gt; intBox = new NumberBox&lt;&gt;(); intBox.setNumber(100); System.out.println(intBox.getNumber()); NumberBox&lt;Double&gt; doubleBox = new NumberBox&lt;&gt;(); doubleBox.setNumber(3.14); System.out.println(doubleBox.getNumber()); // NumberBox&lt;String&gt; strBox = new NumberBox&lt;&gt;(); // 오류 발생 (String은 Number가 아님) } } 와일드카드 (? - 제네릭 타입 미지정) 특정 타입을 제한하지 않고 유연하게 사용하고 싶은 경우 import java.util.ArrayList; import java.util.List; class WildcardExample { public static void printList(List&lt;?&gt; list) { // 와일드카드 사용 for (Object obj : list) { System.out.println(obj); } } public static void main(String[] args) { List&lt;String&gt; stringList = new ArrayList&lt;&gt;(); stringList.add(\"Apple\"); stringList.add(\"Banana\"); List&lt;Integer&gt; intList = new ArrayList&lt;&gt;(); intList.add(1); intList.add(2); printList(stringList); // 가능 printList(intList); // 가능 } }",
    "tags": "java",
    "url": "/java/2025-01-29-generic/"
  },{
    "title": "[Etc] TDD (Test-Driven Development, 테스트 주도 개발)",
    "text": "TDD란? TDD의 주요 과정 TDD의 장점 TDD 예제 (Java) TDD VS 전통적인 개발 방식 TDD가 필요한 경우 TDD의 단점 xUnit TDD (Test-Driven Development)란? 테스트 주도 개발 소프트웨어 개발 방법론 중 하나로, 테스트 코드를 먼저 작성한 후 실제 기능을 구현하는 방식 테스트 먼저, 코드 작성 나중! 짧은 개발 주기의 반복에 의존하는 개발 프로세스 애자일 방법론 중 하나인 eXtream Programming(XP)의 “Test-First” 개념에 기반을 둔 단순한 설계를 중요시함 eXtream Programming(XP) 미래에 대한 예측을 최대한 하지 않고, 지속적으로 프로토타입을 완성하는 애자일 방법론 중 하나 추가 요구사항이 생기더라도, 실시간으로 반영할 수 있음 TDD의 주요 과정 Red-Green-Refactor 세 단계 반복 1️⃣ Red (실패하는 테스트 작성) 구현할 기능에 대한 테스트 코드 작성 실제 기능이 이 시점에서는 없기 때문에 테스트는 실패 빨간색 = 실패 2️⃣ Green (코드 작성 후 테스트 통과) 테스트를 통과할 최소한의 코드만 작성 코드가 정상적으로 동작하여 테스트가 성공하면 다음 단계로 넘어감 초록색 = 성공 3️⃣ Refactor (리팩토링) 코드의 중복을 제거하고 더 나은 구조로 개선 테스트를 다시 실행하여 리팩토링 후에도 테스트가 성공하는지 확인 성능 개선, 코드 가독성 높이기 TDD의 장점 버그 감소 미리 테스트를 작성하기 때문에 오류를 조기에 발견할 수 있음 리팩토링 용이 테스트 코드가 보장되므로 안심하고 코드를 사용 가능 유지보수성 향상 코드가 변경될 때 기존 기능이 정상적으로 동작하는지 확인 가능 문서 역할 테스트 코드 자체가 기능 명세서 역할을 함 TDD 예제 (Java) 1. 실패하는 테스트 작성 import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.*; public class CalculatorTest { @Test void testAddition() { Calculator calc = new Calculator(); assertEquals(5, calc.add(2,3)); } } 현재 Calculator 클래스와 add() 메서드가 없어서 테스트 실패 2. 최소한의 코드 작성 (테스트 통과) public class Calculator { public int add (int a, int b) { return a+b; } } 이제 테스트 실행하면 성공! 3. 리팩토링 코드가 복잡한 경우 성능 최적화나 코드 구조 개선 가능 TDD VS 전통적인 개발 방식 구분 전통적인 개발 방식 TDD 순서 기능 구현 → 테스트 작성 테스트 작성 → 기능 구현 목적 기능 개발 후 버그 찾기 처음부터 버그 방지 유지보수 테스트 부족 시 리팩토링 어려움 안전한 리팩토링 가능 TDD가 필요한 경우 복잡한 로직이 포함된 코드 알고리즘, 비즈니스 로직 장기적으로 유지보수해야하는 프로젝트 협업이 필요한 개발 환경 테스트 코드가 문서 역할을 하므로 이해하기 쉬움 TDD의 단점 간단한 코드에는 불필요한 오버헤드가 발생할 수 있음 초기 개발 속도가 느려질 수 있음 xUnit 단위 테스트를 위한 프레임워크 JUnit(for JAVA)을 시작으로 여러 xUnit 프레임워크가 탄생함 xUnit 이름 해당 언어 관련 사이트 CUnit C CUnit CppUnit C++ CppUnit PHPUnit PHP PHPUnit PyUnit Python PyUnit JUnit Java JUnit",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-01-28-tdd/"
  },{
    "title": "[TIL] TDD, Java Generic",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #7 📅 작성일: 2025-01-27 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 TDD (Test-Driven Development) Java Generic JavaScript로 알고리즘 문제 풀기 🍎 오늘의 문제 상황 &amp; 해결 과정 JavaScript 알고리즘 문제 풀이 시 성능 문제 배열을 다루는 문제에서 O(n^2) 복잡도를 가지는 코드가 시간 초과 오류를 발생시켰다. 해결: Map 자료구조를 활용하여 O(n)으로 최적화하고, 테스트 케이스를 통해 성능을 검증했다. 🦄 느낀 점 TDD를 활용해 작은 프로젝트를 해보고 싶다. 알고리즘 문제에서 성능을 고려하며 자료구조를 잘 선택해야겠다. 🐬 깃블로그 정리 [TDD] (https://nan0silver.github.io/miscellaneous/2025-01-28-tdd/) [Java Generic] (https://nan0silver.github.io/java/2025-01-29-generic/)",
    "tags": "TIL Java til",
    "url": "/til/2025-01-27-til/"
  },{
    "title": "[JavaScript] 단축 평가",
    "text": "단축 평가란? 단축 평가 동작 방식 단축 평가 활용 예시 주의사항 단축 평가 (Short-circuit evaluation) 논리 연산자 (&amp;&amp;, ||) 를 평가할 때, 결과를 미리 결정할 수 있다면 나머지 표현식을 평가하지 않고 곧바로 결과를 반환하는 것 &amp;&amp; (AND) 연산자: 두 피연산자가 모두 true 일 때만 true 를 반환합니다. || (OR) 연산자: 두 피연산자 중 하나라도 true 이면 true 를 반환합니다. 논리 연산자의 동작 방식을 이용하여 불필요한 연산을 줄이고, 코드 실행 효율성을 높임. &amp;&amp; (AND) 와 || (OR) 연산자를 조건문 없이 사용하는 코드를 가능하게 함 단축 평가 동작 방식 1. &amp;&amp; (AND) 연산자 &amp;&amp; 연산자는 좌항부터 평가 좌항이 false 라면: &amp;&amp; 연산의 결과는 항상 false 이므로, 우항을 평가하지 않고 곧바로 false 를 반환 좌항이 true 라면: &amp;&amp; 연산의 결과는 우항에 따라 결정되므로, 우항을 평가하고 그 결과를 반환 console.log(false &amp;&amp; true); //falsk //(좌항이 false이므로 우항을 평가하지 않고 false 반환) console.log(true &amp;&amp; false); //false //(좌항이 true이므로 우항을 평가하여 false 반환) console.log(true &amp;&amp; true); //true //(좌항이 true이므로 우항을 평가하여 true 반환) 2. || (OR) 연산자 || 연산자는 &amp;&amp; 연산자와 마찬가지로 좌항부터 평가 좌항이 true 라면: || 연산의 결과는 항상 true 이므로, 우항을 평가하지 않고 곧바로 true 를 반환 좌항이 false 라면: || 연산의 결과는 우항에 따라 결정되므로, 우항을 평가하고 그 결과를 반환 console.log(true || false); //true //(좌항이 true이므로 우항을 평가하지 않고 true 반환) console.log(false || true); //true //(좌항이 false이므로 우항을 평가하여 true 반환) console.log(false || false); //false //(좌항이 false이므로 우항을 평가하여 false 반환) 단축 평가 활용 예시 1. 객체의 속성에 접근할 때 객체의 속성에 접근하기 전에 객체가 null 또는 undefined 인지 확인하는 코드를 단축 평가로 간결하게 작성 가능 const person = { name: \"Alice\" }; // const person = null; // person이 null인 경우 // 조건문 사용 let name; if (person) { name = person.name; } else { name = \"Unknown\"; } console.log(name); // Alice // 단축 평가 사용 const name2 = person &amp;&amp; person.name; console.log(name2); // Alice (person이 truthy 값이므로 person.name 평가) const person2 = null; const name3 = person2 &amp;&amp; person2.name; console.log(name3); // null (person2가 falsy 값이므로 person2 그대로 반환) // || 연산자를 사용한 기본값 설정 const name4 = person2 || { name: \"Unknown\" }; console.log(name4); // { name: 'Unknown' } (person2가 falsy 값이므로 { name: 'Unknown' } 반환) console.log(name4.name); // Unknown 2. 함수 매개변수에 기본값 설정 함수 매개변수에 기본값을 설정할 때 || 연산자를 사용하여 코드를 간결하게 만들 수 있다. function greet(name) { // 조건문 사용 const userName = name ? name : \"Guest\"; console.log(`Hello, ${userName}!`); } greet(\"Bob\"); // Hello, Bob! greet(); // Hello, Guest! function greet2(name) { // 단축 평가 사용 const userName = name || \"Guest\"; console.log(`Hello, ${userName}!`); } greet2(\"Charlie\"); // Hello, Charlie! greet2(); // Hello, Guest! 3. 조건부 렌더링 (React) React와 같은 UI 라이브러리에서 조건부 렌더링을 구현할 때 단축 평가를 유용하게 사용할 수 있다. function MyComponent({ items }) { return ( &lt;div&gt; {/_ items가 존재하고 배열인 경우에만 목록 렌더링 _/} {items &amp;&amp; Array.isArray(items) &amp;&amp; ( &lt;ul&gt; {items.map((item) =&gt; ( &lt;li key={item.id}&gt;{item.name}&lt;/li&gt; ))} &lt;/ul&gt; )} {/_ items가 없거나 배열이 아닌 경우 메시지 표시 _/} {!items &amp;&amp; &lt;div&gt;No items to display.&lt;/div&gt;} {items || &lt;div&gt;No items to display.&lt;/div&gt;} {/_ || 연산자 사용 _/} &lt;/div&gt; ); } 주의사항 단축 평가는 코드를 간결하게 만들어주지만, 남용하면 코드의 가독성을 해칠 수 있음. 적절한 상황에서 사용하는 것이 중요합니다. &amp;&amp; 와 || 연산자는 boolean 값이 아닌 값도 반환 가능 단축 평가의 반환 값은 마지막으로 평가된 표현식의 결과이다.",
    "tags": "javascript",
    "url": "/javascript/2025-01-27-javascript-short-circuit-evaluation/"
  },{
    "title": "[TIL] JavaScript 단축 평가, Git Actions를 이용한 자동화",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #6 📅 작성일: 2025-01-24 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 javascript 기본 문법 구조 단축 평가 Git Actions를 이용한 자동 Issue 생성 워크플로우 구현 ChatGPT를 백준 공부에 적극 활용 내 코드보다 더 좋은 코드는 어떤 것이고, 어느 부분에서 더 생각할 수 있을지 쉽게 알아갈 수 있었다. 🍎 오늘의 문제 상황 &amp; 해결 과정 Git Actions를 이용한 Issue 생성시, API를 활용하려면 key가 필요했는데, 공개로 키를 올리는 것이 맞지 않는 것 같아서 고민함 ChatGPT를 이용해 GitHub Secrets를 활용해 API Key를 숨겨서 코드 실행 🦄 느낀 점 Git은 그저 코드 저장소라고 생각했는데, 다양한 기능이 있는 것을 보고 재미있었다. ChatGPT를 활용해서 어떤 다른 기능이 있는지 알아보는 재미도 있을 것 같다. 🐬 깃블로그 정리 [단축평가] (https://nan0silver.github.io/miscellaneous/2025-01-27-javascript-short-circuit-evaluation/)",
    "tags": "TIL Java JavaScript Git DevOps til",
    "url": "/til/2025-01-24-til/"
  },{
    "title": "[TIL] git rebase, Java int와 long 구별",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #5 📅 작성일: 2025-01-23 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 git rebase VS git merge Java int 자료형 범위와 long 자료형 범위 한눈에 구별하기 MDN 번역 기여 (오픈소스 기여 방법) 🍎 오늘의 문제 상황 &amp; 해결 과정 백준 java문제를 푸는데 int범위를 넘는 경우를 바로 파악하지 못해서 틀리는 경우가 여러 번 있었다 표현이 다르게 되는 경우 자꾸 틀리는 것이기 때문에 정확하게 이해하고 앞으로 틀리지 않게 하는 것이 중요했다. ChatGPT를 통해 정확히 알아보고 java의 int범위와 long범위를 정확하게 이해하게 되었다. 🦄 느낀 점 대충 빠르게 넘어가려고 하면 나중에 문제가 될 수 있다.. 작은 것이라도 정확하게 익히고 조금은 여유를 가지면서 공부할 필요가 있을 것 같다. 🐬 깃블로그 정리 [git rebase] (https://nan0silver.github.io/miscellaneous/2025-01-23-git-rebase/) [java int &amp; long] (https://nan0silver.github.io/java/2025-01-23-int-long/)",
    "tags": "TIL Java Git til",
    "url": "/til/2025-01-23-til/"
  },{
    "title": "[JAVA] int와 long의 차이 ➡️ 범위와 오버플로우 문제 완벽 정리",
    "text": "int와 long의 차이 int와 long의 입력값 연산 결과의 최대값 예상하기 문제를 보고 빠르게 판단하는 팁 int와 long의 차이 자꾸 문제를 풀다 int와 long을 혼동해서 문제를 틀리는 경우가 있어서 완벽 정리하려고 한다. 입력값의 범위와 연산 결과의 최댓값을 기준으로 판단하는 습관을 들여야 함 int와 long의 입력값 int : 약 -2,147,483,648 ~ 2,147,483,648 long : 약 -9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,808 문제에 입력값이 명시되어 있다면 -2,000,000,000 &lt;= N,M &lt;= 2,000,000,000 int는 처리 가능. 하지만 연산 결과를 생각해야 함 범위가 int의 한계와 가깝다면, 입력값은 int로 가능하더라도 연산 결과가 범위를 초과할 수 있기 때문에 long을 사용하는 것이 안전 판단 기준 입력값이 -10^9 ~ 10^9 사이일 경우 단순한 덧셈이나 뺄셈은 int로 처리 가능 곱셈, 제곱 연산, 누적 합계 등은 long이 필요할 수 있음 입력값이 -10^{10} 이상이거나, 결과적으로 큰 숫자가 나올 가능성이 있다면 무조건 long 사용 연산 결과의 최대값 예상하기 문제에서 요구하는 연산 결과 예상하기 예) 누적합 문제 배열의 크기가 1,000,000이고, 각 원소가 최대 10^6이라면, 누적합은 최대 10^12가 될 수 있음 이 경우 int의 범위를 초과하므로 long을 사용해야 함 문제를 보고 빠르게 판단하는 팁 입력 범위 확인 연산의 종류 확인 규칙 만들기 “입력값이 10^9 이상이면 무조건 long으로 처리한다” 테스트 데이터 체크 극단적인 입력값을 대입해보기",
    "tags": "java",
    "url": "/java/2025-01-23-int-long/"
  },{
    "title": "[Git] git rebase",
    "text": "git rebase git rebase VS git merge git rebase 사용법 장점 주의 사항 git rebase Git에서 브랜치의 커밋 히스토리를 재구성할 때 사용하는 명령어로, 현재 브랜치의 기반이 되는 커밋을 변경한다. 브랜치의 시작점을 다른 브랜치의 최신 커밋으로 옮겨서, 변경 이력을 깔끔하게 정리함 이를 통해 브랜치의 히스토리를 “정리(clean)”하거나 최신 상태를 기반으로 변경사항을 다시 적용할 수 있음 ‼️ 실제 동작 방식 main 브랜치가 이렇게 변경되었다. A - B - C (main 최신 상태) 내 feature-branch는 main 브랜치를 기반으로 작업했지만 오랜된 상태임 A - B - (내 변경 사항 X, Y) (feature-branch) ➡️ 이 상태에서 git rebase main을 실행하면 A - B - C - ( 내 변경 사항 X, Y) (rebase된 feature-branch) git rebase의 필요성 1. Base 브랜치가 변경될 때 Conflict 최소화 여러 개발자가 동시에 작업하는 경우, 메인 브랜치(main or develop)의 최신 커밋을 반영하지 않으면 충돌이 발생할 가능성이 높다/ Rebase를 하면, 최신 코드 기준으로 브랜치 변경 이력을 재구성할 수 있어, Merge conflict를 최소화할 수 있다. ✅ 예제 : Rebase없이 충돌 발생 feature-branch에서 작업을 했지만, main 브랜치가 업데이트됨 git merge main을 하면 불필요한 merge commit이 생성됨 merge commit이 많아지면 협업시 코드리뷰할 때 이력 파악이 어려워짐 conflict가 날 가능성이 많아짐 ✅ Rebase로 conflict 최소화 git checkout feature-branch git rebase main # → 최신 main 브랜치 기준으로 변경 이력 재구성 ➡️ Rebase를 하면 최신 코드와 충돌을 최소화하면서 깔끔한 커밋 이력 유지 가능 git rebase VS git merge 일반적으로 merge와 같은 목적으로 사용되지만, 다른 방식으로 작동 merge 두 브랜치의 히스토리를 합치면서, 새로운 병합 커밋을 생성 개발이 완료된 브랜치를 병합할 때 주로 사용 두 개의 문서를 그냥 합치기 rebase 한 브랜치의 커밋을 다른 브랜치의 끝으로 옮겨서, 히스토리가 마치 일렬로 정리된 것처럼 보임 불필요한 병합 커밋을 없애고 이력을 깔끔하게 유지 가능 개발 브랜치를 최신 코드로 업데이트 할 때 주로 사용 새로운 버전의 문서 위에 내 작업을 다시 복사해서 붙여넣기 예시 이미지 16d0e75 커밋 아래는 merge 흔적 16d0e75 커밋 위는 rebase로 인한 선형 히스토리 git rebase 사용법 업스트림 브랜치로 리베이스 git swicth -c feature git rebase main feature 브랜치에서 작업한 커밋을들 main 브랜치의 최신 상태를 기반으로 재적용 interactive rebase git rebase -i HEAD~n 마지막 n개의 커밋을 선택적으로 수정하거나 합칠 수 있음 실행하면 편집 모드가 열리며, 옵션을 선택할 수 있음 pick, reword, edit, squash, drop등 장점 히스토리 정리 불필요한 merge 커밋 제거 최신 상태 유지 주의 사항 리베이스 중 충돌 이미 푸시된 브랜치에 리베이스 금지 git pull --rebase 원격 브랜치의 변경 사항을 병합 대신 리베이스로 가져올 때 사용",
    "tags": "git",
    "url": "/git/2025-01-23-git-rebase/"
  },{
    "title": "[TIL] git clone VS fork, Headless CMS, Strapi, 네이밍 컨벤션",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #4 📅 작성일: 2025-01-22 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 git clone VS git fork git clone : 원격 저장소 ➡️ 로컬 저장소 git fork : 원격 저장소 ➡️ 내 원격 저장소 (GitHub 계정) Headless CMS, Strapi 네이밍 컨벤션 케밥 케이스, 카멜 케이스, 스네이크 케이스, 파스칼 케이스 🍎 오늘의 문제 상황 &amp; 해결 과정 git clone 후 파일을 생성하고 git add과 git commit 후, git push를 하면 다른 사람의 깃저장소에 저장되는지 궁금했음 git fork와 git clone의 개념을 이해하려고 노력했다. ChatGPT를 통해 차이점을 물어보고 모르는 것을 계속 물어보며 이해했다. 깃블로그에 정리! 🦄 느낀 점 네이밍 컨벤션과 같이 매일 새로운 단어를 배우고 찾아보는 것이 재밋다. git을 매일 열심히 썼는데 쓰는 것만 쓰다보니 다른 부분은 잘 몰랐던 것 같아서 배우고 싶었는데, branch와 merge를 제대로 배운 것 같아서 좋다. 🐬 깃블로그 정리 [Naming Convention] (https://nan0silver.github.io/miscellaneous/2025-01-22-naming-convention/) [git clone VS git fork] (https://nan0silver.github.io/miscellaneous/2025-01-22-git-clone-fork/)",
    "tags": "TIL Git til",
    "url": "/til/2025-01-22-til/"
  },{
    "title": "[Etc] Naming Convention",
    "text": "Naming Convention이란? 케밥 케이스 (Kebab-case) 카멜 케이스 (camelCase) 스네이크 케이스 (snake_case) 파스칼 케이스 (PascalCase) 선택 기준 Naming Convention이란? 프로그래밍에서 변수, 함수, 클래스 이름 등을 작성하는 규칙 1. 케밥 케이스 (Kebab-case) 단어를 하이픈(-)으로 구분하며, 모든 문자를 소문자로 작성 모양이 케밥을 닮았다고 해서 붙여진 이름 특징 가독성이 좋음 HTML, CSS에서 자주 사용됨 언어에 따라 변수나 함수이름으로는 사용할 수 없는 경우도 있음 하이픈이 연산자로 해석될 수 있어서 예시 /* CSS 클래스 이름 */ .button-primary { background-color: blue; color: white; } /* 파일 이름 */ my-awesome-file.js 2. 카멜 케이스 (camelCase) 첫 단어는 소문자로 시작하고, 이후 단어의 첫 글자를 대문자로 작성 이름이 낙타의 등처럼 튀어나온 형태를 닮아서 붙인 이름 특징 JavaScript, Java, C#, Python 등에서 변수와 함수 이름으로 자주 사용됨 대문자 없이 단어를 연결해 코드 가독성을 높이는 데 도움을 줌 예시 // JavaScript 변수와 함수 let userName = \"Alice\"; function getUserData() { return userName; } 3. 스네이크 케이스 (snake_case) 단어를 밑줄(_)로 구분하며, 모든 문자를 소문자로 작성 뱀이 기어다니는 모양을 닮아서 붙여진 이름 특징 Python, SQL, Ruby, C, C++, PHP, JSON 데이터 스키마에서 변수와 함수 이름으로 자주 사용됨 예시 # Python 변수 이름 user_name = \"Alice\" # Python 함수 이름 def get_user_data(): return user_name 4. 파스칼 케이스 (PascalCase) 각 단어의 첫 글자를 대문자로 작성 카멜 케이스와 비슷하지만 첫 단어도 대문자 특징 Java, TypeScript등의 클래스 이름과 타입 이름으로 자주 사용됨 예시 // Java 클래스 이름 public class UserAccount { private String UserName; public UserAccount(String userName) { this.UserName = userName; } } 선택 기준 언어/환경의 표준에 따라 케이스를 선택 JavaScript, Java camelCase (변수/함수) PascalCase (클래스) Python snake_case CSS/HTML kebab-case 팀 또는 프로젝트의 코딩 컨벤션에 따라 일관성 유지가 중요 (가독성을 위해)",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-01-22-naming-convention/"
  },{
    "title": "[Git] git clone VS git fork",
    "text": "git clone git fork 주요 차이점 정리 워크플로우 실전 예시 git clone 역할 원격 저장소를 로컬 컴퓨터에 복제 작업 대상 원격 저장소 특징 저장소의 완전한 복사본(전체 커밋 내역, 브랜치 등)을 가져옴 복제 후, 원격 저장소가 자동으로 origin이라는 이름으로 연결됨 로컬에서 작업한 내용을 원격 저장소에 반영하려면 push사용 동작 방식 Git 저장소 초기화 (git init) 새로 생성된 폴더는 Git 저장소로 설정됨 .git 디렉터리가 자동으로 생성됨 원격 저장소 설정 (git remote add origin) 복제한 원격 저장소가 자동으로 origin이라는 이름으로 연결됨 로컬에서 원격 저장소와 동기화(push, pull)를 가능하게 함 브랜치 체크아웃 기본 브랜치(main or master)의 최신 상태가 복제됨 이 브랜치는 로컬 저장소로 가져와 자동으로 체크아웃됨 파일 다운로드 원격 저장소에 있는 모든 파일과 폴더가 로컬 디렉토리에 다운로드됨 git clone 명령을 실행하면, 다운받은 폴더는 자동으로 Git 저장소로 초기화되고, 원격 저장소와도 연결된 상태임 git init이나 git remote add를 실행할 필요가 없음 git fork 역할 원격 저장소를 자신의 원격 계정으로 복제 작업 대상 GitHub/GitLab 계정 상의 저장소 특징 원본 저장소의 복사본이 내 계정의 원격 저장소로 생성됨 내 계정에서 관리할 수 있는 원격 저장소를 만든다는 것이 핵심 원본 저장소와 연결은 유지되지만, 독립적인 저장소로 사용됨 추가 단계 포크 후, 로컬에 복사하려면 git clone을 사용해야 함 사용 시기 오픈소스 프로젝트에 기여할 때, 원본 저장소를 수정하지 않고 내 계정에서 관리 가능한 복사본을 만들어야 할 때 사용 Pull Request를 보내기 위한 준비 단계로 사용 주요 차이점 정리 특징 git clone git fork 복제 대상 원격 저장소 ➡️ 로컬 저장소 원격 저장소 ➡️ 내 원격 저장소 저장소 위치 로컬에서 작업 내 계정의 원격 저장소에서 작업 연결된 원격 저장소 origin으로 원본 저장소 연결 내 계정의 원격 저장소 (원본 저장소는 upstream으로 연결 가능) 사용 목적 로컬에서 작업하고 원본 저장소에 반영 내 계정에서 독립적으로 원격 저장소 관리 주로 사용 상황 협업 프로젝트에 바로 참여 오픈소스 프로젝트에 기여 (Pull Request 준비) 워크플로우 일반적으로 Fork → Clone → Push → Pull Request가 오픈 소스 협업의 표준 워크플로우 Fork 저장소 생성 먼저, 해당 저장소를 Fork하여 내 계정으로 복사 GitHub에서 기여하고자 하는 저장소 페이지로 이동 우측 상단의 Fork 버튼을 클릭 그러면 내 계정에 저장소 복사본이 생성됨 Fork 저장소 Clone Fork된 저장소를 로컬로 복제 git clone https://github.com/your-username/repository.git your-username은 GitHub 계정 이름으로 대체 Clone이 완료되면 로컬 환경에서 작업 가능 원본 저장소 추가 (선택 사항) 원본 저장소와 동기화를 유지하려면, 원본 저장소를 upstream으로 추가 git remote add upstream https://github.com/original-owner/repository.git original-owner는 원본 저장소의 소유자 이름으로 대체 git remote -v 명령을 사용하여 설정이 제대로 되었는지 확인 가능 로컬에서 작업 새로운 파일을 추가하거나 수정 후 커밋 git add . git commit -m \"Add new feature\" Fork된 저장소에 Push 로컬에서 작업한 내용을 자신의 Fork 저장소에 Push git push origin main 여기서 main은 사용하는 브랜치 이름 Pull Request 생성 GitHub로 돌아가, Fork된 저장소에서 원본 저장소로 Pull Request를 생성 내 Fork 저장소 페이지에서 “Contribute” 버튼 클릭. “Open Pull Request” 버튼 클릭. 변경 사항에 대한 설명을 작성하고 Pull Request를 제출합니다. ✅ 요약 다른 사람의 저장소에 기여하기 위한 전체 과정 Fork: 저장소를 내 계정으로 복제. Clone: 내 계정에 있는 저장소를 로컬로 복제. 원본 저장소 추가: 원본 저장소와 동기화(선택 사항). 작업: 로컬에서 파일 수정 및 커밋. Push: 작업 내용을 내 계정 저장소로 업로드. Pull Request: 원본 저장소에 변경 사항을 제안. 실전 예시 git clone만 사용하는 경우 팀 프로젝트에서 기존 저장소를 복제하여 작업 후, 원본 저장소에 바로 push git clone &lt;repository-url&gt; cd &lt;repository-folder&gt; # 작업 후 git push origin &lt;branch-name&gt; git fork와 git clone을 함께 사용하는 경우 오픈소스 프로젝트에서 자신의 계정으로 fork 후, 로컬에서 복제하여 작업 후 pull request 보냄 # GitHub에서 Fork한 후 git clone &lt;forked-repository-url&gt; cd &lt;repository-folder&gt; # 원본 저장소를 upstream으로 추가 git remote add upstream &lt;original-repository-url&gt; git fetch upstream # 작업 후, 내 계정 원격 저장소에 Push git push origin &lt;branch-name&gt;",
    "tags": "git",
    "url": "/git/2025-01-22-git-clone-fork/"
  },{
    "title": "[TIL] CSS position, flex, bootstrap, responsive/react…",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #3 📅 작성일: 2025-01-21 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 이번에는 CSS 레이아웃의 핵심 개념들과 프론트엔드 개발자가 자주 접하는 실전 용어들에 대해 집중적으로 학습했다. 📌 CSS Position, Flex, Bootstrap position 속성을 통해 요소의 정적/상대/절대 위치 설정 방식 이해 (static, relative, absolute, fixed, sticky 각각의 차이점 체감) Flexbox 처음 강의로만 접했을 땐 직관적으로 와닿지 않았지만, Flexbox Froggy 같은 게임을 하며 눈으로 보고 손으로 익히는 학습 방식이 큰 도움이 됨 justify-content, align-items, flex-grow 등 실무에서 자주 쓰이는 속성들을 자연스럽게 체득 Bootstrap 실습 문서를 보며 Grid 시스템과 반응형 유틸리티 클래스 실습 기존에 막연했던 .container, .row, .col-md-* 구조를 HTML에 적용해보며 정확하게 개념화 💡 프론트엔드 개발자 관점에서 이해한 용어들 Responsive vs Reactive responsive: 디바이스 크기에 따라 콘텐츠가 적절히 조절되는 UI (ex. 반응형 웹) reactive: 사용자 입력이나 데이터 변화에 실시간 반응하는 시스템 설계 (ex. 리액티브 프로그래밍, RxJS) PWA (Progressive Web App) 웹 앱이 네이티브 앱처럼 동작하도록 만드는 기술 대표적 특징: 오프라인 지원, 홈 화면 추가, 빠른 로딩 속도 실제로 어떤 앱들이 PWA를 도입하고 있는지 찾아보며 가능성과 필요성을 체감 🍎 오늘의 문제 상황 &amp; 해결 과정 🤔 문제 상황 처음 flex를 강의로 배울 때는 개념이 잘 들어오지 않았다. justify-content나 flex-direction처럼 말은 쉬워보이는데, 실제로 어떤 결과를 만드는지 바로 이해되지 않았다. 🛠️ 해결 과정 실행해보며 학습: 직접 HTML과 CSS 파일을 만들어 이것저것 시도해봄 Flexbox Froggy 게임: 문제를 풀며 개념을 시각적으로 체득 → \"아 이런 구조가 되는 거구나\"라는 감이 생김 ChatGPT로 예시 생성: 2열 레이아웃을 flex로 구현해줘 같은 요청을 통해 다양한 예시 코드를 받아 실습에 활용 🦄 느낀 점 CSS는 개념보다 체험이 먼저다. 책이나 강의만으로는 막연하게 느껴지던 것들이, 직접 화면에서 변화하는 모습을 보면서 확실히 이해됐다. 실무에서 나오는 단어들은 그냥 넘기지 말자. 현직 개발자들이 무심코 던지는 단어들 — 예: “PWA 괜찮은데요”, “이건 responsive하게 짜야죠” — 이 안에 수많은 기술 개념이 숨어 있다는 걸 느꼈다. → 익숙하지 않더라도 하나하나 찾아보고 내 것으로 만드는 습관이 중요하다. 📌 마무리 요약 💬 프론트엔드는 ‘보이는 것’이 전부가 아니다. 직접 만들고, 부딪히고, 튜닝하면서 체득하는 과정이 핵심이다. 🐬 깃블로그 정리 [responsive / reactive의 의미] (https://nan0silver.github.io/miscellaneous/2025-01-20-responsive/) [CSS Flex] (https://nan0silver.github.io/miscellaneous/2025-01-21-css-flex/)",
    "tags": "TIL JavaScript CSS til",
    "url": "/til/2025-01-21-til/"
  },{
    "title": "[CSS] CSS Flex",
    "text": "Flex(Flexbox) 주요 Flexbox 속성 20개 예제: 통합 코드 flex를 이용한 게임 Flex(Flexbox) Flexbox(Flexible Box Layout Module) 컨테이너 내의 아이템 간 공간 배분과 정렬 기능을 제공하는 1차원 레이아웃 모델 주로 행이나 열 단위로 작동하며, 복잡한 계산 없이도 요소들의 크기와 순서를 유연하게 배치할 수 있음 장점 복잡한 레이아웃을 간단하게 구현 컨테이너 내 요소의 크기가 불명확하거나 동적인 경우에도 효과적으로 대응 요소의 순서를 CSS로 변경할 수 있어 반응형 디자인에 유용 float나 Position을 사용할 때보다 코드가 간결해짐 주요 Flexbox 속성 CSS3 Flexbox에서 가장 많이 사용되는 20개의 속성(property)을 아래에 정리했습니다. 각각의 속성에 대한 간략한 설명과 함께 예제 코드를 제공합니다. 1. display: flex Flexbox를 활성화. .container { display: flex; } 2. flex-direction 주축의 방향 설정. row (기본값), row-reverse, column, column-reverse. .container { flex-direction: column; } 3. justify-content 주축에서 항목 정렬. flex-start, flex-end, center, space-between, space-around, space-evenly. .container { justify-content: space-between; } 4. align-items 교차축에서 항목 정렬. stretch (기본값), flex-start, flex-end, center, baseline. .container { align-items: center; } 5. align-content 여러 줄에서 교차축 정렬. stretch, flex-start, flex-end, center, space-between, space-around. .container { align-content: space-around; } 6. flex-wrap 항목이 컨테이너를 초과하면 줄 바꿈 여부. nowrap (기본값), wrap, wrap-reverse. .container { flex-wrap: wrap; } 7. flex 개별 항목의 크기 설정 (약어). flex: grow shrink basis; .item { flex: 1 1 auto; } 8. flex-grow 남은 공간을 차지할 비율. 기본값: 0. .item { flex-grow: 2; } 9. flex-shrink 공간 부족 시 줄어드는 비율. 기본값: 1. .item { flex-shrink: 0; } 10. flex-basis 항목의 기본 크기 설정. .item { flex-basis: 100px; } 11. order 항목의 배치 순서. 기본값: 0. .item { order: 2; } 12. gap 항목 간 간격 설정. .container { gap: 20px; } 13. row-gap 가로축 항목 간 간격 설정. .container { row-gap: 15px; } 14. column-gap 세로축 항목 간 간격 설정. .container { column-gap: 10px; } 15. align-self 개별 항목의 교차축 정렬 설정. auto, flex-start, flex-end, center, baseline, stretch. .item { align-self: flex-end; } 16. min-width 항목의 최소 너비. .item { min-width: 100px; } 17. max-width 항목의 최대 너비. .item { max-width: 200px; } 18. min-height 항목의 최소 높이. .item { min-height: 50px; } 19. max-height 항목의 최대 높이. .item { max-height: 150px; } 20. place-content justify-content와 align-content를 한 번에 설정. center, stretch, space-between 등. .container { place-content: center; } 예제: 통합 코드 &lt;div class=\"container\"&gt; &lt;div class=\"item\"&gt;Item 1&lt;/div&gt; &lt;div class=\"item\"&gt;Item 2&lt;/div&gt; &lt;div class=\"item\"&gt;Item 3&lt;/div&gt; &lt;/div&gt; &lt;style&gt; .container { display: flex; flex-direction: row; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 10px; height: 300px; } .item { flex: 1 1 100px; align-self: stretch; min-width: 100px; max-width: 300px; } &lt;/style&gt; flex를 이용한 게임 https://flexboxfroggy.com/#ko 다 깼다!",
    "tags": "javascript",
    "url": "/javascript/2025-01-21-css-flex/"
  },{
    "title": "[TIL] CSS의 정의, em, rem, float",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #2 📅 작성일: 2025-01-20 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 이번에는 그동안 ‘대충은 안다’고 생각했던 **CSS의 기본 개념들과 웹의 메타 정보 설정(OG)**에 대해 한층 더 깊이 있게 이해하게 되었다. 🧷 CSS의 정의부터 세세한 단위까지 CSS (Cascading Style Sheets) HTML 구조에 ‘스타일’을 입히는 언어. 눈에 보이는 모든 웹의 디자인과 인터랙션을 담당하는 핵심 기술이다. 단위 차이 – em vs rem em: 부모 요소의 font-size를 기준으로 계산됨. 중첩된 요소에서는 비율이 누적되기 때문에 예측이 어렵다. rem: 루트 요소(html)의 font-size를 기준으로 계산. 전역적으로 일관된 크기 조절이 가능하다. ➤ 실무에서는 대부분 rem을 기준으로 통일하는 추세! float 속성 요소를 좌우로 띄워 배치하는 방식이지만, modern CSS에서는 flexbox나 grid가 대체하고 있다. 다만, 여전히 레거시 코드나 간단한 배치에서는 float이 등장하기도 하므로 이해는 필수. 🌐 웹 OG (Open Graph) SNS에서 링크를 공유했을 때, 썸네일 이미지 / 제목 / 설명이 미리보기로 보이는 기능은 OG 메타태그 덕분이다. 예시: &lt;meta property=\"og:title\" content=\"내 블로그 타이틀\" /&gt; &lt;meta property=\"og:description\" content=\"유익한 개발 인사이트가 가득한 블로그\" /&gt; &lt;meta property=\"og:image\" content=\"https://myblog.com/images/thumbnail.png\" /&gt; &lt;meta property=\"og:url\" content=\"https://myblog.com\" /&gt; SEO뿐 아니라 브랜딩과 클릭 유도에도 중요한 역할을 하므로, 웹 개발 시 꼭 챙겨야 할 부분. 🍎 오늘의 문제 상황 &amp; 해결 과정 🤔 문제 상황 CSS를 평소에 자주 쓰고 있어서 “이 정도는 알지!”라고 생각했지만, 실제로는 em, rem, float, OG 태그와 같은 용어들의 의미와 정확한 사용법을 막연히만 알고 있었다. 🔧 해결 과정 개발 중 우연히 encountered 한 단어들을 그냥 넘기지 않고, 바로바로 정리하고 문서화하는 습관을 시도해봤다. VS Code + Markdown을 사용해서 개념을 정리하고, 블로그에 업로드할 수 있도록 요약까지 해보았다. 결과적으로 단지 “아는 느낌”이 아니라 필요할 때 꺼내쓸 수 있는 지식으로 바뀌었다. 🦄 느낀 점 겉만 아는 것과 속까지 아는 것은 다르다. CSS나 HTML은 쉬운 것처럼 느껴질 수 있지만, 막상 실제로 ‘왜 그렇게 되는지’를 설명하려고 하면 막히는 경우가 많다. 앞으로는 **모르는 개념을 마주쳤을 때 ‘그냥 넘기지 않기’**를 실천하려고 한다. ✍️ “몰랐던 걸 내 언어로 정리하는 순간, 진짜 내 것이 된다.” 📌 Tip: 개발자에게는 ‘검색력’도 중요하지만, “기억에 남게 정리하는 습관”은 더 강력한 무기가 될 수 있다. 🐬 깃블로그 정리 [CSS 기초] (https://nan0silver.github.io/miscellaneous/2025-01-18-css/) [CSS Float] (https://nan0silver.github.io/miscellaneous/2025-01-19-css-float/)",
    "tags": "TIL JavaScript CSS til",
    "url": "/til/2025-01-20-til/"
  },{
    "title": "[Etc] Responsive VS Reactive",
    "text": "Responsive Reactive Responsive VS Reactive 결합된 활용 Responsive (반응형) Responsive는 주로 UI/UX 디자인이나 프론트엔트 개발에서 사용되는 개념 애플리케이션 또는 웹 페이지가 화면 크기, 해상도, 디바이스 특성에 따라 적절히 변하도록 설계된 것을 의미 특징 주요 초점 레이아웃 및 디자인이 다양한 화면 환경(데스크톱, 태블릿, 모바일)에 적응 기술 주로 CSS, Flexbox, Grid, Viewport 등을 사용 목적 사용자 경험을 개선하고, 어떤 장치에서도 보기 좋은 디자인을 제공 예시 웹사이트 반응형 디자인 큰 화면에서는 여러 열(column)을 보여주고, 작은 화면에서는 한 열로 정렬 이미지와 텍스트 사이즈가 디바이스 크기에 따라 자동으로 조정 부트스트랩 (Bootstrap) col-m-6와 같은 클래스 이름을 사용하여 화면 크기에 따라 레이아웃을 조정 Reactive (반응형) Reactive는 주로 프로그래밍 패러다임과 관련이 있음 시스템이 변화를 감지하고 즉각적으로 동작을 수행하는 것을 의미 특징 주요 초점 데이터와 상태의 변화에 따라 UI가 자동으로 업데이트 기술 Reactive Programming과 관련된 라이브러리와 프레임워크를 활용 ex) RxJS, React, Vue, Svelte 등 목적 상태 관리와 데이터 흐름을 단순화하고, 사용자 입력 또는 데이터 변화에 실시간으로 반응 예시 React.js에서의 State변화 사용자가 버튼을 클릭하면 상태가 변경되고, 해당 상태에 따라 UI가 즉각적으로 업데이트 import React, { useState } from \"react\"; function Counter() { const [count, setCount] = useState(0); return ( &lt;div&gt; &lt;p&gt;Count: {count}&lt;/p&gt; &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increase&lt;/button&gt; &lt;/div&gt; ); } RxJS 스트림 데이터를 스트림(stream) 형태로 처리하고, 데이터 변경에 실시간으로 반응 import { fromEvent } from \"rxjs\"; const button = document.getElementById(\"myButton\"); const clicks = fromEvent(button, \"click\"); clicks.subscribe(() =&gt; console.log(\"Button clicked!\")); Responsive VS Reactive 측면 Responsive Reactive 적용 범위 주로 UI/UX와 레이아웃 디자인 상태 관리와 데이터 흐름 목적 화면 크기에 따른 레이아웃 및 스타일 변경 데이터 및 상태 변경에 따른 즉각적인 반응 사용 기술 CSS, Flexbox, Grid 등 React, RxJS, Vue 등 상태 기반 프레임워크 초점 디바이스별 최적화된 레이아웃 제공 데이터의 흐름과 UI 동기화 예시 모바일에서 1열 레이아웃, 데스크톱에서 3열 레이아웃 버튼 클릭 시 상태 업데이트 후 UI 리렌더링 결합된 활용 Responsive와 Reactive는 함께 사용될 때 더 큰 효과를 발휘한다. 예를 들어, React.js로 만들어진 SPA(Single Page Application)에서 반응형 디자인(CSS)을 사용해 다양한 디바이스를 지원하면서, React의 상태 관리(State Management)를 통해 UI를 데이터와 동기화할 수 있음. 예시 Reaponsive는 레이아웃과 UI에 초점을 맞추고, Reactive는 데이터와 상태 관리에 집중 둘이 상호보완적! import React, { useState } from 'react'; import './App.css'; // Responsive 스타일 포함 function App() { const [isDarkMode, setIsDarkMode] = useState(false); return ( &lt;div className={`app ${isDarkMode ? 'dark-mode' : ''}`}&gt; &lt;p&gt;Welcome to the responsive and reactive app!&lt;/p&gt; &lt;button onClick={() =&gt; setIsDarkMode(!isDarkMode)}&gt; Toggle Dark Mode &lt;/button&gt; &lt;/div&gt; ); } /* App.css */ .app { padding: 20px; transition: background-color 0.3s; } .dark-mode { background-color: #333; color: #fff; } @media (max-width: 768px) { .app { font-size: 14px; } }",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-01-20-responsive/"
  },{
    "title": "[CSS] CSS Float",
    "text": "CSS Float란 Clearfix Clear 속성 Clearfix VS Clear Float 사용시 주의사항 결론 CSS Float이란? Float의 기본 개념 요소가 normal flow에서 벗어나 부모 요소의 왼쪽 또는 오른쪽으로 이동한다. 텍스트와 inline 요소들이 float된 요소 주변을 감싼다. Float의 사용 전통적으로 다단 레이아웃을 만드는 데 사용된다. 이미지나 다른 요소를 텍스트 흐름 내에 배치하는 데 유용 Clearfix Float의 문제점 부모 요소 높이 붕괴 float된 요소는 부모 요소의 높이에 영향을 주지 않아 부모 요소가 높이를 잃을 수 있다. Clearfix 이 문제를 해결하기 위해 clearfix 기법이 사용된다. overflow: auto 또는 overflow: hidden을 부모 요소에 적용한다. 가상 요소 (::after)를 사용하여 float를 해제한다. Clearfix 방법: CSS를 이용한 Clearfix: .clearfix::after { content: \"\"; display: block; clear: both; } 부모 요소에 clearfix 클래스를 추가하여 float 문제를 해결한다. Clear 속성 핵심 문제: 특정 요소가 바로 앞에 있는 float 요소의 영향을 받아 원하는 위치에 배치되지 않을 수 있다. clear 속성의 역할: 특정 요소가 이전의 float 요소 아래로 내려가도록 강제하여 float의 영향을 방지한다. float 요소 다음에 나오는 요소에 주로 사용된다. 사용 예시 (clear 속성): .element { clear: both; } clear: both: 왼쪽과 오른쪽의 float 요소로부터 벗어남. 특정 요소 자체의 위치를 조정하기 위한 용도로 사용된다. Clearfix VS Clear 속성 개념 Clearfix Clear 속성 적용 대상 부모 요소가 float된 자식 요소를 감싸도록 해결 특정 요소가 float 요소의 영향을 받지 않도록 해결 해결 문제 부모 요소 높이 붕괴 문제 특정 요소의 위치 문제 주요 방식 overflow 속성, ::after 가상 요소 clear: left/right/both 속성 사용 위치 부모 요소 float 요소 바로 다음에 나오는 요소 부모 요소의 높이 붕괴 문제를 해결하려면 Clearfix를 사용한다. 요소가 float의 영향을 받아 잘못된 위치에 있을 때는 clear 속성을 사용한다. Float 사용 시 주의사항 Float는 레이아웃의 기본적인 도구이지만, Flexbox나 Grid와 같은 현대적인 레이아웃 기술로 대체될 수 있다. 복잡한 레이아웃에서는 유지보수가 어려워질 수 있다. Float의 대안: Flexbox: 1차원 레이아웃에 적합하며, 요소의 정렬 및 간격 조절에 강력하다. CSS Grid: 2차원 레이아웃에 적합하며, 행과 열을 기반으로 복잡한 레이아웃을 만들 수 있다. 결론 CSS Float는 여전히 유용한 기술이지만, 현대적인 레이아웃 기술과 함께 이해하고 사용하는 것이 중요 프로젝트의 요구 사항에 따라 적절한 레이아웃 기술을 선택해야 함",
    "tags": "javascript",
    "url": "/javascript/2025-01-19-css-float/"
  },{
    "title": "[CSS] CSS 문법",
    "text": "CSS란? CSS 문법 기초 CSS 적용 방법 CSS 프로퍼티 값의 단위 CSS란? CSS : Cascading Style Sheets 웹 페이지의 시각적 표현을 담당하는 스타일 언어 다양한 디바이스의 화면 크기에 대응하는 반응형 디자인 구현 내용과 디자인의 분리로 유지보수성 향상 HTML VS CSS HTML 웹페이지 구조와 콘텐츠 정의 CSS HTML 요소의 스타일과 레이아웃 지정 CSS 문법 기초 선택자 (Selector) 스타일을 적용할 HTML 요소 지정 /* 요소 선택자 */ p { color: blue; } /* 클래스 선택자 */ .highlight { background-color: yellow; } /* ID 선택자 */ #header { font-size: 24px; } /* 전체 선택자 */ * { margin: 0; padding: 0; } /* 무조건 뒤에 오는게 이긴다. 뒤로 갈수록 덮어씌우는 개념 */ /* 아이디랑 클래스 중 아이디가 이김 */ 속성 (Property) 변경하고자 하는 스타일의 종류 값 (Value) 속성에 적용할 구체적인 스타일 값 선언 (Declaration) 속성과 값의 쌍 규칙 (Rule) 선택자와 선언 블록의 조합 선택자 { 속성: 값; 속성: 값; } /* 구체적인 예시 */ h1 { color: blue; font-size: 18px; } CSS 적용 방법 인라인 스타일 HTML 요소 내부에 직접 스타일 적용 내부 스타일시트 head 섹션 내 style 태그에 CSS 작성 외부 스타일시트 별도의 .css파일에 스타일 정의 HTML 문서의 head 섹션에서 링크로 연결 CSS 프로퍼티 값의 단위 크기 단위 px : 픽셀 단위, 절대값 % : 백분율 단위, 상대값 em : 요소에 지정된 사이즈에 상대적인 배수 단위 rem : 최상위 요소(html)의 사이즈 기준 배수 단위 Viewport 단위 : vh, vw, vmin, vmax",
    "tags": "javascript",
    "url": "/javascript/2025-01-18-css/"
  },{
    "title": "[HTML] Emmet",
    "text": "Emmet이란? Emmet의 강력한 단축키 !+Tab Emmet 사용법 Emmet, 어디에서 사용할 수 있나요? Emmet이란? Emmet은 웹 개발자가 HTML, CSS 코드를 훨씬 빠르고 효율적으로 작성할 수 있도록 도와주는 플러그인입니다. 간단한 축약어를 입력하면 Emmet이 알아서 전체 코드로 확장해줍니다. 예를 들어, ul&gt;li*5&gt;a라고 입력하면 다음과 같은 HTML 코드가 자동으로 생성됩니다. &lt;ul&gt; &lt;li&gt;&lt;a href=\"\"&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"\"&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"\"&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"\"&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"\"&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; Emmet을 사용하면 이런 불필요한 작업을 줄이고, 개발자는 오롯이 로직과 디자인에 집중할 수 있습니다. Emmet의 강력한 단축키 ! + Tab Emmet을 사용하는 가장 대표적인 사례 중 하나는 ! + Tab 단축키입니다. 이 단축키를 입력하면 기본 HTML 문서의 구조가 즉시 생성됩니다. 예를 들어, 빈 파일에서 !를 입력한 후 Tab 키를 누르면 다음과 같은 기본 HTML 문서가 자동으로 작성됩니다. &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\" /&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /&gt; &lt;title&gt;Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt;&lt;/body&gt; &lt;/html&gt; 이 기본 구조는 웹 페이지를 시작할 때 반드시 필요한 요소들로 구성되어 있으며, 직접 입력하는 번거로움을 크게 줄여줍니다. 이 기능만 사용해도 초보자부터 숙련된 개발자까지 작업 시간을 크게 단축할 수 있습니다. Emmet 사용법 (굉장히 쉽고 편리함) Emmet의 문법은 간단하면서도 강력합니다. 몇 가지 기본 규칙만 익히면 금방 능숙하게 사용할 수 있습니다. 자식 요소: &gt; 기호를 사용하여 자식 요소를 생성합니다. 예를 들어, div&gt;p는 &lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;로 확장됩니다. 형제 요소: + 기호를 사용하여 형제 요소를 생성합니다. 예를 들어, h2+p는 &lt;h2&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;로 확장됩니다. 반복 요소: * 기호를 사용하여 요소를 반복 생성합니다. 예를 들어, li*3는 &lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;로 확장됩니다. 그룹화: () 괄호를 사용하여 요소들을 그룹으로 묶을 수 있습니다. 예를 들어, div&gt;(header&gt;ul&gt;li*2)+footer는 다음과 같이 확장됩니다. &lt;div&gt; &lt;header&gt; &lt;ul&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/header&gt; &lt;footer&gt;&lt;/footer&gt; &lt;/div&gt; 속성 추가: [] 괄호를 사용하여 요소에 속성을 추가할 수 있습니다. 예를 들어, a[href=#]는 &lt;a href=\"#\"&gt;&lt;/a&gt;로 확장됩니다. 여러 속성을 추가하려면 a[href=# title=링크]와 같이 작성합니다. 클래스 및 ID 추가: CSS 선택자처럼 . 기호로 클래스를, # 기호로 ID를 추가할 수 있습니다. 예를 들어, div.container는 &lt;div class=\"container\"&gt;&lt;/div&gt;로, div#header는 &lt;div id=\"header\"&gt;&lt;/div&gt;로 확장됩니다. 여러 개의 클래스를 추가하려면 div.container.main처럼 작성합니다. 텍스트 내용 추가: {} 중괄호 안에 텍스트 내용을 입력할 수 있습니다. 예를 들어, p{안녕하세요}는 &lt;p&gt;안녕하세요&lt;/p&gt;로 확장됩니다. 이 외에도 다양한 기능들이 있지만, 이 정도만 알아도 Emmet의 강력함을 충분히 경험할 수 있습니다. Emmet, 어디에서 사용할 수 있나요? Emmet은 대부분의 텍스트 에디터와 IDE에서 플러그인 형태로 제공됩니다. Visual Studio Code, Sublime Text, Atom, IntelliJ IDEA 등 유명한 에디터에서는 기본적으로 Emmet을 지원하거나, 간단한 설치만으로 사용할 수 있습니다.",
    "tags": "javascript",
    "url": "/javascript/2025-01-17-emmet/"
  },{
    "title": "[TIL] Prompt Engineering, RAG, vs code Cline",
    "text": "📝 TIL (Today I Learned) 🔗 원본 이슈: #1 📅 작성일: 2025-01-16 🔄 최종 수정: 2025년 03월 05일 🍀 새롭게 배운 것 GPT 프롬프트 엔지니어링 최근 다양한 AI 활용법이 쏟아지는 가운데, 프롬프트 설계 능력의 중요성을 실감하고 있다. 오늘은 특히 RTF (Role-Task-Format) 구조를 배웠다. 단순히 명령어를 입력하는 것을 넘어서, AI에게 ‘역할(Role)’, ‘할 일(Task)’, ‘출력 형식(Format)’을 명확하게 지정해주는 것이 얼마나 효율적인지 직접 체감했다. 예) You are a UX designer. Generate a list of 3 app features in table format. RAG (Retrieval-Augmented Generation) 단순히 사전 학습된 언어 모델이 아닌, 외부 문서를 불러와서 참조하며 답을 생성하는 방식이다. 기업들이 실무에서 RAG를 기반으로 챗봇이나 문서 검색 시스템을 구현하고 있다는 것을 알게 되었고, 자연어처리와 정보 검색(IR)의 결합이라는 점에서 흥미로웠다. VS Code + Cline으로 Markdown 정리 습관 들이기 처음에는 단순히 메모를 하기 위해 사용했지만, 마크다운 문법을 배우고 나니 노션이나 블로그에도 바로 활용할 수 있다는 장점이 컸다. 코드 스니펫, 체크박스, 표 등의 기능도 유용하게 느껴졌다. Bullet point와 in a nutshell 정리법 정보를 짧고 핵심적으로 요약하는 능력이 AI를 다룰 때도, 협업 문서를 작성할 때도 점점 더 중요해지고 있다는 걸 실감했다. 이번에는 중요한 개념들을 bullet point로 먼저 정리하고, 마지막에는 nutshell 요약으로 마무리해보았다. 🍎 오늘의 문제 상황 &amp; 해결 과정 문제 상황: 최근 많이 접하는 RAG, RTF 같은 AI 관련 용어들이 낯설고, 이론은 어렵게 느껴졌다. 막연히 알고는 있었지만, 실제로 언제 어디에 어떻게 쓰이는지를 이해하지 못하고 있었다. 해결 과정: Cline 마크다운 환경에서, 유튜브 영상과 구글링으로 얻은 정보를 빠르게 요약 및 정리 RAG 관련 오픈소스 프로젝트 예시를 찾아보며 구조 이해 RTF 방식으로 프롬프트 실습 → 직접 써보니 효과가 훨씬 좋다는 걸 느낌 ChatGPT에게 “너는 AI 프롬프트 엔지니어야. 초보자를 위한 개념 설명을 해줘 (in table format)” 라고 요청하니, 이해가 훨씬 쉬워짐 🦄 느낀 점 요즘 들어 “AI를 잘 다루는 사람 vs 그냥 사용하는 사람”의 차이가 커지고 있다는 걸 느낀다. 특히 프롬프트 설계, 데이터 기반 활용, 워크플로우 자동화 같은 부분에서 큰 격차가 벌어지는 것 같다. 평소 유튜브로 재미 삼아 보던 영상들이, 실전에서 실제 도움이 되니 흥미로웠다. 이제는 소비자로서 보는 것을 넘어서, 창의적으로 활용하는 쪽으로 넘어가야겠다는 생각이 들었다. 앞으로는 프롬프트 모음집을 정리하거나, 내가 이해한 방식으로 개념들을 설명해보는 나만의 AI 사용 설명서를 만들어보면 좋을 것 같다. 🐬 깃블로그 정리 [RAG Cline통한 정리] (https://nan0silver.github.io/ai/2025-01-15-rag/) [생성형 AI와 LLM] (https://nan0silver.github.io/ai/2025-01-16-basic/)",
    "tags": "TIL til",
    "url": "/til/2025-01-16-til/"
  },{
    "title": "[AI] 생성형 AI와 LLM",
    "text": "LLM 생성형 AI GPT Prompt Engineering RTF Framework LLM (Large Language Model) 광범위한 양의 텍스트 데이터를 학습한 모델 인간의 글과 대화 방식을 받아들이며 더욱 정교하고 자연스러운 대화 능력 갖춰감 생성형 AI (Generative AI) 데이터를 분석하고 학습하여 새로운 콘텐츠를 생성하는 인공지능 기술 GPT (Genertive Pre-trained Transformer) OpenAI가 개발한 대형 언어 모델로, 사전 학습된 트렌스포머 구조를 기반으로 한 생성형 AI기술 트렌스포머 구조 Google의 논문 “Attention is All You Need”에서 소개된 딥러닝 모델 구조 Pre-training 방대한 텍스트 데이터를 기반으로 언어의 패턴과 문맥을 학습 Fine-tuning (미세 조정) 특정 목적이나 응용에 맞춰 추가 학습을 진행하여 성능 최적화 생성 능력 기존 데이터를 이해하고 이를 기반으로 새로운 텍스트 생성 ChatGPT 맥락을 파악하는 능력이 뛰어남 환각(Hallucinate) 실제 데이터나 사실을 반영하지 않고 비현실적이거나 오류를 포함하 내용을 만들어내는 경우가 있다 해결 방법 파인 튜닝 프롬프트 엔지니어링 크로스체킹 Prompt Engineering 어떻게 질문을 하느냐에 따라 결과가 달라질 수 있음 필요성 내가 원하는 바를 정확히 주면 줄수록 정확한 대답을 얻을 수 있음 언제나 고급 모델을 쓸수는 없음 (너무 비쌈) Zero-shot Prompting 작업에 대한 지시만 포함하는 프롬프트 방식 One-shot Prompting 작업 예시를 하나 제공하여 AI가 이를 참고로 결과를 생성하도록 하는 방식 Few-shot Prompting 작업 예시를 여러 개 제공하는 방식 복잡한 작업 수행에서 사용 Chain of Thought (CoT) 모델이 단계적으로 사고 과정을 출력하도록 유도 Zero-shot CoT Tree of Thoughts (ToT) 가능한 대안을 모두 도출하고 그 중 촤선의 답변을 선택하도록 하는 방식 “모든 옵션을 평가하고 가장 좋은 대안을 제시하세요” ReAct 결과물을 생성(Reaction)하고 피드백(Reasoning)을 통해 개선해나가는 방식 “예제를 짜고 정상적으로 작동하는지 검증하시오” RTF Framework Role, Task, Format를 명확히 정의해 프롬프트를 설계하는 방법론 Role-based Prompting AI의 역할을 명확히 지정하여 특정 관점이나 전문성으로 답 얻을 수 있음 Task 특정 작업을 지시 프롬프트의 핵심 Format AI의 응답 형식을 지정 (JSON, 엑셀 등) 면접할때 사용 가능 당신은 백엔드 면접관입니다. 주니어 개발자 면접을 진행할 때 어떤 질문을 묻겠습니까? 학습자의 수준에 맞춘 접근 가능",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2025-01-16-basic/"
  },{
    "title": "[AI] RAG (Retrieval-Augmented Generation) 이란?",
    "text": "RAG RAG의 작동 방식 RAG의 장점 RAG의 활용 분야 결론 RAG (Retrieval-Augmented Generation) 거대 언어 모델(LLM)은 학습 데이터에 없거나 최신 정보에 대해서는 어려움을 겪을 수 있다. 이러한 한계를 극복하기 위한 기술이 RAG (Retrieval-Augmented Generation), 즉 검색 증강 생성입니다. RAG는 언어 모델이 답변을 생성하기 전에 외부 지식 소스에서 관련 정보를 검색하여 답변의 품질과 정확성을 높이는 방법론입니다. 마치 20년차 개발자가 새로운 기술에 대해 설명하기 전에 관련 문서를 찾아보고 이해하는 과정과 유사. RAG의 작동 방식 검색 (Retrieval) 사용자의 질문이나 요청이 들어오면, RAG 시스템은 미리 구축된 외부 지식 베이스에서 관련 정보를 검색 이 지식 베이스는 문서, 웹 페이지, 데이터베이스 등 다양한 형태를 가짐 검색 과정에서는 질문의 의미를 파악하고, 지식 베이스 내의 정보와 유사성을 비교하여 가장 관련성이 높은 정보를 추출. 생성 (Generation) 검색된 관련 정보는 원래의 질문 또는 요청과 함께 언어 모델에 입력됨 언어 모델은 이 정보를 바탕으로 답변을 생성 이때, 단순히 검색된 정보를 나열하는 것이 아니라, 검색된 정보를 바탕으로 새로운 문장을 구성하거나, 질문에 대한 답변을 논리적으로 도출하는 등 더욱 풍부하고 맥락에 맞는 답변을 생성 가능 RAG의 장점 정보의 최신성 확보 언어 모델은 학습 데이터 시점 이후의 최신 정보에 접근하기 어렵습니다. RAG는 외부 지식 베이스를 통해 실시간 또는 최신 정보를 활용하여 답변의 정확성을 높일 수 있습니다. 답변의 근거 제시 RAG는 답변을 생성할 때 사용된 외부 정보의 출처를 제시할 수 있습니다. 답변의 신뢰도를 높이고, 사용자가 정보를 추가적으로 검증할 수 있도록 돕습니다. 모델 업데이트 비용 절감 기존 언어 모델은 새로운 정보를 학습시키기 위해 모델 전체를 재학습해야 하는 경우가 많아 비용과 시간이 많이 소요됩니다. RAG는 외부 지식 베이스만 업데이트하면 되므로 모델 업데이트 비용을 크게 절감할 수 있습니다. 특정 도메인에 대한 전문성 강화 특정 분야의 지식 베이스를 RAG에 활용하면, 언어 모델은 해당 분야에 대한 전문적인 답변을 제공할 수 있습니다. 예를 들어, 의료 분야의 RAG 시스템은 최신 의학 논문을 검색하여 환자에게 정확한 정보를 제공할 수 있습니다. RAG의 활용 분야 챗봇 및 가상 비서 사용자의 질문에 대해 최신 정보를 기반으로 정확하고 상세한 답변을 제공하는 챗봇을 구축할 수 있습니다. 지식 검색 시스템 방대한 양의 문서나 데이터베이스에서 사용자의 질문에 가장 적합한 정보를 빠르게 찾아 제공하는 시스템을 구축할 수 있습니다. 콘텐츠 생성 특정 주제에 대한 최신 정보를 검색하여 블로그 게시물, 기사, 보고서 등 다양한 형태의 콘텐츠를 생성하는 데 활용될 수 있습니다. 교육 및 연구 학생이나 연구자가 특정 주제에 대한 정보를 검색하고 이해하는 과정을 돕는 도구로 활용될 수 있습니다. 결론 RAG (Retrieval-Augmented Generation)은 언어 모델의 잠재력을 한 단계 더 끌어올리는 중요한 기술입니다. 외부 지식 소스를 활용하여 답변의 정확성, 최신성, 신뢰성을 높임으로써, 인공지능이 더욱 유용하고 신뢰할 수 있는 도구로 발전하는 데 기여할 것입니다. 마치 숙련된 개발자가 끊임없이 새로운 정보를 습득하고 활용하여 문제를 해결하는 것처럼, RAG는 인공지능이 더욱 똑똑하게 정보를 처리하고 활용할 수 있도록 돕는 핵심적인 기술입니다.",
    "tags": "miscellaneous ai",
    "url": "/miscellaneous/ai/2025-01-15-rag/"
  },{
    "title": "[Algorithm] Linear Time Sorting Algorithm",
    "text": "Counting Sort Radix Sort Order Statistics Randomized Selection Worst-Case Linear-Time Selection 그외 Counting Sort No comparison sort 조건 데이터의 크기 범위가 제한된 경우 데이터의 갯수가 상수개인 경우 CountingSort(A, B, k) { for i = 1 to k C[i] = 0; for j = 1 to n C[A[j]] += 1; for i = 2 to k C[i] = C[i] + C[i-1]; for j = n downto 1 //stable하게 만들기 위해 1 to n이 아닌 n to 1 수행 B[C[A[j]]] = A[j]; C[A[j]] -= 1; } k가 n개 이하일 때 정렬이 가능하다. k가 너무 큰 경우 각 자리수마다 counting sort를 수행하는 방법을 사용할 수 있다. - radix sort 시간 복잡도 : \\(O(n)\\) 장점 stable하다 단점 in-place 알고리즘은 아니다. (extra place 필요) Radix Sort counting sort의 일반 버전 RadixSort(A, d){ for i=1 to d StableSort(A) on digit i //StableSort = counting sort } 시간 복잡도 : \\(d*O(n)\\) Radix Sort의 핵심은 stable한 것이다. counting sort때문에 in-place하진 않다. 자릿수의 최대 값은 \\(logn\\)이다. 따라서 radix sort가 merge sort보다 빠를 수 있다. 한계 길이가 다른 문자열같은 digit이 정확하지 않으면 사용할 수 없다. Order Statistics n개의 요소들 중 i번째로 작은 요소를 고르는 것 minimun은 첫 번째 order statistic Randomized Selection quicksort의 partition()을 사용한다. 하지만 우리는 오직 하나의 subarray만 평가하면 된다. RandomizedSelect(A, l, r, k) if (l == r) then return A[l]; p = RandomizedPartition(A, l, r) if (p == k) then return A[p]; if (p &lt; k) then return RandomizedSelect(A, l, p-1, k); else return RandomizedSelect(A, p+1, r, k); ``` 시간 복잡도 worst case : \\(O(n^2)\\) best, average case : \\(O(n)\\) Worst-Case Linear-Time Selection generte a good partitioning element Randomized selection에서 pivot value를 고르는데 추가로 $\\Theta(n)$시간을 써 업그레이드한 방법 알고리즘 n개의 element들을 5개씩 묶어 그룹을 만든다. 각 그룹의 중간값을 찾는다. -&gt; \\(O(const)\\) Select()를 재귀적으로 사용해 n/5개의 중간값 x를 찾는다. \\[n/5 + n/25 + n/125 + ... &lt; n\\] x를 중심으로 partition을 진행한다. 시간 복잡도 : \\(O(n)\\) Quick sort에서도 해당 알고리즘을 이용해 worst case의 시간복잡도를 \\(O(nlogn)\\)으로 만들 수 있다. 하지만 이 경우 pivot value를 찾는 과정에서 캐쉬가 한번 뒤집혀져 quick sort의 장점 중 하나인 cache friendly 장점이 사라진다. 차라리 merge sort나 heap sort를 사용한다. 그외 Insertion sort \\[O(n^2)\\] Merge sort, Heap sort, Quick sort comparison sort all comparison sorts are \\(\\Omega(nlogn)\\)",
    "tags": "algorithm",
    "url": "/algorithm/2024-12-13-linear-time-sorting/"
  },{
    "title": "[Algorithm] 분할정복 알고리즘 (Divide and conquer)",
    "text": "분할정복 알고리즘 설계 방법 특징 및 장단점 분할정복 알고리즘 (Divide and conquer algorithm) 그대로 해결할 수 없는 문제를 작은 문제로 분할하여 문제를 해결하는 방법. 대표적인 예로는 정렬 알고리즘 중에서 퀵 정렬이나 합병 정렬과 이진 탐색, 선택 문제, 고속 푸리에 변환(FFT) 문제들이 있음. 설계 방법 1) Divide ∙  원래 문제가 분할하여 비슷한 유형의 더 작은 하위 문제로 분할이 가능할 때 까지 나눈다. 2) Conquer ∙  각 하위 문제를 재귀적으로 해결한다. 하위 문제의 규모가 나눌 수 없는 단위가 되면 탈출 조건을 설정하고 해결한다. 3) Combine ∙  Conquer한 문제들을 통합하여 원래 문제의 답을 얻어 해결한다. 🖋 Divide를 제대로 나누면 Conquer과정은 자동으로 쉬워진다. 그래서 Divide를 잘 설계하는 것이 중요! 🖋 분할정복 알고리즘은 재귀 알고리즘이 많이 사용되는데, 이 부분에서 분할정복 알고리즘의 효율성을 깎아내릴 수 있다. 특징 및 장단점 ∙  분할된 작은 문제는 원래 문제와 성격이 동일하다  -&gt; 입력 크기만 작아짐 ∙  분할된 문제는 서로 독립적이다(중복 제거 X) -&gt; 순환적 분할  및 결과 결합 가능 ∙  분할정복은 Top-down방식으로 재귀 호출의 장단점과 똑같다고 보면 된다. 장점 단점 ∙  Top-down 재귀방식으로 구현하기 때문에 코드가 직관적이다. ∙  재귀함수 호출로 오버헤드가 발생할 수 있다 ∙  문제를 나누어 해결한다는 특징상 병렬적으로 문제를 해결할 수 있다. ∙  스택에 다량의 데이터가 보관되는 경우 오버플로우가 발생할 수 있다.",
    "tags": "algorithm",
    "url": "/algorithm/2024-12-12-divide-conquer/"
  },{
    "title": "[JAVA] Set",
    "text": "목차 텍스트 블록 formatted() 메서드 레코드 패턴 매칭 case문 개선 Set 데이터 자료구조(데이터 컬렉션) 중 하나로, 특정한 값들을 저장하는 추상자료형 List와 다르게 데이터를 중복해서 저장할 수 없음 저장된 데이터를 인덱스로 관리하지 않기 때문에 저장 순서가 보장되지 않음 수학의 유한 집합을 컴퓨터로 구현한 것 특성 데이터를 비순차적으로 저장할 수 있는 순열 자료구조 삽입한 데이터가 순서대로 저장되지 않음 수정 가능(mutable) 중복해서 삽입 불가능 Fast Lookup이 필요할 때 주로 쓰임 대표적인 클래스 HashSet, TreeSet, LinkedHashSet 클래스들의 주요 메소드 add(E e) 리턴타입 : boolean interator() 리턴타입 : Iterator 검색을 위한 반복자 생성 size() 리턴타입 : int clear() 리턴타입 : void remove(Object o) 리턴타입 : boolean HashSet Set 컬랙션을 구현하는 대표적인 클래스 데이터를 중복 저장할 수 없고 순서를 보장하지 않는다. 예시 Set&lt;String&gt; set = new HashSet&lt;String&gt;(); set.add(\"one\"); set.add(\"two\"); Interator&lt;String&gt; iter = set.iterator(); while(iter.hasNext()) { //꺼낼 것이 있다면 true 리턴 System.out.println(iter.next()); //다음 데이터 리턴 } TreeSet 중복된 데이터를 저장할 수 없고 입력한 순서대로 값을 저장하지 않음 TreeSet은 기본적으로 오름차순으로 데이터를 정렬 LinkedHashSet 입력된 순서대로 데이터를 관리한다. 중복된 데이터를 저장할 수는 없음 저장된 데이터의 존재를 빠르게 확인할 수 있지만 내부에 삽입 순서로 정렬된 목록이 포함됨 포켓몬 고와 같은 게임에서 객체가 이미 목록에 있는지 여부를 빠르게 확인하고 목록에 없는 경우 목록에 추가할 수 있음 LinkedHashSet vs HashSet HashSet은 HashMap을 사용해 개체를 저장 LinkedHashSet은 LinkedHashMap을 사용 삽입 순서를 유지할 필요가 없지만 고유한 개체를 저장해야하는 경우 HashSet이 적합 LinkedHashSet의 성능은 HashSet보다 약간 느림",
    "tags": "java",
    "url": "/java/2024-12-08-set/"
  },{
    "title": "[Spring] Spring 매핑 개념과 주요 애너테이션 활용법",
    "text": "Mapping 맵핑 (Mapping) Mapping 클라이언트로 부터 요청이 들어오는 URL과 컨트롤러 메서드를 연결하는 작업 Mapping 애너테이션을 사용해 클라이언트의 요청이 URL로 들어올 때 해당 URL에 맞는 컨트롤러가 있는지 확인하고 해당 컨트롤러를 매핑하여 요청을 처리 @RequestMapping 클라이언트가 특정 URL로 요청을 보낼 때, 이 요청을 처리할 컨트롤러 메서드를 정의하는 것 Get, Post, Put, Delete, Patch등의 URL을 다 포함하고 있으며, 옵션을 통해 종류를 지정할 수 있음 @Controller public class ProductController { @RequestMapping(\"/products\", method = RequestMethod.GET) public String listProducts() { return \"product-list\"; } @RequestMapping(\"/products\", method = RequestMethod.POST) public String addProducts() { return \"product-added\"; } } HTTP 메서드에 특화된 매핑 @GetMapping GET 요청만 받는 애노테이션 @RequestMapping(method = RequestMethod.GET) @PostMapping POST 요청만 받는 애노테이션 @RequestMapping(method = RequestMethod.POST) @PutMapping PUT 요청만 받는 애노테이션 @RequestMapping(method = RequestMethod.PUT) @DeleteMapping DELETE 요청만 받는 애노테이션 @RequestMapping(method = RequestMethod.DELETE) @PatchtMapping PATCT 요청만 받는 애노테이션 @RequestMapping(method = RequestMethod.PATCH)",
    "tags": "spring",
    "url": "/spring/2024-12-03-mapping/"
  },{
    "title": "[Spring] Spring Framework의 주요 개념 (IoC, DI, AOP, PSA)",
    "text": "스프링 콘셉트 스프링 콘셉트 스프링 프레임워크의 주요 개념에 대해 다룬다. IoC Inversion of Control 객체의 생성과 관리를 개발자가 아니라 프레임워크가 대신하는 것 public class A { private B b; } 객체를 직접 생성하지 않고(new 키워드 사용하지 않고) 외부에서 관리하는 객체를 가져와 사용 스프링에서는 스프링 컨테이너가 객체를 관리, 제공하는 역할을 함 스프링 컨테이너 빈이 생성되고 소멸되기 까지의 생명주기를 관리하는 것 DI Dependency Injection 외부에서 객체를 주입받아 사용하는 것 예시 (IoC/DI를 기초로 하는 스프링 코드) public class A { //A에서 B를 주입받음 @Autowired B b; } Bean 스프링 컨테이너가 생성하고 관리하는 객체 스프링은 빈을 컨테이너에 등록하기 위해 XML 파일 설정, 애너테이션 추가 등 방법 제공 AOP Aspect Oriented Programming 프로그래밍 시 핵심 관점과 부가 관점을 나누어 개발하는 것 PSA Portable Service Abstraction 어느 기술을 사용하던 일관된 방식으로 처리하도록 하는 것 대표적인 예 클라이언트의 매핑과 클래스, 메서드의 매핑을 위한 애너테이션",
    "tags": "spring",
    "url": "/spring/2024-12-02-spring-basic/"
  },{
    "title": "[JAVA] JAVA 메모리 모델과 변수의 종류 : static, 지역변수, 레퍼런스 변수 이해하기",
    "text": "static 변수 Method Area 지역변수 &amp; 레퍼런스 변수 지역 변수 레퍼런스 변수 JAVA 변수들의 특징 및 차이점 요약 static 변수와 지역 변수 비교 static 변수와 레퍼런스 변수 비교 지역 변수와 레퍼런스 변수 비교 static 변수 인스턴스가 아닌 클래스에 귀속 인스턴스가 여러 개 생성되도 static 변수는 딱 하나 클래스가 메모리에 로드될 때 한 번 생성됨 객체가 아닌 클래스 자체에 저장되기 때문에 모든 객체가 동일한 메모리 위치를 공유함 특징 수명 클래스가 메모리에 로드될 때 생성되고, 프로그램이 종료될 때까지 유지됨 일반적인 지역변수와 달리 블록을 벗어나도 소멸되지 않음 메모리 위치 static 변수는 Method Area에 저장됨 static 변수의 객체 독립성 static 변수가 클래스 자체에 속해 있기 때문에, 객체를 생성하지 않아도 해당 클래스 이름만으로 직접 접근 가능 예시 public class Example { static int staticVar = 10; //static 변수 (클래스 변수) int instanceVar = 20; //인스턴스 변수 (객체 변수) public static void main(String[] args) { //static 변수는 클래스 이름으로 접근 가능 System.out.println(\"Static Variable: \" + Example.staticVar); //출력: 10 //객체를 생성하지 않아도 static 변수에 접근 가능 Example.staticVar = 30; System.out.println(\"Static Variable: \" +Example.staticVar); //출력: 30 //객체를 생성해야 인스턴스 변수에 접근 가능 Example obj1 = new Example(); System.out.println(\"Instance Variable: \" + obj1.instanceVar); //출력: 20 } } static 변수 사용 시점 공유 데이터가 필요할 때 모든 객체에서 동일한 값 공유해아 할 때 사용 예: 총 객체 갯수, 공통 설정값 등 객체와 무관하게 동작해야할 때 클래스 자체의 정보를 나타내거나, 객체 없이 사용 가능한 값을 저장할 때 예: 수학 상수 Math.PI, System.out.println()의 out도 static public class TestClass{ static int number; } public class Test{ public static void main(String []arg){ TestClass class1 = new TestClass(); TestClass class2 = new TestClass(); class1.number = 3; class2.number = 5; System.out.println(\"class1의 number: \" + class1.number); System.out.println(\"class2의 number: \" + class2.number); } } // class1의 number: 5 // class2의 number: 5 마지막에 number에 5가 저장되어있기 때문에 5가 두번 출력 Method Area JVM(Java Virtual Machine)의 메모리 구조 중 하나 클래스 수준의 정보를 저장하는 영역 저장되는 데이터 종류 클래스 정보 클래스의 이름, 부모 클래스, 접근 제어자 등의 메타데이터 클래스 변수 (static 변수) 클래스가 로드될 때 메모리에 할당되며 모든 객체에서 공유됨 메서드 정보 메서드의 이름, 리턴 타입, 매개변수 타입 등 메서드의 바이트코드 포함 상수 (Constant Pool) 컴파일 시 생성된 상수(문자열, 숫자 리터럴 등)와 참조(메서드 참조, 클래스 참조)가 저장됨 런타임 상수 풀(Runtime Constant Pool) 런타임 중에 동적으로 생성된 상수와 참조. 특징 JVM내에서 유일 : 모든 스레드가 공유 수명 : JVM이 종료될 때까지 유지 Garbage Collection 대상 아님 : 클래스 정보는 명시적으로 제거되지 않음 지역변수 &amp; 레퍼런스 변수 지역변수 (Local Variable) 특정 블록이나 함수 안에서만 선언되고 사용가능한 변수 해당 블록이나 함수가 실행을 마치면 메모리에서 삭제되며, 외부에서 접근 불가능 특징 유효 범위 (Scope) 변수가 선언된 블록(중괄호 {}로 감싸진 영역) 내에서만 유효 초기화 필요 지역변수는 자동으로 초기화 되지 않음 메모리 관리 지역변수는 함수 호출시 생성되고, 함수 종료 시 자동으로 소멸됨 일반적으로 스택 메모리 사용 예제 public class Example { public static void main(String[] args) { int x = 1; // x는 main 메서드의 지역 변수 if (x &lt; 10) { int y = 20; // y는 if 블록의 지역 변수 } //y는 if블록 밖에서 사용할 수 없음 } } 레퍼런스 변수 (Reference Variable) 객체의 메모리 주소를 저장한는 변수, 즉 객체를 참조하는 데 사용됨 실제 객체 데이터를 직접 저장하지 않고 객체가 메모리에 위치한 주소만 저장 특징 객체와 연결 레퍼런스 변수는 new키워드 등을 통해 생성된 객체를 가리킴 동적 메모리 사용 레퍼런스 변수가 가리키는 객체는 힙(Heap)메모리에 저장됨 null값 가능 초기화되지 않은 레퍼런스 변수는 null값을 가질 수 있음 null값을 참조하려면 NullPointerException이 발생 두 레퍼런스 변수가 동일한 객체를 가리킬 수 있음 한 레퍼런스 변수를 통해 객체를 수정하면 다른 레퍼런스 변수도 수정됨 예제 public class Example{ public static void main(String[] args) { String str = \"Hello\"; //str은 String객체를 참조하는 레퍼런스 변수 System.out.println(str.length()); //참조된 객체의 메서드 호출 가능 str = null; //str이 아무 객체도 참조하지 않음 //System.out.println(str.length()); //NullPointerException 발생 } } public class Example { public static void main(String[] args) { int[] numbers = {1,2,3}; int[] ref = numbers; //같은 객체 참조 ref[0] = 100; //참조를 통해 객체 수정 System.out.println(numbers[0]); //출력: 100 } } Java 변수 비교: static, 지역 변수, 레퍼런스 변수의 특징과 차이점 static 변수와 지역 변수 비교 특징 static 변수 지역 변수 범위(Scope) 클래스 전체에서 접근 가능 (전역적) 선언된 블록(예: 함수) 내에서만 유효 수명(Lifetime) 프로그램 종료 시까지 유지 블록 실행이 끝나면 소멸 공유 모든 객체가 같은 값을 공유 각 함수 호출마다 독립적으로 생성 메모리 위치 메서드 영역(Method Area) 스택(Stack) 메모리 static 변수와 레퍼런스 변수 비교 특징 static 변수 레퍼런스 변수 저장 내용 클래스 수준에서 공유되는 데이터 객체의 메모리 주소를 저장 초기화 여부 명시적 초기화가 없으면 기본값으로 초기화됨 초기화되지 않으면 null 값을 가짐 수명 클래스 로드부터 프로그램 종료까지 유지 변수의 유효 범위 내에서만 사용 가능 클래스 의존성 클래스와 연결 (객체와 무관) 객체를 가리킴 (객체가 없으면 의미 없음) 메모리 위치 메서드 영역(Method Area) 스택(지역 변수일 때) 또는 힙(객체를 참조할 때) 지역 변수와 레퍼런스 변수 비교 특징 지역 변수 레퍼런스 변수 저장 내용 값 자체 객체의 메모리 주소 유효 범위 선언된 블록 내 객체가 참조되는 동안 메모리 위치 스택 메모리 힙 메모리에 저장된 객체를 참조 초기화 필요성 명시적 초기화 필요 초기화되지 않은 경우 null 값을 가질 수 있음",
    "tags": "java",
    "url": "/java/2024-11-20-variable/"
  },{
    "title": "[JAVA] JAVA version 17의 주요 변화",
    "text": "목차 텍스트 블록 formatted() 메서드 레코드 패턴 매칭 case문 개선 텍스트 블록 이전 버전에서는 여러 줄의 텍스트를 작성할때 \\n을 추가해야해서 가독성이 좋지 않은 부분이 개선되었다. 예시 String example11 = \"SELETE * FROM \\\"product\\\"\\n\" + \"WHERE \\\"country\\\" = \\\"KOREA\\\"\\n\" + \"ORDER BY \\\"name\\\";\\n\"; String example17 = \"\"\" SELECT * FROM \"product\" WHERE \"country\" = \"KOREA\" ORDER BY \"name; \"\"\"; //가독성이 훨씬 좋아졌다 formatted() 메서드 값을 파싱하는 데 더 편하게 해주는 formatted() 메서드 제공 예시 String example17 = \"\"\" { \"id\": %d, \"name\": %s } \"\"\".formatted(1, \"nahyun\"); 레코드 데이터 전달을 위한 객체를 더 빠르고 간편하게 만들기 위한 기능 getter를 자동으로 만들어 주기 때문에 애너테이션이나 메서드로 게터를 정의하지 않아도 됨 예시 record Item(String name, int price) { //파라미터가 private final로 정의된다 } Item product1 = new Item(\"product1\", 2500); product1.price(); //2500 패턴 매칭 타입 확인을 위해 사용하던 instanceof 키워드를 개선 이전에는 instanceof 키워드와 형변환 코드를 조합해야 했지만 이제는 바로 형변환 가능 자료형에 맞는 case 처리 switch-case문에서 자료형에 맞게 case 처리 가능 예시 static double getIntegerValue(Object object) { return switch (object) { case Double d -&gt; d.intValue(); case Float f -&gt; f.intValue(); case String s -&gt; Integer.parseInt(s); default -&gt; 0d; }; }",
    "tags": "java",
    "url": "/java/2024-11-15-java17/"
  },{
    "title": "[CS] 컴파일 언어 VS 인터프리터 언어, 그리고 Java",
    "text": "컴파일 언어 인터프리터 언어 컴파일 언어 VS 인터프리터 언어 항상 접할때마다 헷갈려서 정리하기로 했다. 컴파일 언어 한번에 전체 코드 번역 소스코드를 기계어로 변환하는 과정(컴파일)을 거친 후 실행 실행 파일이 생성됨으로 배포에 용이함 컴파일 타임 사용 이 과정을 거쳐 소스코드는 기계어가 되어 실행가능한 상태가 됨 실행 속도 기계어로 변환된 상태에서 실행되므로 매우 빠름 인터프리터 언어보다 20~100배 이상 빠름 개발 과정 문법 오류를 실행 전에 발견할 수 있어 안정적임 하지만 코드 변경 시 다시 컴파일해야 하므로 개발 편의성이 다소 떨어짐 대표적인 언어 C, C++, 러스트, Go 등 인터프리터 언어 스크립트 언어 별도의 실행 파일 없이, 소스코드를 직접 실행하는 경우가 많음 번역과 실행이 동시에 이루어짐 프로그램을 실행할 때 한 줄씩 읽고 해석한 뒤 바로 실행 런타임 사용 실행 시점에 코드가 해석되므로 빌드 과정이 필요 없음 실행 속도 한 줄씩 해석하며 실행하므로 컴파일언어보다 느림. 개발 과정 즉시 실행 및 테스트가 가능하여 개발 속도가 빠름 동적 타입을 지원하는 경우가 많아 코드 수정이 용이 대표적인 언어 Python, Ruby, JavaScript 등 기타 특징 python은 C++로 만들어져 있음 컴파일 언어는 빠르지만 개발 편의성이 떨어져 인터프리터 언어를 만드는데 사용되기도 함 실행 속도를 개선하기 위해 JIT(Just-In-Time) 컴파일러를 사용하는 경우도 있음 Python의 PyPy, Javascript의 V8엔진 등 왜 인터프리터 언어가 더 느릴까? 인터프리터 언어가 빌드 과정이 없는데 왜 느릴까? ‼️ 코드를 실행하는 방식 때문! 1. 한 줄씩 해석하며 실행하기 때문 컴파일 언어는 미리 전체 코드를 기계어로 변환한 후 실행하지만, 인터프리터 언어는 실행할 때마다 한 줄씩 해석하고 실행 컴파일 언어 실행 전에 한 번만 컴파일 -&gt; 실행 시에는 기계어(0과1)로 바로 실행 -&gt; 속도가 빠름 인터프리터 언어 실행할 때마다 소스 코드를 읽고, 해석하고, 실행 -&gt; 한 줄씩 번역하면서 실행해야 해서 속도가 느림 2. 동적 타입 (dynamic typing) 지원이 많아서 대부분의 인터프리터 언어 (Python, JavaScript 등)는 동적 타입 (dynamic typing)을 지원 동적 타입 언어는 실행 중 변수의 타입을 결정하기 때문에 매 실행마다 타입 체크가 필요 반면, 컴파일 언어(C, C++ 등)는 컴파일 시점에 타입이 결점되므로 실행 속도가 훨씬 빠름 3. 최적화 부족 컴파일러는 최적화(Optimization)를 통해 코드를 더 효율적으로 변환함 예를 들어, 컴파일러는 불필요한 연산을 제거하고, 반복문을 최적화하는 등 실행 속도를 높이기 위해 다양한 작업 수행 인터프리터 언어는 실행할 때마다 소스 코드를 직접 해석하기 때문에 이런 최적화가 어려움 4. 메모리 관리 방식 차이 컴파일 언어는 메모리 할당을 미리 최적화할 수 있지만, 인터프리터 언어는 실행 중에 동적으로 메모리를 할당하는 경우가 많아 메모리 관리 부담이 큼 그럼 인터프리터 언어의 속도를 높이는 방법은? ✅ 1. JIT(Just-In-Time) 컴파일 JIT 컴파일러는 인터프리터 방식과 컴파일 방식의 장점을 결합한 방법 프로그램 실행 도중 자주 실행되는 코드 블록을 미리 기계어로 변환해서 속도를 높임 대표적 예시 Java의 JVM (HotSpot JIT 컴파일러) Python의 PyPy JavaScriptdml V8 엔진 (Chrome, Node.js) ✅ 2. 바이트코드(Bytecode) 사용 일부 인터프리터 언어는 소스 코드를 직접 해석하는 대신, 한 번 중간 코드(바이트코드)로 변환한 후 실행하는 방식을 사용 예: Python의 CPython(기본 구현체) Python 소스 코드(.py) -&gt; 바이트코드(.pyc) 변환 -&gt; 실행 덕분에 매번 소스 코드를 해석하는 부담이 줄어듦 🔹 Java는 어떻게 실행될까? Java는 전통적인 컴파일 언어와 인터프리터 언어의 특징을 혼합한 하이브리드 언어 1️⃣ 소스 코드 → 바이트코드 변환 (컴파일 과정) Java 코드를 작성하면, javac 컴파일러가 이를 바이트코드(Bytecode) 로 변환. 바이트코드는 완전한 기계어가 아니라 JVM(Java Virtual Machine)에서 실행할 수 있는 중간 코드 이 과정은 전통적인 컴파일 언어(C, C++)와 비슷하지만, 완전히 기계어로 변환되지 않고 플랫폼 독립적인 코드로 남아 있음. 2️⃣ JVM에서 바이트코드 실행 (인터프리터 + JIT 컴파일) Java의 실행 과정에서는 JVM(Java Virtual Machine) 이 핵심 역할을 수행 JVM은 바이트코드를 한 줄씩 읽고 실행하는 인터프리터 방식을 사용하지만, 성능을 높이기 위해 JIT(Just-In-Time) 컴파일러를 활용. 🔹 JIT(Just-In-Time) 컴파일러가 하는 일 JIT 컴파일러는 인터프리터와 컴파일 방식의 장점을 결합한 기술이야. 실행 중 자주 사용되는 바이트코드를 분석해서 기계어로 변환(컴파일)한 후 캐싱해 둠. 이후 같은 코드가 실행될 때는 다시 해석하지 않고, 컴파일된 기계어를 바로 실행해서 성능을 높여. 즉, Java는 처음에는 인터프리터처럼 실행되지만, JIT이 동작하면 컴파일된 기계어 코드가 사용되므로 속도가 빨라지는 것이야. 🔹 Java는 컴파일 언어일까? 인터프리터 언어일까? ✔ 둘 다 아님! Java는 하이브리드 방식을 사용 컴파일 언어처럼: 소스 코드를 바이트코드로 변환하는 컴파일 과정이 있음. 인터프리터 언어처럼: JVM이 바이트코드를 한 줄씩 해석하며 실행할 수도 있음. JIT을 사용하면: 실행 중 특정 코드 블록을 기계어로 컴파일해서 성능을 높임.",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2024-11-08-language/"
  },{
    "title": "[AWS] AWS 기초",
    "text": "목차 AWS란? S3 &amp; Cloudfront AWS 솔루션 실무 적용 사례 AWS 클라우드 인프라의 구성 요소 AWS 네트워크 구성 요소 설명: 캠퍼스 예시로 이해하기 AWS 초기 설정 및 구성 시 주의점 AWS에 대한 기초 내용 AWS란? Amazon Web Service 클라우드 컴퓨팅 플랫폼 인터넷을 통해 IT리소스(서버, 스토리지, 데이터베이스, 네트워킹 등)를 제공하고 관리하는 서비스 특징 확장성 (Scalability) 사용자가 필요에 따라 리소스를 쉽게 확장, 축소 가능 블랙 프라이데이에는 몇 배의 트래픽이 몰림. 이때마다 하드웨어를 사용하는건 비효율적, 이때만 자원을 사용하고 끝나면 반납할 수 있음 유연성 (Flexibility) 다양한 IT 환경에 맞춰 손쉽게 맞춤화 가능 자바스크립트로 백엔드 많이 사용 비용 효율성 (Cost Efficiency) 초기 자본 투자 없이, 사용한 만큼 지불하는 비용 구조 가용성 높은 가용성과 자동 백업, 복구 기능으로 서비스 중간 최소화 람다 서비스를 처음 띄울 때 서울 4개의 구역에 띄워놓을 수 있음. 한 개의 구역에 오류가 나도 다른 구역에서는 잘 쓸 수 있음. AWS 계정 만들어보기 AWS Cloud Practitioner Essentials (Korean) Cloud Practitioner 자격증 있음 공부하는 것 추천함 (따는건 비쌈) 큰 회사에서는 AWS 자격증이 크게 상관없겠지만, 작은 회사에서는 AWS역량이 필수적 S3 &amp; Cloudfront S3 Simple Storage Service AWS 최초의 서비스 클라우드 파일 저장소 AWS 사용하고 있는 회사라면 99%의 확률로 활용하고 있음 S3는 서버사이트 스크립팅(PHP, Python등)이 필요없는 정적 웹사이트에 최적 기본 개념 버킷 (Bucket) S3에서 데이터를 저장하는 컨테이너 모든 S3객체는 반드시 하나의 버킷에 속해 있음 S3 스토리지의 최상위 계층이며, 사용자가 데이터를 저장하고 관리할 수 있는 폴더와 비슷 컴퓨터에서 C드라이브와 비슷한 느낌 각 버킷은 고유한 이름을 가짐(전세걔 유일) 데이터 저장 위치(region), 권한 설정, 버전 관리, 수명 주기 정책 등 관리 가능 Key S3버킷 내 객체(파일)를 고유하게 식별하는 문자열 버킷 내 키는 객체의 “경로”로 생각 가능 디렉토리 구조를 흉내낼 수 있도록 설계됨 그냥 전체가 하나의 키임 사용 방법 AWS Console AWS Cli FTP 프로그램 file transfer protocol 사이버덕, 파일질라 Cloudfront AWS CDN 서비스 Contents Delivery Network 인터넷 사용자에게 웹 콘텐츠를 빠르고 효율적으로 제공하기 위해 설계된 분산형 서버 네트워크 S3를 비롯한 AWS의 다른 서비스와 연동이 쉬움 AWS를 사용하는 회사라면 99% 사용 S3는 저장에 특화, Cloudfront는 전송에 특화 S3는 직접 접근으로 주로 내부 사용자나 제한된 사용자들에게 제공을 많이함 하지만 Cloudfront는 CDN을 통해 접근하기때문에 속도도 빠르고 캐싱도 됨 S3 1GB당 약 0.117$, Cloudfront 1GB당 0.095$ CloudFront는 약정 계약이 가능 AWS 솔루션 실무 적용 사례 이미지 리사이즈 대역폭 및 비용 감소할 수 있음 첫 번째 AWS 활용 포트폴리오 S3에 이미지가 업로드 되면 자동적으로 원하는 크기로 리사이징하여 저장하는 방법 원하는 사이즈의 이미지를 실시간으로 생성하는 방법 본인이 자신있는 프로그래밍 언어를 선택하여 AWS Lambda 기능을 활용해서 작성 ‘aws cloudfront 이미지 리사이징’ 구글 검색 보안 민감정보 보호 방법 Signed URL 특정 사용자에게만 접근 권한을 부여하기 위해 URL에 만료 시간과 암호화된 서명을 포함한 URL Signed Cookie 특정 조건을 만족하는 사용자만 CloudFront를 통해 콘텐츠에 접근할 수 있도록 설정하는 보안 메커니즘 AWS 클라우드 인프라의 구성 요소 EC2 (Elastic Compute Cloud) 개발자가 클라우드 컴퓨팅 작업을 할 수 있도록 설계된 서비스 가상화된 서버를 하나의 인스턴스 형태로 제공하며, 컴퓨팅 요구사항에 맞게 용량 조절 가능 IDC Internet Data Center 물리적 인프라를 제공하는 시설 리전 (Region) 물리적으로 분리된 지리적 위치 각 리전은 여러 개의 데이터 센터(Availability Zone, AZ)로 구성되어 있음 리전 간 데이터 전송은 네트워크 지연 시간(latency)이 발생할 수 있음 각 리전은 법적, 규제 요구 사항을 충족하도록 설계됨 Availability Zone 리전 내에서 독립적으로 운영되는 데이터 센터 각 AZ는 하나 이상의 데이터 센터로 구성되어 있음 VPC (가상 사설 네트워크) Virtual Private Cloud 네트워크 2개 이상의 컴퓨터나 장치가 서로 데이터를 주고 받을 수 있도록 연결된 시스템 사설 공개되지 않은, 외부와 분리되느 특정 사용자나 조직만 접근할 수 있는 가상 물리적인 하드웨어 장비나 네트워크 인프라 없이, 소프트웨어를 통해 논리적으로 격리 AWS 네트워크 구성 요소 설명: 캠퍼스 예시로 이해하기 퍼블릭 서브넷 Public Subnet public : 인터넷과 직접 연결되어있다. subnet : sub + network, 하나의 네트워크를 더 작은 단위의 네트워크로 (부분 집합) 중앙 운동장, 도서관, 기념품샵 등등 프라이빗 서브넷 Private Subnet 인터넷과 직접 연결되어있지 않다. 교수 연구실, 실험실 (아무나 못들어가는) 라우팅 / 라우팅 테이블 Routing Table 라우팅 : 경로, 네트워크 내에서 데이터가 이동할 경로를 결정 캠퍼스 내 길 / 길 안내 지도 인터넷 게이트웨이 학교 정문 NAT 게이트웨이 Network Address Translation Network Address : IP주소 (Internet Protocol) 네트워크 상에서 각 장치를 식별하기 위해 사용되는 고유한 숫자 주소 내부 네트워크의 사설 IP 주소를 공용 IP주소로 변환 경비실, 차량 차단기, 보안 검사대 네트워크 ACL (Access Control List) 전체 구역 통제 시스템 서브넷 단위 Stateless, 상태 비기반, 독립적인 제어 들어올 때도 검사하고 나갈때도 검사함 우선순위가 있음 차단기의 정책, 비행기 탈 때와 비슷 보안 그룹 (Security Group) 개별 사무실 출입 통제 시스템 기본적으로 모든 트래픽은 차단하며 허용 규칙만 있음 stateful, 상태 기반 (신분증 제출하고 출입증 받아가는 느낌) 라우팅 테이블에 인터넷 게이트웨이랑 퍼블릭 서브넷이 연결 반대로 생각하면 퍼블릭 서브넷과 프라이빗 서브넷을 구분짓는 중요한 요소가 됨 AWS 초기 설정 및 구성 시 주의점 AWS에서 처음으로 제공해주는 VPC는 가급적으로 사용하지 말자 람다를 private 서브에 올리고 nat를 사용하는 것을 추천 람다는 실행할 때마다 ip가 바뀜, 문제가 될 수 있음",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2024-09-02-aws/"
  },{
    "title": "[JAVA] StringBuilder",
    "text": "목차 String StringBuilder String 반복적으로 String을 연결하거나, 수정해야 할 경우, 보통은 아래와 같은 경우로 string을 사용한다. public class Main{ public static void main(String[] args) { String java = \"자바\"; java += \"공부\"; System.out.println(java); } } 하지만 string은 불변(immutable)객체이므로, “자바”메모리에 “공부”가 추가되는 것이 아니라, 새로운 메모리에 “자바공부”가 저장됨 문자열이 수정될 때마다 새로운 메모리를 할당받기 때문에 성능저하가 일어날 수 있음 StringBuilder StringBuilder는 mutable sequence of characters. 문자열이 변경될 때마다 새로운 메모리를 할당받지 않고, 버퍼를 통해 문자열을 관리하다 toStirng()을 통해 Stirng 객체를 생성 StringBuilder가 효율적인 경우 문자열의 반복적인 연결 문자열의 잦은 수정 대량의 문자열을 처리할 때 단점 StringBuilder는 thread-safe하지 않아 멀티쓰레드 환경에서 좋지 않다. 멀티쓰레스 환경에서는 StringBuffer를 추천 StringBuffer는 StringBuilder와 동일한 API를 사용하지만 각각의 메소드에 대해 동기화를 보장하기 때문 String보다는 빠르고 StirngBuilder보다는 느림",
    "tags": "java",
    "url": "/java/2024-08-29-stringbuilder/"
  },{
    "title": "[Algorithm] 서로소 집합과 유니온 파인드",
    "text": "서로소 집합 유니온 파인드 유니온 파인드의 자료구조 유니온 파인드의 예시 트리와 관련된 용어들 루트 노드, 자식노드, 부모노드, 서브트리, 리프노드, 깊이 이 이미지에서 깊이는 5 이진트리 자식 노드가 2개씩 있는 트리 서로소 집합 서로 공통된 원소를 가지고 있지 않은 두 개 이상의 집합 분리 집합 (Disjoint Set)이라고도 부름 사용 용도 서로 다른 원소들이 같은 집합에 속해있는지, 아닌지 판별할 때 사용 사이클이 존재하는지 판별할때 사용 Union-Find 자료구조로 서로소 집합을 표현 유니온 파인드가 다른 고급 알고리즘의 베이스가 됨 (Kruskal Algorithm) 유니온 파인드 유니온 파인드(Union-Find)의 자료구조 init, find, merge(union) 함수들의 형태로 보통 이루어짐 함수명 고정 X init 초기화 함수 Parent 배열에 대해 자신의 인덱스 값을 가지도록 초기화 초기에 자신의 부모 노드는 자신이라는 의미 void init() { for (int i = 1; i &lt;= n; ++i) { parent[i] = i; } } find 자신의 부모 노드를 찾는 함수 재귀 함수로 구현됨 자기 자신을 가리키는 인덱스 (루트 노드)를 찾을 때까지 반복 int find_parent1(int x) { return x == parent[x] ? x : find_parent1(parent[x]); } int find_parent2(int x) { if (x == parent[x]) return x; else return parent[x] = find_parent2(parent[x]); } // memoization을 사용하는 2가 더 빠름 ``` merge 두 노드를 하나의 집합으로 합치는 함수 y의 부모 노드는 x find 함수를 같이 사용 if 문에서 x == y이면? 사이클이 발생하는 경우이므로 제외 void merge_parent(int x, int y) { int x = find_parent(x); int y = find_parent(y); if (x != y) parent[y] = x; } ``` 유니온 파인드의 예시 최종적으로 오직 루트 노드만이 자기 자신을 가리키게 됨 이러한 특서으로 루트 노드 찾을 수 있음",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-18-day9/"
  },{
    "title": "[JAVA] 키보드로 사용자 입력받는 2가지 방법 (BufferdReader, Scanner)",
    "text": "목차 BufferReader, InputStreamReader, System.in Scanner 1. BufferdReader, InputStreamReader, System.in System.in 일반적으로 keyboard 입력을 지칭하는 Standard Input Stream InputStreamReader byte stream을 character stream으로 변경해주는 역할 수행 InputStreamReader 클래스는 생성자의 파라미터로 InputStream 객체를 전달받음 이 InputStream 객체의 종류에 따라 키보드 사용자 입력을 읽어들일수도 있고, 파일 내용을 읽어들일 수도 있음 사용법 InputstreamReader (InputStream in) InputstreamReader (InputStream in, String charsetName) InputstreamReader (InputStream in, Charset cs) InputstreamReader (InputStream in, CharsetDecoder dec) 생성자의 파라미터로 charset 정보를 전달받아 읽어들이는 stream의 charset을 지정할 수도 있음 BufferedReader 효율적으로 문자를 읽어들이기 위해 버퍼링을 해줌 버퍼링 (Buffering) 효율적인 데이터 처리를 위해 중간 저장공간(Buffer)을 사용하는 것 (주로 입출력에서 사용) 디스크 접근은 시간이 오래걸리기 때문에 한번에 데이터를 저장하여 시간을 줄이고, 필요할 때마다 데이터를 읽음 I/O작업은 시간이 많이 걸리기 때문에 버퍼링으로 접근횟수를 줄여 효율적으로 데이터 사용이 가능 기본 버퍼 사이즈를 그대로 이용할 수도, 생성자를 이용해 버퍼 사이즈를 지정할 수도 있음 보통 FileReader, InputStreamReader의 read()와 같이 비용이 많이 드는 Reader를 파라미터로 전달받아 사용함 만약 BufferedReader없이 FileReader나 InputStreamReader를 사용하면 시스템은 바이트별로 사용자의 입력을 받아서 처리하는 동작을 반복함 시스템에서 IO는 자원소모가 많음 하지만 BufferReader를 사용하면, 시스템은 버퍼가 비어있을 때만, 실제 IO를 일으켜서 데이터를 읽어오고, 나머지 경우에는 메모리에 있는 버퍼의 데이터를 읽어서 처리함 데이터를 문자열로 받아오기 때문에, 적절히 데이터를 처리 후 사용해야 한다. BufferdReader, InputStreamReader, System.in를 이용한 예제 import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; public class UserInput { public static void main(String[] args) throws IOExceptio{ //키보드 사용자 입력을 받을 수 있는 객체 생성 BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); // 입력 데이터 읽기 (한 줄) String str = reader.readLine(); // 입력 데이터 출력 System.out.println(str); } } 2. Scanner Scanner 클래스를 이용하면 1번 방법보다 더 쉽게 사용자 키보드 입력을 받을 수 있음 입력받은 데이터를 Scanner클래스 메소드를 사용해 더 쉽게 가공 가능 예제 import java.util.Scanner; public class ScannerLoop { public static void main(String[] args) { // Scanner 선언 Scanner scanner = new Scanner(System.in); //다음으로 읽어들일 token이 있는지 체크 while (scanner.hasNext()) { //token별로 입력값을 읽어 String을 리턴 String str = scanner.next(); System.out.println(str); } scanner.close(); } } token(공백)별로 사용자 입력값을 읽어들이는 예제",
    "tags": "java",
    "url": "/java/2024-07-17-day8/"
  },{
    "title": "[Algorithm] 동적 계획법 (DP)",
    "text": "목차 Dynamic Programming 정의 DP의 종류 DP 사용조건 DP 유의점 동적 계획법 (DP, Dynamic Programming) 예시 문제 1 1000원짜리 커피를 500원짜리 동전과 100원짜리 동전만 사용하여 계산하려고 한다. 동전을 가장 적게 사용하여 계산하려고 할 때, 필요한 동전의 최소 개수는? (단, 동전은 무수히 많다.) Solution (500 * 2) VS (500 * 1 + 100 * 5) VS (100 * 10) 그리디 알고리즘으로 해결 가능 예시 문제 2 23원짜리 커피를 5원짜리 동전과 2원짜리 동전만 사용하여 계산하려고 한다. 동전을 가장 적게 사용하여 계산하려고 할 때, 필요한 동전의 최소 개수는? (단, 동전은 무수히 많다.) Solution 그리디 알고리즘으로 해결 불가능 그리디 알고리즘을 적용할 수 잇는 조건 중 하나인 최적 부분 구조 조건을 만족하지 않기 때문 지역적으로 최적이 전역적으로도 최적이 아님 Dynamic Programming 정의 이전에 계산한 값을 재사용하여, 하나의 문제를 한 번만 풀게 하는 알고리즘 패러다임 Divide &amp; Conquer과 비슷하지만, 중간 결과를 저장하여 효율성을 높인다는 점에서 차이 이전에 계산해둔 값을 메모리(배열 등)에 저장해서 반복 작업을 줄이는 기법이 핵심 하위 문제의 결과를 먼저 저장하고, 이를 나중에 필요할 때 사용 Tabulation(botton-up), Memoization(top-down) DP의 종류 Top-Down DP 가장 큰 문제부터 풀기 시작하여, 작은 문제들을 재귀적으로 호출하여 답을 구하는 방식 주로 재귀를 통해 해결 ${\\color{yellow}메모이제이션(Memoization)}$을 활용하여 복잡도를 줄임 예시 int fibo(int n) { if (n &lt;= 2 ) return 1; int &amp;ret = dp[n] if (ret != -1) return ret; return ret = fibo(n-1) + fibo(n-2) } Botton-Up DP 작은 문제들을 먼저 풀기 시작하여, 최종적으로 가장 큰 문제들을 해결하는 방식 주로 반복문을 통해 해결 ${\\color{yellow}점화식과 기저사례}$(base case)가 필요 -&gt; ${\\color{yellow}Tabulation}$ 예시 for (int i = 2; i &lt;= 40; ++i) { dp[i] = dp[i-1] + dp[i-2]; } //점화식 DP 사용 조건 겹치는 부분(작은) 문제 (Overlapping Subproblem) 어떠한 문제가 여러 개의 부분(하위) 문제(subproblem)으로 쪼갤 수 있을 대 사용 최적 부분 구조 (Optimal Substructure) 문제의 정답을 작은 문제의 정답에서 구할 수 있을 때 사용 예시 N번째 피보나치 수를 구하는 문제 N-1번째 피보나치 수를 구하는 문제, N-2번째 피보나치 수를 구하는 문제로 쪼갤 수 있음 문제의 정답을 하위 문제의 정답의 합으로 구할 수 있음 재귀로 풀 때 O(2^N) 이미 구했던 값도 다시 계산해야 함 시간 초과 발생 빛 stack overflow 가능성이 높음 반복문으로 풀 때 O(N) 기저사례와 점화식으로 구현 DP 유의점 복잡한 문제의 경우, 점화식을 직접 계산해서 구해야 한다.",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-16-day7/"
  },{
    "title": "[Algorithm] 너비 우선 탐색 &amp; 다익스트라 알고리즘",
    "text": "목차 너비 우선 탐색 BFS 다익스트라 Dijkstra 알고리즘 너비 우선 탐색 (BFS) BFS (Breadth First Search) 하나의 정점으로부터 시작하여 차례대로 모든 정점들을 한 번씩 방문하는 것 루트 노드 (혹은 다른 임의의 노드)에서 시작해서 인접한 노드를 먼저 탐색하는 방법 두 노드 사이의 최단 경로 혹은 임의의 경로를 찾고 싶을 때 사용 BFS의 특징 재귀적으로 동작하는 DFS와 달리, BFS는 주로 큐(Queue) 사용 사이클이 있는 경우, 무한 루프에 빠지지 않도록 방문하는 방문 체크를 해주어야 함 물웅덩이에 돌멩이를 하나 던지면, 파동이 전체 방향으로 퍼져나가는 동심원의 형태로 탐색이 진행 BFS의 동작 순서 BFS의 구현 빈 큐 q 및 visited 배열 생성 시작 노드 ‘st’를 큐 q에 삽입 노드 ‘st’를 방문한 것으로 표시 큐 q가 비어있지 않은 동안 다음을 반복 : 큐의 맨 앞에서 요소를 꺼내 ‘now’에 저장 큐의 맨 앞의 요소를 제거 ‘now’의 값을 출력하고 뒤에 공백을 붙임 노드 ‘now’의 인접 리스트 v에서 각 이웃 ‘next’에 대해 만약 ‘next’가 아직 방문하지 않은 노드인 경우 : 노드 ‘next’를 방문한 것으로 표시 ‘next’를 큐 q에 넣음 BFS의 시간복잡도 V : 정점(노드)의 수, E : 간선의 수 인접 리스트로 표현된 그래프 O(V+E) 인접 행렬로 표현된 그래프 O(V^2) DFS와 BFS의 공통점과 차이점 공통점 그래프에서 시작 노드로부터 목적지 노드까지 도달하거니 특정 정보를 찾는 것이 목표 방문 기록을 체크해 이미 방문한 노드를 다시 방문하지 않게 하여 무한 루프 방지 DFS, BFS 두 방식 모드 조건 내의 모든 노드를 검색한다는 점에서 시간 복잡도는 동일 차이점 DFS는 주로 재귀로 구현하지만, BFS는 큐(queue) 자료구조를 활용하여 구현 일반적으로 DFS보다 BFS가 조금 더 빠르게 동작 동작 순서 상 DFS는 트리를 탐색할 때 자주 사용, BFS는 최단 경로 탐색에서 자주 사용 시간 복잡도 주어진 그래프의 구조와 시작 노드에 따라서 실제 시간 복잡도가 다를 수 있으며, 어떤 알고리즘이 더 효율적인지는 그래프의 형태와 알고리즘의 목적에 따라 달라짐 일반적으로 어떤 알고리즘을 선택할지는 문제의 특성과 요구사항에 따라 결정 다익스트라 (Dijkstra) 알고리즘 그래프 알고리즘 알고리즘을 사용하는 경우 BFS 사용 시, 격자모양의 미로에서는 상하좌우 방향의 가중치가 모두 동일 현재 정점에서 이어진 간선들의 가중치가 모두 동일 하지만 가중치가 모두 일정하지 않다면 -&gt; BFS를 사용할 수 없음 다익스트라 알고리즘 설명 한 정점에서 다른 모든 정점으로의 최단 경로를 구하는 알고리즘 간선의 가중치가 양수일 때만 사용 가능 음수면 다익스트라가 아닌 테이크스트라 알고리즘 사용 BFS와 유사하지만, 일반적인 큐가 아닌 우선순위 큐(Priority Queue)를 사용하여 비용이 가장 작은 간선부터 탐색한다는 차이점이 있음 우선순위 큐 (Priority Queue) 들어오는 순서에 상관 없이 우선 순위가 높은 데이터가 먼저 나가는 자료구조 Heap을 이용해 구현하는 것이 가장 효율적 그리디(Greedy) 알고리즘 매 단계에서 현재까지의 부분 해(solution)를 최적화하여 최종적으로 전체 문제의 최적 해를 찾아냄 다익스트라 알고리즘 동작 순서 출발 노드 선택 출발 노드로부터 각 노드까지의 최단 거리 배열 초기화 출발노드 거리는 0, 나머지 노드는 무한대(충분히 큰 값)로 설정 현재 노드 설정 현재까지의 최단 거리가 확정된 노드 중 가장 가까운 노드 선택 이웃 노드 갱신 선택한 노드를 기준으로 해당 노드와 이웃한 노드들 간의 거리 갱신 모든 노드를 확인할 때까지 3,4단계 반복 핵심 아이디어 각 노드까지의 현재까지 알려진 최단 거리를 계속 갱신하며 출발 노드로부터 최단 경로를 찾는 것 비용이 가장 작은 간선부터 이어주기 위해 우선순위 큐를 사용한다. 다익스트라 알고리즘 시간 복잡도 V : 정점(노드)의 수, E : 간선의 수 O(ElogV) 다익스트라 알고리즘의 구현 문제 예시 방향 그래프가 주어지면 주어진 시작점에서 다른 모든 정점으로의 최단 경로의 비용을 구하여라 첫째 줄에 정점의 개수와 간선의 개수가 입력됨 둘째 줄에는 시작 정점의 번호가 입력됨 셋째 줄부터 간선의 개수만큼의 줄에 걸쳐 (u,v,w)가 주어짐 (u,v,w) -&gt; u에서 v로 가는 양의 가중치 w인 간선 존재 구현 예시 출발 노드 선택 출발 노드로부터 각 노드까지의 최단 거리 배열 초기화 현재 노드 설정 이웃 노드 갱신 모든 노드 확인할 때까지 3,4단계 반복",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-15-day6/"
  },{
    "title": "[Algorithm] 깊이 우선 탐색",
    "text": "목차 DFS란? DFS특징 DFS 시간 복잡도 깊이 우선 탐색 (DFS) DFS란?(Depth First Search) 특정 정점(노드)에서 시작해서 트리나 그래프에서 한 가지 경로를 최대한 깊게 탐색하고, 해당 경로를 끝까지 탐색한 후 다른 경로로 이동 미로를 탐색할 때 한 방향으로 갈 수 있을 때까지 계속 가다가, 더 이상 갈 수 없게 되면 다시 가장 가까운 갈림길로 돌아와서 다른 방향으로 다시 탐색을 진행하는 방법과 유사 모든 정점을 방문하고자 하는 경우에 사용 DFS 특징 일반적으로 재귀 함수 사용 Stack으로도 구현 가능 모든 경우의 수에 대해 탐색을 진행 사이클이 있는 경우, 무한 루프에 빠지지 않도록 방문 체크 해줘야함 BFS보다 깊은 경로를 빠르게 찾는데 용이 진행 순서 구현 함수 DFS(now): 현재 노드를 방문한 것으로 표시 현재 노드를 출력 모든 이웃노드 'next'에 대해서 반복: 만약 'next'를 아직 방문하지 않았다면: DFS(next) DFS 시간 복잡도 V : 정점(노드)의 수, E : 간선의 수 인접 리스트로 표현된 그래프 O(V+E) 인접 행렬로 표현된 그래프 O(V^2) 희소 그래프 Sparse Graph 그래프 내에 적은 숫자의 간선만을 가지는 그래프 인접 행렬보다 인접 리스트 사용이 유리",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-12-day5/"
  },{
    "title": "[Algorithm] 재귀와 정렬",
    "text": "목차 재귀 정렬 재귀 재귀 : 자신을 정의할 때, 자기 자신을 참조하는 것 재귀 함수 : 함수 내부에서 자기 자신을 호출하는 함수 주의할 점 무한 루프에 빠지지 않도록 종료 조건을 잘 설정 종료 조건을 기저 사례 (base case)라고도 함 함수의 파라미터 및 인자 설정에 유의 정렬 정렬의 종류 삽입 정렬 (Insertion Sort) 최악 O(n^2) 버블 정렬 (Bubble Sort) 최악 O(n^2) 합병 정렬 (Merge Sort) 최악 O(nlogn) 퀵 정렬 (Quick Sort) 최악 O(n^2) 평균 O(nlogn) 설명 배열의 요소들 중에서 피벗(Pivot)을 정하여, 피벗의 앞에는 피벗보다 작은 원소들이 오고, 피벗 뒤에는 피벗보다 큰 값이 오도록 배열을 둘로 나눔 분할된 두 개의 배열의 크기가 0이나 1이 될 때까지, 분할된 두 배열에 대해 재귀적으로 이 과정을 반복 재귀 호출이 한 번 진행될 때마다 최소한 하나의 원소가 최종적인 위치에 있게 되므로, 종료됨이 보장 힙 정렬 (Heap Sort) 최악 O(nlogn) 특정 정렬이 빠르다고 항상 좋은 것은 아님 데이터의 특성, 크기에 따라 적절한 방법 사용해야 함 언어들의 라이브러리 내장 sort 구현 C++ 인트로 정렬 (Intro Sort) 퀵 정렬 + 힙 정렬 + 삽입 정렬 Python 팀 정렬 (Tim Sort) 합병 정렬 + 삽입 정렬 Java Java7 이전에는 병합 정렬, 이후에는 팀 정렬 코테에선 왠만하면 내장 sort함수를 사용",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-11-day4/"
  },{
    "title": "[Algorithm] 문자열",
    "text": "목차 코딩테스트에 자주 나오는 문자열 1) 회문 2) 올바른 괄호 문자열 분할 정복과 백트래킹 1) 분할 정복 2) 백트레킹 코딩테스트에 자주 나오는 문자열 1. 회문 (Palindrome) 앞뒤 방향으로 볼 때, 같은 순서의 문자로 구성된 문자열을 의미 예시 “소주 만 병만 주소”, “Madam, I’m Adam”, “1234321” 2. 올바른 괄호 문자열 (VPS = Valid Parenthesis String) 조건 빈 문자열은 올바른 괄호 문자열이다 S가 올바른 괄호 문자열이라면, (S)도 올바른 괄호 문자열이다. S, T가 괄호 문자열이라면 ST도 올바른 괄호 문자열이다. 보통은 Stack을 사용해서 해결 ’)’가 입력될 때마다, 스택에 있는 ‘(‘를 하나씩 지움 이때, 스택(top)이 비어있거나, ‘(‘가 없으면 올바른 괄호 문자열이 아님 모든 문자열을 순회한 뒤, 스택이 비어있으면 올바른 괄호 문자열 치환 사용하기 ’(‘를 1, ‘)’를 -1로 치환 문자열 S를 전부 순회하며 합 계산 중간에 합이 음수가 되거나, 모든 계산이 끝나고 0이 아니면 올바른 괄호 문자열이 아님 분할 정복과 백트래킹 분할 정복 (Divide and Conquer) 큰 문자를 작은 문제로 분할하여 작은 문제의 답을 모다 큰 문제의 답을 구함 기저 사례(base case)를 잘 설정하여 일정 기준 이상 분할되지 않도록 해야 함 보통 재귀로 구현 예시 피보나치 수열 Z 백트래킹 답이 될 수 없는 경우는 탐색 대상에서 제외하며 효율적으로 답을 구하는 알고리즘 가지치기(pruning)를 통해 연산량을 유의미하게 줄여줌 가지치기를 사용하기 위해서는 현재 상태에서 도달할 수 있는 상태가 모두 답이 될 수 없음을 보여야 함 정확한 시간 복잡도 측정 어려움 보통 재귀로 구현 많이 연습해봐야 익힐 수 있음 예시 스도쿠 대입해보고 현재 상태에서 스도쿠를 완성할 수 없다면, 분기점으로 다시 돌아옴 Nqueen",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-10-day3/"
  },{
    "title": "[Algorithm] 유클리드 호제법",
    "text": "목차 유클리드 호제법 소수 판별법 유클리드 호제법 두 수가 서로 상대방 수를 나누어 원하는 수를 구하는 것 GCD (Greatest Common Divisor) 최대공약수 두 자연수 a, b에 대해서 (a &gt; b) a를 b로 나눈 나머지를 r이라고 하면 a와 b의 최대공약수는 b와 r의 최대공약수와 동일 이 성질에 따라, b를 r로 나눈 나머지 r’를 구하고, 다시 r을 r’로 나눈 나머지를 구하는 과정을 반복하여 나머지가 0이 되었을때 나누는 수가 a와 b의 최대공약수 예시 1071과 1029의 최대공약수 구하기 1071 % 1029 = 42 1029 % 42 = 21 42 % 21 = 0 21이 1071과 1029의 최대공약수 LCM (Least Common Multiple) 최소공배수 LCM(a, b) = a * b / GCD(a, b) 어떠한 두 수의 곱은, 그 두 수의 최대공약수와 최소공배수의 곱과 같다 cpp의 gcd, lcm 함수는 c++17부터 지원 numeric 모듈 보통 코테에서 c++17 사용 python은 math 모듈의 gcd, lcm 함수 gcd는 python 3.5 lcm은 python 3.9 보통 코테에서 python 3.8 사용 java는 지원하지 않음 소수 판별법 1은 소수, 합성수 아님 에라토스테네스의 체 O(Nlog(logN)) N이 커지면 거의 O(N) 회귀가 아닌 반복",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-09-day2/"
  },{
    "title": "[Algorithm] 시간 복잡도",
    "text": "시간 복잡도 언어별 실행 속도 cpp &gt; Java &gt; python 보통 언어별 시간 보정이 존재 우선 java가 편하니까 Java로 해보기로! 평균적으로 대략 1초에 1억 번 연산 (10^8) 실제 문항을 풀 때, N의 범위를 먼저 확인할 것 시간 복잡도를 고민하지 않고 무작정 구현 먼저 하면 처음부터 다시 코드를 작성해야함 예를 들어, 시간제한 1초 / 1 &lt;= N &lt;= 10^5 인 경우 O(N^2)는 불가능 O(NlogN)까지 가능",
    "tags": "algorithm",
    "url": "/algorithm/2024-07-08-day1/"
  },{
    "title": "[Etc] URI과 URL의 차이",
    "text": "목차 URI URL URN URI와 URL의 차이점 flutter앱을 개발하는 도중, http통신관련 코드를 짜면서 Uri.parse()함수를 여러 번 접하게 되었다. 주소 관련 변수명을 url로 쓰고 있어 이 둘의 의미가 혼동되어 정확하게 알아보고자 하였다. URI (Uniform Resource Identifier) 우리 말로 ‘통합 자원 식별자’ Uniform -&gt; 리소스를 식별는 통일된 방식 Resource -&gt; URI로 식별이 가능한 웹 브라우저 파일 및 그 이외의 리소스를 포함하는 모든 종류의 자원 Identifier -&gt; 다른 항목과 구분하기 위해 필요한 정보 즉, URI는 인터넷상의 리소스 자원 자체를 식별하는 고유한 문자열 시퀀스 URL (Uniform Resource Locator) 네트워크상에서 통합 자원(리소스)의 “위치”를 나타내기 위한 규약 웹 사이트 주소 + 컴퓨터 네트워크 상의 자원 특정 웹 페이지의 주소에 접속하기 위해서는 웹 사이트의 주소뿐만 아니라 프로토콜(https, http, sftp, smp 등)을 함께 알아야 접속이 가능한데, URL은 이들 모두를 나타낸다. URN (Uniform Resource Name) 리소스의 위치, 프로토콜, 호스트 등과는 상관없이 각 자원에 이름을 부여한 것 웹 문서의 물리적인 위치와 상관없이 웹 문서 자체를 나타낸다. URI와 URL의 차이점 URI= 식별자, URL=식별자+위치 nan0silver.github.io는 리소스의 이름만 나타내므로 URI https://nan0silver.github.io/는 이름과 위치를 나타내므로 URL (프로토콜 http를 포함하기 때문) URL ⊂ URI URL은 프로토콜과 결합된 상태이다. (프로토콜 + 이름) URI는 그 자체로 이름이 될 수 있다.",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2023-08-14-about-UriUrl/"
  },{
    "title": "[Flask] Flask서버에 외부 접근하는 방법",
    "text": "app.run()안에 바인딩될 호스트 정보를 넣어준다. app.run()은 127.0.0.1로 실행되며 이는 로컬에서만 실행가능하다. app.run(host=’0.0.0.0’)의 경우 모든 호스트로 접근 가능하다. 포트 변경을 원하는 경우 app.run(host=’0.0.0.0’, port=8000)과 같이 사용한다. 위의 방법으로 실행하면 flask서버를 실행한 컴퓨터의 IP주소와 함께 설정한 포트로 연결가능한 주소가 나온다.",
    "tags": "flask",
    "url": "/flask/2023-07-01-flask-run/"
  },{
    "title": "[Flask] Flask 서버와 통신",
    "text": "목차 Flask란? Dio Future Flask에서 json형태로 response보내는 함수 Flask란? 웹 애플리케이션 개발을 위한 파이썬 프레임워크 가장 유명한 Django(장고)보다 가볍고 필요한 기능만 최대한 라이트한 개발을 할 수 있다. Dio A powerful Http client for Dart http처럼 서버와 통신하기 위해 필요한 패키지 많은 기능을 가지고 있고, 여러가지 커스텀을 쉽게 할 수 있다. pubspec.yaml에 dependency를 추가해주어야 한다. Http와 json형식의 데이터로 받아올 때 차이점 Http로 요청 후 리턴받은 데이터를 decode해준 값이 Dio로 요청 후 리턴받은 데이터와 동일하다. https://kyungsnim.net/175 에서 참고 Future 지금은 없지만 미래에 요청한 데이터 혹은 에러가 담길 그릇 싱글스레드 환경에서 비동기 처리를 위함 비동기 : 어떤 동작이 완료되지 않아도 다음 동작을 수행하는 것 동기 : 모든 동작이 완료된 후 다음 동작을 수행하는 것 Flask에서 json 형태로 response보내는 함수 jsonify json response를 보내기 위해 이미 content-type header가 ‘application/json’로 되어 있는 flask.Response() 객체를 리턴 jsonify도 함수 내부에서도 json form으로 serialize하는 과정에서 json.dumps를 사용 다만 dump하기 전에 받은 값들을 모두 dictionary로 만들었다. Parameter accept dictionary list json.dumps python이 가지고 있는 json library의 json.dumps() 수동으로 MIME type header를 추가해주어야 하는 encoded string을 리턴한다. flask가 알아서 판단해 response를 자동으로 보내주도록 사용하기 때문에 직접적으로 사용할 수 있다. 다만 reponse header fields는 디폴트(text/html; charset=utf-80)로 처리된다. Parameter accept jsonify보다 더 많은 타입",
    "tags": "flask",
    "url": "/flask/2023-04-18-about-flask/"
  },{
    "title": "[Flutter] Flutter UI",
    "text": "Flutter Layout Widget의 생명주기 Flutter Layout Flutter Layout의 핵심은 위젯 위젯은 현재 주어진 상태(데이터)를 기반으로 어떤 UI를 구현할지 정의 플러터 프레임워크는 기존 상태 위젯과 새로운 상태의 위젯을 비교하여 UI변화를 반영 최소한의 리소스로 UI변경을 이룸 레이아웃 모델, 앱 내 이미지, 아이콘, 글자 등 거의 모든 것이 위젯 위젯은 자식을 하나만 갖는 위젯과 자식을 여럿 갖는 위젯으로 나뉨 자식을 하나만 갖는 위젯 container 위젯 자식 위젯을 커스터마이징할 수 있는 위젯 클래스 여백, 간격, 테두리, 배경색 등을 추가할 수 있음 나머지 UI는 속성에 의해 제어됨 (color속성, Text.style속성 등) 자식을 여럿 갖는 위젯 children 매개변수를 입력 받음 리스트로 여러 위젯을 입력할 수 있음 Column 위젯, Row 위젯 children 매개변수에 입력된 모든 위젯들을 세로(가로)로 베치 ListView 위젯 리스트 구현가능, 입력된 위젯이 화면을 벗어나게 되면 스크롤 가능해짐 예시 위의 스크린샷에 해당하는 위젯을 구현하기 위한 위젯 트리이다. ❗️Material apps vs Non-Material apps Material apps 플랫 디자인의 장점을 살리면서도 빛에 따른 종이의 그림자 효과를 이요해 입체감을 살리는 디자인방식을 가진 앱 구글에서 사용하고 있는 플랫 디자인 지침 앱마다 다른 디자인을 통일시키기 위함 Scaffold 위젯 기본적인 material design의 시각적인 레이아웃 구조를 실행한다. Scafflod 위젯 vs Container Scafflod 기본적으로 appbar, body라는 2개의 옵션을 가짐 Container Scafflod의 body부분에 들어가는 부속품 봉지라고 생각하면 됨 한 개의 자식을 가지는 레이아웃 위젯 Container의 생성자는 아래와 같다. Container({ Key key, this.alignment, this.padding, Color color, Decoration decoration, this.foregroundDecoration, double width, double height, BoxConstraints constraints, this.margin, this.transform, this.child, })&lt;/pre&gt; - Widget의 생명주기 Stateful Widget의 생명주기 stateless widget은 한 번 만들어지면 갱신할 수 없어 생명주기가 없다. stateful widget은 10단계의 생명주기가 있다. createState()함수 상태를 생성하는 함수 다른 생명주기 함수들이 포함된 State 클래스를 반환 StatefulWidget 클래스를 상속받는 클래스는 반드시 이 함수를 호출해야 한다. Class MyHomePage extends StatefulWidget { @override _MyHomePageState createState() =&gt; new _MyHomePageState(); } mounted == true createState() 함수가 호출되어 상태가 생성되면 mounted 속성이 true가 된다. 위젯을 제어할 수 있는 buildContext클래스에 접근 가능해짐 buildContext가 활성화되어야 setState()함수 이용 가능 initState()함수 위젯을 초기화하는 함수 주로 데이터 목록을 만들거나 처음 필요한 데이터를 주고받을 때 호출 이 함수를 호출할 때 내부에서 _getJsonData() 함수를 호출하면 서버에서 데이터를 가져와 화면에 출력할 수 있음 didChangeDependencies()함수 initState()함수 호출 후, 해당 위젯이 데이터에 의존하는 위젯이라면 반드시 호출해야하는 함수 주로 상속받은 위젯을 사용할 때 피상속자가 변경되면 호출 build()함수 위젯을 화면에 렌더링하는 함수 (Widget을 반환한다.) @override Widget build(BuildContext context) { return MaterialApp( title: 'Flutter Demo', theme: ThemeData( primarySwatch: Colors.blue, ), home: MyHomePage(title: 'Flutter Demo Page'), ); } didUpdateWidget()함수 부모 위젯이나 데이터가 변경되어 위젯을 갱신해야 할 때 호출하는 함수 initState()함수는 위젯을 초기화할 때 한 번만 호출되므로 위젯이 변경되었을 때 이 함수를 호출해야함 setState()함수 데이터가 변경되었다는 것을 알려주고 이를 반영하여 화면 UI를 변경하는 함수 deactive()함수 위젯의 상태 관리를 중지하는 함수 State객체가 플러터 구성 트리에서 제거될 때 호출됨 dispose()함수를 호출하기 전까지는 State객체를 재사용할 수 있게 해줌 dispose()함수 State객체를 영구적으로 소멸할 때 호출되는 함수 mounted == false 생명주기를 끝내주는 함수 false가 된 다음 이 State는 재사용할 수 없다.",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2023-04-13-flutter-UI/"
  },{
    "title": "[Flutter] Start Flutter",
    "text": "목차 What is Flutter Dart Flutter Project What is Flutter? 크로스 플랫폼 앱 개발 프레임 워크 Dart 언어 사용 구글에서 만듬 컴파일 언어의 특징을 활용하여 앱 개발 가능 프레임워크, 엔진, 임베더 계층으로 구성 프레임워크 Dart로 개발된 여러 클래스로 앱 개발 엔진 플러터의 코어 C, C++ 데이터 통신, 다트 컴파일, 렌더링, 시스템 이벤트 임베더 플러터 앱이 크로스 플랫폼에서 동작하도록 플러터 엔진이 렌더링한 결과를 플랫폼별 네이티브 언어로 뷰를 만들어 화면에 보여줌 네이티브 언어 안드로이드 : 자바, 코틀린 IOS : 오브젝티브-C, 스위프트 플러터의 장점 높은 개발 효율 hot reload 코드 변경 이후 빌드시간에 의한 낭비되는 시간을 없애기 위해 업데이트된 소스파일들이 dart virtual machine에 주입되면 flutter는 변경된 사안을 기반으로 widge tree를 재구성 -&gt; 변경된 것이 빠르게 결과물에 적용됨 유연한 사용자 인터페이스 다양한 위젯 제공 강력한 애니메이션 기능 제공 빠른 속도 Dart 비동기 처리 방식 작업이 끝나기를 기다리지 않고 다음 작업을 처리하게 하는 것 작동 방식 async 함수를 비동기로 만듬 await 비동기 함수 안에서 언제 끝날지 모르는 작업 앞에 붙임 해당 작업의 결과를 받기 위해 비동기 함수이름 앞에 Future 붙임 예시 코드 Future checkVersion() async { var version = await lookUpVersion(); print(version); }&lt;/pre&gt; 하나의 thread로 동작 Flutter Project lib 폴더 플러터 앱 개발을 위한 다트 파일 pubspec.yaml 플러터의 다양한 패키지, 이미지, 폰트 사용할수 있게 해줌",
    "tags": "miscellaneous",
    "url": "/miscellaneous/2023-04-06-start-flutter/"
  }]};
