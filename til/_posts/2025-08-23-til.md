---
layout: post
collection: til
description: >
  2025-08-23 TIL
categories: ["til"]
tags: ["TIL", "Git", "ML"]
date: 2025-08-23 00:00:00
last_modified_at: 2025-08-23 00:36:49
sitemap: false
---

# [TIL] A/B 테스트

> 📝 **TIL (Today I Learned)**  
> 📅 **작성일**: 2025-08-23  
> 🔄 **최종 수정**: 2025년 08월 25일

---

## 🍀 새롭게 배운 것

# A/B 테스트란?

- **정의**: 같은 목표를 두고 **두 버전(A=기준, B=변경안)** 을 **동시에 무작위로** 사용자에게 나눠 보여준 뒤, **어느 쪽이 더 성과가 좋은지** 통계적으로 비교하는 실험.
- **목적**: 느낌/감이 아니라 **데이터로 의사결정**. 버튼 문구, 화면 배치, 가격 제안, 푸시 타이밍 등 “실제로” 지표가 개선되는지 검증.

# 기본 용어

- **변수(Variant)**: A(컨트롤) vs B(실험안). 3개 이상이면 A/B/n.
- **지표(Metric)**: 실험의 **목표**(예: 등록 전환율, 1일차 잔존, 통화 완료율).
- **유의수준 α**: 오탐 허용(보통 0.05).
- **검정력 Power(1−β)**: 진짜 차이가 있을 때 잡아낼 확률(보통 0.8).
- **MDE**(최소 검출 가능 효과): “이 정도 차이는 나야 성공이라 본다” 최소 개선 폭(예: +2%p).

# 어떻게 하는가 (실전 절차 7단계)

1. **가설 세우기**

   - 예) “대기시간 안내 문구를 바꾸면 **매칭 시작 클릭률**이 ↑한다.”

2. **지표 딱 하나만 주지표로**

   - 주지표: 매칭 시작 클릭률
   - 보조지표(가드레일): 이탈률, 고객불만 접수율 등 “부작용 체크”

3. **표본수(기간) 계획**

   - 대략의 규칙: **차이를 작게 보고 싶을수록, 베이스 전환율이 낮을수록 → 더 많은 트래픽/기간**이 필요.
   - (참고 공식 – **이해만**):

     - 비율형 지표의 각 그룹 표본수 n ≈ `2 * (zα/2 + zβ)^2 * p̄(1-p̄) / Δ^2`

       - `p̄`: 기준 전환율 추정, `Δ`: 검증하고 싶은 차이(절대값)

4. **무작위 배정 & 고정**

   - **사용자 단위**로 50/50 랜덤 분배(세션/페이지뷰 단위 X).
   - 실험 중엔 **변형하지 말기**(중간에 디자인을 또 바꾸지 않기).

5. **정확한 로깅**

   - 모든 이벤트에 `experiment_id`, `variant`(A/B) 파라미터를 함께 로깅.
   - **SRM**(sample ratio mismatch) 체크: 50/50이 크게 깨지면(예: 60/40) 실험 무효.

6. **기간 고정 & ‘엿보기’ 금지**

   - **종료 조건 전**에 유의성만 보고 중단하면 거짓 양성↑.
   - 꼭 필요하면 **사전 정의된 순차검정**(group-sequential)이나 **베이즈 접근**을 사용.

7. **해석 & 롤아웃**

   - 통계 유의 + **실무 유의**(임팩트/비용/부작용) 함께 본 뒤, 점진적 롤아웃(예: 10%→30%→100%).

# GA4/앱에서 바로 쓰는 구성 팁

- 이벤트 설계 예:

  - `event_name: start_match_click`
  - 파라미터:

    - `experiment_id: "wait_copy_v1"`
    - `variant: "A"|"B"`
    - 사용자 ID 또는 설치 ID(사용자 기준 배정 유지)

- **빅쿼리 연동** 시 쿼리로 `variant`별 전환율 비교가 쉬워짐.
- **SRM 빠른 체킹**: 실시간 대시보드에서 A/B 트래픽이 49–51% 근처인지 확인.

# A/B 테스트 3가지 예시

1. **대기시간 안내 문구**

   - A: “곧 연결됩니다”
   - B: “평균 30초 내 연결됩니다 · 취소 가능”
   - 주지표: `start_match_click / 방문자`
   - 가드레일: 즉시 이탈률, 고객불만

2. **통화 후 피드백 수집 방식**

   - A: 5점 척도만
   - B: 5점 + “칭찬 한마디” 한줄 텍스트
   - 주지표: 피드백 제출률
   - 가드레일: 피드백 작성 시간, 다음날 재방문율

3. **안심케어(유료) 소개 타이밍**

   - A: 첫 3회 통화 후 페이월
   - B: 첫 1회 통화 후 페이월
   - 주지표: 7일 내 결제 전환율
   - 가드레일: 7일 유지율, 평균 통화시간 변화

# 설계 체크리스트 (붙여넣어 쓰기)

- [ ] 가설과 **주지표 1개** 명확
- [ ] **MDE**와 **기간/표본수** 사전 정의
- [ ] **사용자 단위 랜덤** 배정 + 고정
- [ ] **experiment_id / variant** 로깅
- [ ] **SRM** 모니터링
- [ ] 중도 엿보기 금지(혹은 순차검정 채택)
- [ ] 통계 유의 + **비즈니스 유의** 함께 판단
- [ ] 롤아웃/롤백 플랜 준비

# 자주 하는 실수

- 여러 요소를 한꺼번에 바꾸기 → **원인 분리 불가**
- 주지표를 여러 개로 두기 → 해석 혼란
- 세션/페이지뷰 단위 랜덤화 → 사용자 경험이 섞여 **오염**
- 주중/주말, 마케팅 캠페인 겹침 **시즌성 영향** 무시
- 결과가 좋게 나올 때까지만 **계속 엿보기**

# (참고) 빈도주의 vs 베이즈

- **빈도주의**: p-value/신뢰구간, 고정 표본 설계에 적합.
- **베이즈**: “B가 A보다 좋을 확률”처럼 **직관적 해석**과 **순차적 의사결정**에 유리.
  둘 다 장단점 있어요—팀의 익숙함/툴링에 따라 선택.
